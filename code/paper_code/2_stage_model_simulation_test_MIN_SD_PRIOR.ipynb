{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: tidyverse\n",
      "\n",
      "── \u001b[1mAttaching packages\u001b[22m ─────────────────────────────────────── tidyverse 1.3.0 ──\n",
      "\n",
      "\u001b[32m✔\u001b[39m \u001b[34mggplot2\u001b[39m 3.2.1     \u001b[32m✔\u001b[39m \u001b[34mpurrr  \u001b[39m 0.3.3\n",
      "\u001b[32m✔\u001b[39m \u001b[34mtibble \u001b[39m 2.1.3     \u001b[32m✔\u001b[39m \u001b[34mdplyr  \u001b[39m 0.8.4\n",
      "\u001b[32m✔\u001b[39m \u001b[34mtidyr  \u001b[39m 1.0.2     \u001b[32m✔\u001b[39m \u001b[34mstringr\u001b[39m 1.4.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34mreadr  \u001b[39m 1.3.1     \u001b[32m✔\u001b[39m \u001b[34mforcats\u001b[39m 0.5.0\n",
      "\n",
      "── \u001b[1mConflicts\u001b[22m ────────────────────────────────────────── tidyverse_conflicts() ──\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m    masks \u001b[34mstats\u001b[39m::lag()\n",
      "\n",
      "Loading required package: rstan\n",
      "\n",
      "Loading required package: StanHeaders\n",
      "\n",
      "rstan (Version 2.19.3, GitRev: 2e1f913d3ca3)\n",
      "\n",
      "For execution on a local, multicore CPU with excess RAM we recommend calling\n",
      "options(mc.cores = parallel::detectCores()).\n",
      "To avoid recompilation of unchanged Stan programs, we recommend calling\n",
      "rstan_options(auto_write = TRUE)\n",
      "\n",
      "\n",
      "Attaching package: ‘rstan’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:tidyr’:\n",
      "\n",
      "    extract\n",
      "\n",
      "\n",
      "Loading required package: mvtnorm\n",
      "\n",
      "Loading required package: bayesplot\n",
      "\n",
      "This is bayesplot version 1.7.1\n",
      "\n",
      "- Online documentation and vignettes at mc-stan.org/bayesplot\n",
      "\n",
      "- bayesplot theme set to bayesplot::theme_default()\n",
      "\n",
      "   * Does _not_ affect other ggplot2 plots\n",
      "\n",
      "   * See ?bayesplot_theme_set for details on theme setting\n",
      "\n"
     ]
    }
   ],
   "source": [
    "require(tidyverse)\n",
    "require(rstan)\n",
    "require(ggplot2)\n",
    "require(mvtnorm)\n",
    "rstan_options(auto_write = TRUE)\n",
    "require(bayesplot)\n",
    "missing_val=-100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = file.path('/nfs/turbo/umms-cgillies/cgillies/RACE_CAPS/analysis', '/20200728_stage_impute_beta_missing_min_PRIOR_SD')\n",
    "dir.create(path)\n",
    "setwd(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsed with column specification:\n",
      "cols(\n",
      "  .default = col_double()\n",
      ")\n",
      "\n",
      "See spec(...) for full column specifications.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_nmr = read_csv('/nfs/turbo/umms-cgillies/cgillies/RACE_CAPS/11_20_2019_even_odds_interaction_prior_1/nmr_metabolites_scaled_matrix.csv')\n",
    "metabolites = colnames(df_nmr)[1:27]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl>\n",
       "\t<dt>$alpha</dt>\n",
       "\t\t<dd>2.4350852557673</dd>\n",
       "\t<dt>$beta</dt>\n",
       "\t\t<dd>5.68186559679037</dd>\n",
       "\t<dt>$mu</dt>\n",
       "\t\t<dd>0.3</dd>\n",
       "\t<dt>$sigma_2</dt>\n",
       "\t\t<dd>0.0230340168984334</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description}\n",
       "\\item[\\$alpha] 2.4350852557673\n",
       "\\item[\\$beta] 5.68186559679037\n",
       "\\item[\\$mu] 0.3\n",
       "\\item[\\$sigma\\_2] 0.0230340168984334\n",
       "\\end{description}\n"
      ],
      "text/markdown": [
       "$alpha\n",
       ":   2.4350852557673\n",
       "$beta\n",
       ":   5.68186559679037\n",
       "$mu\n",
       ":   0.3\n",
       "$sigma_2\n",
       ":   0.0230340168984334\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "$alpha\n",
       "[1] 2.435085\n",
       "\n",
       "$beta\n",
       "[1] 5.681866\n",
       "\n",
       "$mu\n",
       "[1] 0.3\n",
       "\n",
       "$sigma_2\n",
       "[1] 0.02303402\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#TARGET_MISSING_RATE=0.3\n",
    "get_alpha_beta_for_target_rate = function(df,metabolites,TARGET_MISSING_RATE) {\n",
    "    missing_rate = df_nmr[,metabolites] %>% summarise_all(function(x) { mean(x == min(x))  })\n",
    "    missing_rate_numeric = missing_rate %>% t() %>% as.numeric\n",
    "    mu = mean( missing_rate_numeric )\n",
    "    sigma_2 = var(missing_rate_numeric)\n",
    "    RATE = TARGET_MISSING_RATE/mu\n",
    "    mu = RATE * mu\n",
    "    sigma_2 = RATE * sigma_2\n",
    "    mu\n",
    "    sigma_2\n",
    "    nu = mu * (1 - mu) / sigma_2 - 1\n",
    "    alpha = mu * nu\n",
    "    beta = (1 - mu) * nu\n",
    "    list(alpha=alpha,beta=beta,mu=mu,sigma_2=sigma_2)\n",
    "}\n",
    "\n",
    "get_alpha_beta_for_target_rate(df_nmr,metabolites,0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "died = df_nmr$died_90_day\n",
    "sigma_0 = cov(df_nmr[died == 0,c(1:27)])\n",
    "mu_0 = colMeans(df_nmr[died == 0,c(1:27)]) \n",
    "sigma_1 = cov(df_nmr[died == 1,c(1:27)])\n",
    "mu_1 = colMeans(df_nmr[died == 1,c(1:27)]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generation code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_df = function(n_0,mu_0,sigma_0,n_1,mu_1,sigma_1,frac_sig=0.5,censor=TRUE,max_missing=0.6,alpha=-1,beta=-1) {\n",
    "    diffs = abs( mu_1 - mu_0) / sqrt( (diag(sigma_0)^2)/n_0 + (diag(sigma_1)^2)/n_1  )\n",
    "    #print(diffs)\n",
    "    m = length(diffs)\n",
    "    diffs = diffs/sum(diffs)\n",
    "    #print(diffs)\n",
    "    ind = seq(1,m)\n",
    "    set_non_zero = sample(ind,size=ceiling(frac_sig * m),prob=diffs)\n",
    "    set_zero = setdiff(ind,set_non_zero)\n",
    "    truth = rep(FALSE,m)\n",
    "    truth[set_non_zero] = TRUE\n",
    "    mu_0[set_zero] = 0\n",
    "    mu_1[set_zero] = 0\n",
    "    X_0 = rmvnorm(n = n_0, mean = mu_0, sigma = sigma_0) \n",
    "    X_1 = rmvnorm(n = n_1, mean = mu_1, sigma = sigma_1)\n",
    "    df_sample = data.frame(rbind(X_0,X_1))\n",
    "    df_sample$died_90_day = c( rep(0,n_0),rep(1,n_1)  )\n",
    "    \n",
    "    df_censored = df_sample\n",
    "    df_naive_impute = df_sample\n",
    "    n_var = length(mu_0)\n",
    "    thresholds = rep(0,n_var)\n",
    "    est.thresholds = rep(0,n_var)\n",
    "    est.naive_impute = rep(0,n_var)\n",
    "    missing_rates=rep(0,n_var)\n",
    "    if(censor == TRUE) {\n",
    "        \n",
    "        missing_rates = rbeta(n_var,shape1 = alpha, shape2 = beta)\n",
    "        # only allow a missing rate up to a certain level\n",
    "        missing_rates = sapply(missing_rates, function(x) { min(max_missing,x) })\n",
    "        \n",
    "        #missing_rates = rep(MISSING_RATE, n_var)\n",
    "        \n",
    "        for(i in 1:n_var) {\n",
    "            thresholds[i] = quantile( df_censored[, i], missing_rates[i] )\n",
    "            df_censored[ (df_censored[, i] < thresholds[i]), i ] = NA\n",
    "            est.thresholds[i] = min( df_censored[ , i ], na.rm = T)\n",
    "            est.naive_impute[i] = log( min( exp(df_censored[ , i ]), na.rm = T) / 2 )\n",
    "            df_naive_impute[ (df_naive_impute[, i] < thresholds[i]), i ] = est.thresholds[i]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    \n",
    "    list(df_sample=df_sample,truth=truth, df_censored=df_censored, df_naive_impute=df_naive_impute, missing_rates=missing_rates, thresholds=thresholds, est.thresholds=est.thresholds, est.naive_impute=est.naive_impute)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 1 Imputation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage_1_impute = \"\n",
    "functions {\n",
    "    real normal_ub_rng(real mu, real sigma, real ub) {\n",
    "      real p_ub = normal_cdf(ub, mu, sigma);\n",
    "      real u = uniform_rng(0, p_ub);\n",
    "      real y = mu + sigma * inv_Phi(u);\n",
    "      return y;\n",
    "    }\n",
    "}\n",
    "data {\n",
    "    int<lower=0> N;\n",
    "    int<lower=0> N_var;\n",
    "    int<lower=0> N_miss;\n",
    "    int<lower=0> N_use_impute;\n",
    "\n",
    "    matrix[ N, N_var ] x_naive_impute;\n",
    "    matrix[ N, N_var ] x_is_missing;\n",
    "\n",
    "    //contains the indicies of x_naive_imp to use for imputation\n",
    "    int x_use_impute[N_use_impute, N_var ];\n",
    "\n",
    "    //Threshold for imputation\n",
    "    //Separate threshold per metabolite\n",
    "    vector[N_var] threshold;\n",
    "    \n",
    "\n",
    "    // This vector contains the missing row index, column index\n",
    "    int x_missing[ N_miss, 2 ];\n",
    "    \n",
    "}\n",
    "parameters {\n",
    "\n",
    "    //betas for each imputed value\n",
    "    matrix[ N_use_impute, N_var ] beta_impute_raw;\n",
    "    vector[ N_var ] alpha_impute;\n",
    "    vector<lower=0>[ N_var ] sigma_impute;\n",
    "    real<lower=0> sigma_beta_impute_x;\n",
    "\n",
    "}\n",
    "transformed parameters {\n",
    "    matrix[ N_use_impute, N_var ] beta_impute;\n",
    "    for(j in 1:N_var) {\n",
    "        beta_impute[,j] = beta_impute_raw[,j] * sigma_beta_impute_x;\n",
    "    }\n",
    "}\n",
    "model {\n",
    "    sigma_beta_impute_x ~ std_normal();\n",
    "    // FORGOT TO SET PRIOR ON alpha_x_pred and sigma_impute\n",
    "\n",
    "    for(j in 1:N_var) {\n",
    "        real y[N];\n",
    "        vector[N_use_impute] beta_x_pred;\n",
    "        int x_use_ind[N_use_impute];\n",
    "        matrix[N, N_use_impute] x_pred_use;\n",
    "        real alpha_x_pred;\n",
    "        real sigma_x_pred;\n",
    "        //predicted target\n",
    "        vector[N] xj_pred;\n",
    "        //target\n",
    "        vector[N] xj;\n",
    "        int observed[N];\n",
    "        \n",
    "        //ADD TO LIKELIHOOD\n",
    "        beta_impute_raw[, j] ~ std_normal();\n",
    "    \n",
    "        //ASSIGN VALS\n",
    "        xj = x_naive_impute[, j];\n",
    "        //dont make a prediction using itself\n",
    "        //this should be copying the values according to ref\n",
    "        beta_x_pred = beta_impute[, j];\n",
    "        alpha_x_pred = alpha_impute[j];\n",
    "        x_use_ind = x_use_impute[, j];\n",
    "        sigma_x_pred = sigma_impute[j];\n",
    "        x_pred_use = x_naive_impute[, x_use_ind];\n",
    "        \n",
    "        //Make pred\n",
    "        xj_pred = x_pred_use * beta_x_pred + alpha_x_pred;\n",
    "        \n",
    "        \n",
    "        //observed = (x_is_missing[, j] == 0);\n",
    "        \n",
    "        // target +=  normal_lpdf(xj | xj_pred, sigma_x_pred);\n",
    "\n",
    "        for(i in 1:N) {\n",
    "            real mu_x_pred;\n",
    "            mu_x_pred = xj_pred[i];\n",
    "            if( x_is_missing[i,j] == 0) {\n",
    "                // if observed use pdf for observed value\n",
    "                target +=  normal_lpdf(xj[i] | mu_x_pred, sigma_x_pred);\n",
    "            } else {\n",
    "                // if censored, use normal CDF\n",
    "                target +=  normal_lcdf(threshold[j] | mu_x_pred, sigma_x_pred);\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "generated quantities {\n",
    "    real x_impute_mean[ N_miss ];\n",
    "    real x_impute[ N_miss ];\n",
    "\n",
    "    for(i in 1:N_miss) {\n",
    "        //These correspond to the rows and columns in the original data frame\n",
    "        int metab_row;\n",
    "        int metab_col;\n",
    "        row_vector[N_use_impute] x_pred_use;\n",
    "        vector[N_use_impute] beta_x_pred;\n",
    "        real alpha_x_pred;\n",
    "        int x_use_ind[N_use_impute];\n",
    "        real mu_x;\n",
    "        real sd_x;\n",
    "        real ub_x;\n",
    "\n",
    "        metab_row = x_missing[i,1];\n",
    "        metab_col = x_missing[i,2];\n",
    "        x_use_ind = x_use_impute[, metab_col ];\n",
    "        beta_x_pred = beta_impute[, metab_col ];\n",
    "        alpha_x_pred = alpha_impute[ metab_col ];\n",
    "        x_pred_use = x_naive_impute[metab_row, x_use_ind];\n",
    "\n",
    "        mu_x = x_pred_use * beta_x_pred + alpha_x_pred;\n",
    "        sd_x =  sigma_impute[ metab_col ];\n",
    "        ub_x = threshold[ metab_col ];\n",
    "        x_impute_mean[ i ] = mu_x;\n",
    "        x_impute[i] = normal_ub_rng(mu_x, sd_x, ub_x);\n",
    "    }\n",
    "}\n",
    "\n",
    "\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage_1_impute_code_file = 'stage_1_impute.stan'\n",
    "write_lines(x = stage_1_impute, path = stage_1_impute_code_file)\n",
    "stage_1_impute_model = stan_model(file = stage_1_impute_code_file, verbose = FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage_1_impute_get_init_vals = function(data) {\n",
    "    n_var = data$N_var\n",
    "    N_use_impute = data$N_use_impute\n",
    "    # matrix[ N_use_impute, N_var ] beta_impute_raw;\n",
    "    beta_impute_raw = matrix( rep(0, data$N_use_impute * n_var), ncol=n_var)\n",
    "    alpha_impute = rep(0,n_var)\n",
    "    x_use_impute = data$x_use_impute\n",
    "    sigma_impute = rep(1, n_var)\n",
    "    \n",
    "    for(i in 1:n_var) {\n",
    "        x_imp_vals_use = data$x_naive_impute[, x_use_impute[,i]   ]\n",
    "        y_out_imp = data$x_naive_impute[,i]\n",
    "        m_out = glm(y_out_imp ~ x_imp_vals_use,family=\"gaussian\")\n",
    "        coefs_imp = summary(m_out)$coef\n",
    "        alpha_impute[i] = coefs_imp[1,1]\n",
    "        for(k in 1:N_use_impute) {\n",
    "            beta_impute_raw[k,i] = coefs_imp[1 + k,1]\n",
    "        }\n",
    "        sigma_impute[i] = sum(m_out$residuals^2) / m_out$df.residual\n",
    "    }\n",
    "    \n",
    "    sigma_beta_impute_x = sqrt( sum( beta_impute_raw^2 ) / (prod(dim(beta_impute_raw)) - 1) ) \n",
    "    \n",
    "    inits = list(\n",
    "        sigma_impute = sigma_impute,\n",
    "        sigma_beta_impute_x = sigma_beta_impute_x,\n",
    "        alpha_impute = alpha_impute,\n",
    "        beta_impute_raw = beta_impute_raw / sigma_beta_impute_x\n",
    "    )\n",
    "    \n",
    "    inits\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage_1_impute_make_data = function(x_censored, y, threshold=NULL,\n",
    "                                         N_use_impute=8) {\n",
    "    \n",
    "    if(is.null(threshold)) {\n",
    "        threshold = apply(x_censored,MARGIN=2,FUN=function(x) { min(x,na.rm = T)})\n",
    "    }\n",
    "    \n",
    "    naive_impute_val = log( exp(threshold) / 2)\n",
    "    \n",
    "    n = dim(x_censored)[1]\n",
    "    N_var = dim(x_censored)[2]\n",
    "    N_miss = sum(is.na(x_censored))\n",
    "    \n",
    "    x_naive_impute = x_censored %>% select_all()\n",
    "    x_is_missing = apply( is.na(x_censored), FUN=as.numeric, MARGIN=c(1,2))             \n",
    "    for(j in 1:N_var) {\n",
    "        x_naive_impute[is.na(x_naive_impute[,j]),j] = naive_impute_val[j]\n",
    "    }            \n",
    "    # create a matrix that contains the N_use_impute indicies of the most correlated\n",
    "    # variables with the metabolite of interest\n",
    "    # each column contains a metabolite corresponding with x_censored\n",
    "    # each row corresponds to the index of the metabolite most correlated with it up to N_use_impute\n",
    "    # rows\n",
    "    var_cors = cor(x_naive_impute,use = \"complete\")\n",
    "    diag(var_cors) = 0\n",
    "    get_inds_to_use_per_metabolite = function(x) { which( rank(-abs(x)) <= N_use_impute)   }\n",
    "    x_use_impute = apply(var_cors,MARGIN=1,FUN=get_inds_to_use_per_metabolite )\n",
    "\n",
    "    x_censored[is.na(x_censored)] = missing_val\n",
    "\n",
    "    x_censored = as.matrix(x_censored)\n",
    "    x_missing = matrix(nrow = N_miss, ncol = 2)\n",
    "    x_missing_init = rep(0,N_miss)\n",
    "    x_missing_init_raw = rep(0,N_miss)\n",
    "    \n",
    "    # make a table were the first column is the row number in x_censored\n",
    "    # second column contains the metabolite column number in x_censored\n",
    "    col1 = c()\n",
    "    col2 = c()\n",
    "    for(j in 1:dim(x_censored)[2]) {\n",
    "        missing_in_col = which(x_censored[,j] == missing_val)\n",
    "        col1 = c(col1, missing_in_col)\n",
    "        col2 = c(col2, rep(j,length(missing_in_col)))\n",
    "    }\n",
    "    x_missing[,1] = col1\n",
    "    x_missing[,2] = col2\n",
    "    \n",
    "    if( N_miss > 0 ) {\n",
    "        # make a vector with naive imputation values\n",
    "        for(i in 1:dim(x_missing)[1]) {\n",
    "            row = x_missing[i,1]\n",
    "            col = x_missing[i,2]\n",
    "            x_missing_init[i] = x_naive_impute[row,col]\n",
    "            x_missing_init_raw[i] = x_missing_init[i] - threshold[col]\n",
    "        }\n",
    "    }\n",
    "\n",
    "    data = list(\n",
    "            N = n,\n",
    "            N_miss = N_miss,\n",
    "            N_var = N_var,\n",
    "            x_raw = x_censored,\n",
    "            x_naive_impute = as.matrix(x_naive_impute),\n",
    "            N_use_impute = N_use_impute,\n",
    "            x_use_impute = x_use_impute,\n",
    "            x_missing = x_missing,\n",
    "            x_missing_init = x_missing_init,\n",
    "            x_missing_init_raw = x_missing_init_raw,\n",
    "            x_is_missing = x_is_missing,\n",
    "            threshold = threshold,\n",
    "            y=y\n",
    "        )\n",
    "\n",
    "    #str(data)\n",
    "    #mean(x_censored == missing_val)\n",
    "    #data$N_miss / (data$N * data$N_var)\n",
    "\n",
    "    data   \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "replicate_init = function(init_data,chains=4) {\n",
    "    init = list()\n",
    "    for(i in 1:chains){\n",
    "        init[paste0(i)] = list(init_data)\n",
    "    }\n",
    "    init\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0"
      ],
      "text/latex": [
       "0"
      ],
      "text/markdown": [
       "0"
      ],
      "text/plain": [
       "[1] 0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of 13\n",
      " $ N                 : int 200\n",
      " $ N_miss            : int 0\n",
      " $ N_var             : int 27\n",
      " $ x_raw             : num [1:200, 1:27] -0.2539 0.1963 0.0995 1.0577 -0.5308 ...\n",
      "  ..- attr(*, \"dimnames\")=List of 2\n",
      "  .. ..$ : NULL\n",
      "  .. ..$ : chr [1:27] \"hydroxybutyrate\" \"oxoisocaproate\" \"X3.hydoxybutyrate\" \"alanine\" ...\n",
      " $ x_naive_impute    : num [1:200, 1:27] -0.2539 0.1963 0.0995 1.0577 -0.5308 ...\n",
      "  ..- attr(*, \"dimnames\")=List of 2\n",
      "  .. ..$ : NULL\n",
      "  .. ..$ : chr [1:27] \"hydroxybutyrate\" \"oxoisocaproate\" \"X3.hydoxybutyrate\" \"alanine\" ...\n",
      " $ N_use_impute      : num 8\n",
      " $ x_use_impute      : int [1:8, 1:27] 3 15 17 18 19 22 26 27 1 4 ...\n",
      "  ..- attr(*, \"dimnames\")=List of 2\n",
      "  .. ..$ : NULL\n",
      "  .. ..$ : chr [1:27] \"hydroxybutyrate\" \"oxoisocaproate\" \"X3.hydoxybutyrate\" \"alanine\" ...\n",
      " $ x_missing         : int[0 , 1:2] \n",
      " $ x_missing_init    : num(0) \n",
      " $ x_missing_init_raw: num(0) \n",
      " $ x_is_missing      : num [1:200, 1:27] 0 0 0 0 0 0 0 0 0 0 ...\n",
      "  ..- attr(*, \"dimnames\")=List of 2\n",
      "  .. ..$ : NULL\n",
      "  .. ..$ : chr [1:27] \"hydroxybutyrate\" \"oxoisocaproate\" \"X3.hydoxybutyrate\" \"alanine\" ...\n",
      " $ threshold         : Named num [1:27] -2.4 -2.11 -3.15 -2.4 -2.32 ...\n",
      "  ..- attr(*, \"names\")= chr [1:27] \"hydroxybutyrate\" \"oxoisocaproate\" \"X3.hydoxybutyrate\" \"alanine\" ...\n",
      " $ y                 : num [1:200] 0 0 0 0 0 0 0 0 0 0 ...\n"
     ]
    }
   ],
   "source": [
    "set.seed(0)\n",
    "n_0=100\n",
    "n_1=100\n",
    "beta_params = get_alpha_beta_for_target_rate(df_nmr,metabolites,TARGET_MISSING_RATE = 0.3)\n",
    "#out = make_df(n_0,mu_0,sigma_0,n_1,mu_1,sigma_1,frac_sig=0.4,censor=TRUE,\n",
    "#                  max_missing = 0.4, alpha = beta_params$alpha, beta=beta_params$beta)\n",
    "\n",
    "out = make_df(n_0,mu_0,sigma_0,n_1,mu_1,sigma_1,frac_sig=0.4,censor=FALSE,\n",
    "                  max_missing = 0.4, alpha = beta_params$alpha, beta=beta_params$beta)\n",
    "\n",
    "\n",
    "write_rds(out,'debug_df.rds')\n",
    "\n",
    "x_censored = out$df_censored[,metabolites]\n",
    "y=out$df_censored$died_90_day\n",
    "sum(is.na(x_censored))\n",
    "\n",
    "stage_1_data = stage_1_impute_make_data(x_censored, y, N_use_impute=8)\n",
    "stage_1_init_data = replicate_init(\n",
    "        stage_1_impute_get_init_vals(stage_1_data), chains=1\n",
    "    )\n",
    "str(stage_1_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SAMPLING FOR MODEL 'stage_1_impute' NOW (CHAIN 1).\n",
      "Chain 1: \n",
      "Chain 1: Gradient evaluation took 0 seconds\n",
      "Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\n",
      "Chain 1: Adjust your expectations accordingly!\n",
      "Chain 1: \n",
      "Chain 1: \n",
      "Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)\n",
      "Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)\n",
      "Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)\n",
      "Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)\n",
      "Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)\n",
      "Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)\n",
      "Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)\n",
      "Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)\n",
      "Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)\n",
      "Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)\n",
      "Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)\n",
      "Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)\n",
      "Chain 1: \n",
      "Chain 1:  Elapsed Time: 68.42 seconds (Warm-up)\n",
      "Chain 1:                45.1 seconds (Sampling)\n",
      "Chain 1:                113.52 seconds (Total)\n",
      "Chain 1: \n"
     ]
    }
   ],
   "source": [
    "stage_1_fit = sampling(stage_1_impute_model,  data = stage_1_data, init=stage_1_init_data, cores=1, chains=1, iter = 2000, control=list(adapt_delta=0.8))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A data.frame: 10 × 11</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>mean</th><th scope=col>se_mean</th><th scope=col>sd</th><th scope=col>X2.5.</th><th scope=col>X25.</th><th scope=col>X50.</th><th scope=col>X75.</th><th scope=col>X97.5.</th><th scope=col>n_eff</th><th scope=col>Rhat</th><th scope=col>PARAM</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>-5512.6520737</td><td>1.1956927349</td><td>16.06832048</td><td>-5.543797e+03</td><td>-5.523679e+03</td><td>-5513.1013050</td><td>-5501.2417105</td><td>-5480.7377332</td><td> 180.5934</td><td>0.9995295</td><td>lp__                 </td></tr>\n",
       "\t<tr><th scope=row>2</th><td>    0.1972392</td><td>0.0006506298</td><td> 0.01056270</td><td> 1.780939e-01</td><td> 1.895429e-01</td><td>    0.1964747</td><td>    0.2043881</td><td>    0.2188030</td><td> 263.5613</td><td>0.9991405</td><td>sigma_beta_impute_x  </td></tr>\n",
       "\t<tr><th scope=row>3</th><td>    3.6329327</td><td>0.0134496092</td><td> 0.27568563</td><td> 3.097374e+00</td><td> 3.445525e+00</td><td>    3.6250536</td><td>    3.8110687</td><td>    4.1945714</td><td> 420.1544</td><td>0.9991785</td><td>beta_impute_raw[7,16]</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>    4.3375261</td><td>0.0148969168</td><td> 0.31698955</td><td> 3.720797e+00</td><td> 4.117323e+00</td><td>    4.3296303</td><td>    4.5447819</td><td>    4.9611346</td><td> 452.7903</td><td>0.9990645</td><td>beta_impute_raw[7,25]</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>    3.3370878</td><td>0.0127093304</td><td> 0.28440287</td><td> 2.791659e+00</td><td> 3.141564e+00</td><td>    3.3299810</td><td>    3.5263381</td><td>    3.9184802</td><td> 500.7519</td><td>0.9997764</td><td>beta_impute_raw[8,17]</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>    3.4715000</td><td>0.0103898173</td><td> 0.31538750</td><td> 2.843631e+00</td><td> 3.245802e+00</td><td>    3.4727668</td><td>    3.6934118</td><td>    4.0503065</td><td> 921.4529</td><td>0.9993288</td><td>beta_impute_raw[5,27]</td></tr>\n",
       "\t<tr><th scope=row>7</th><td>    1.4982265</td><td>0.0069840063</td><td> 0.22234685</td><td> 1.061910e+00</td><td> 1.343338e+00</td><td>    1.5059335</td><td>    1.6490110</td><td>    1.9177824</td><td>1013.5676</td><td>0.9995534</td><td>beta_impute_raw[4,4] </td></tr>\n",
       "\t<tr><th scope=row>8</th><td>    0.5832399</td><td>0.0092835255</td><td> 0.30322833</td><td> 2.510396e-02</td><td> 3.715368e-01</td><td>    0.5748025</td><td>    0.7738567</td><td>    1.2013517</td><td>1066.8754</td><td>0.9990317</td><td>beta_impute_raw[6,4] </td></tr>\n",
       "\t<tr><th scope=row>9</th><td>    0.1147143</td><td>0.0017639371</td><td> 0.05902539</td><td> 5.266292e-03</td><td> 7.296193e-02</td><td>    0.1127369</td><td>    0.1549204</td><td>    0.2334397</td><td>1119.7256</td><td>0.9990989</td><td>beta_impute[6,4]     </td></tr>\n",
       "\t<tr><th scope=row>10</th><td>   -0.1129056</td><td>0.0156587304</td><td> 0.52932891</td><td>-1.186984e+00</td><td>-4.662099e-01</td><td>   -0.0950578</td><td>    0.2401523</td><td>    0.9438383</td><td>1142.7156</td><td>0.9990009</td><td>beta_impute_raw[4,14]</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 10 × 11\n",
       "\\begin{tabular}{r|lllllllllll}\n",
       "  & mean & se\\_mean & sd & X2.5. & X25. & X50. & X75. & X97.5. & n\\_eff & Rhat & PARAM\\\\\n",
       "  & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <chr>\\\\\n",
       "\\hline\n",
       "\t1 & -5512.6520737 & 1.1956927349 & 16.06832048 & -5.543797e+03 & -5.523679e+03 & -5513.1013050 & -5501.2417105 & -5480.7377332 &  180.5934 & 0.9995295 & lp\\_\\_                 \\\\\n",
       "\t2 &     0.1972392 & 0.0006506298 &  0.01056270 &  1.780939e-01 &  1.895429e-01 &     0.1964747 &     0.2043881 &     0.2188030 &  263.5613 & 0.9991405 & sigma\\_beta\\_impute\\_x  \\\\\n",
       "\t3 &     3.6329327 & 0.0134496092 &  0.27568563 &  3.097374e+00 &  3.445525e+00 &     3.6250536 &     3.8110687 &     4.1945714 &  420.1544 & 0.9991785 & beta\\_impute\\_raw{[}7,16{]}\\\\\n",
       "\t4 &     4.3375261 & 0.0148969168 &  0.31698955 &  3.720797e+00 &  4.117323e+00 &     4.3296303 &     4.5447819 &     4.9611346 &  452.7903 & 0.9990645 & beta\\_impute\\_raw{[}7,25{]}\\\\\n",
       "\t5 &     3.3370878 & 0.0127093304 &  0.28440287 &  2.791659e+00 &  3.141564e+00 &     3.3299810 &     3.5263381 &     3.9184802 &  500.7519 & 0.9997764 & beta\\_impute\\_raw{[}8,17{]}\\\\\n",
       "\t6 &     3.4715000 & 0.0103898173 &  0.31538750 &  2.843631e+00 &  3.245802e+00 &     3.4727668 &     3.6934118 &     4.0503065 &  921.4529 & 0.9993288 & beta\\_impute\\_raw{[}5,27{]}\\\\\n",
       "\t7 &     1.4982265 & 0.0069840063 &  0.22234685 &  1.061910e+00 &  1.343338e+00 &     1.5059335 &     1.6490110 &     1.9177824 & 1013.5676 & 0.9995534 & beta\\_impute\\_raw{[}4,4{]} \\\\\n",
       "\t8 &     0.5832399 & 0.0092835255 &  0.30322833 &  2.510396e-02 &  3.715368e-01 &     0.5748025 &     0.7738567 &     1.2013517 & 1066.8754 & 0.9990317 & beta\\_impute\\_raw{[}6,4{]} \\\\\n",
       "\t9 &     0.1147143 & 0.0017639371 &  0.05902539 &  5.266292e-03 &  7.296193e-02 &     0.1127369 &     0.1549204 &     0.2334397 & 1119.7256 & 0.9990989 & beta\\_impute{[}6,4{]}     \\\\\n",
       "\t10 &    -0.1129056 & 0.0156587304 &  0.52932891 & -1.186984e+00 & -4.662099e-01 &    -0.0950578 &     0.2401523 &     0.9438383 & 1142.7156 & 0.9990009 & beta\\_impute\\_raw{[}4,14{]}\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 10 × 11\n",
       "\n",
       "| <!--/--> | mean &lt;dbl&gt; | se_mean &lt;dbl&gt; | sd &lt;dbl&gt; | X2.5. &lt;dbl&gt; | X25. &lt;dbl&gt; | X50. &lt;dbl&gt; | X75. &lt;dbl&gt; | X97.5. &lt;dbl&gt; | n_eff &lt;dbl&gt; | Rhat &lt;dbl&gt; | PARAM &lt;chr&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 1 | -5512.6520737 | 1.1956927349 | 16.06832048 | -5.543797e+03 | -5.523679e+03 | -5513.1013050 | -5501.2417105 | -5480.7377332 |  180.5934 | 0.9995295 | lp__                  |\n",
       "| 2 |     0.1972392 | 0.0006506298 |  0.01056270 |  1.780939e-01 |  1.895429e-01 |     0.1964747 |     0.2043881 |     0.2188030 |  263.5613 | 0.9991405 | sigma_beta_impute_x   |\n",
       "| 3 |     3.6329327 | 0.0134496092 |  0.27568563 |  3.097374e+00 |  3.445525e+00 |     3.6250536 |     3.8110687 |     4.1945714 |  420.1544 | 0.9991785 | beta_impute_raw[7,16] |\n",
       "| 4 |     4.3375261 | 0.0148969168 |  0.31698955 |  3.720797e+00 |  4.117323e+00 |     4.3296303 |     4.5447819 |     4.9611346 |  452.7903 | 0.9990645 | beta_impute_raw[7,25] |\n",
       "| 5 |     3.3370878 | 0.0127093304 |  0.28440287 |  2.791659e+00 |  3.141564e+00 |     3.3299810 |     3.5263381 |     3.9184802 |  500.7519 | 0.9997764 | beta_impute_raw[8,17] |\n",
       "| 6 |     3.4715000 | 0.0103898173 |  0.31538750 |  2.843631e+00 |  3.245802e+00 |     3.4727668 |     3.6934118 |     4.0503065 |  921.4529 | 0.9993288 | beta_impute_raw[5,27] |\n",
       "| 7 |     1.4982265 | 0.0069840063 |  0.22234685 |  1.061910e+00 |  1.343338e+00 |     1.5059335 |     1.6490110 |     1.9177824 | 1013.5676 | 0.9995534 | beta_impute_raw[4,4]  |\n",
       "| 8 |     0.5832399 | 0.0092835255 |  0.30322833 |  2.510396e-02 |  3.715368e-01 |     0.5748025 |     0.7738567 |     1.2013517 | 1066.8754 | 0.9990317 | beta_impute_raw[6,4]  |\n",
       "| 9 |     0.1147143 | 0.0017639371 |  0.05902539 |  5.266292e-03 |  7.296193e-02 |     0.1127369 |     0.1549204 |     0.2334397 | 1119.7256 | 0.9990989 | beta_impute[6,4]      |\n",
       "| 10 |    -0.1129056 | 0.0156587304 |  0.52932891 | -1.186984e+00 | -4.662099e-01 |    -0.0950578 |     0.2401523 |     0.9438383 | 1142.7156 | 0.9990009 | beta_impute_raw[4,14] |\n",
       "\n"
      ],
      "text/plain": [
       "   mean          se_mean      sd          X2.5.         X25.         \n",
       "1  -5512.6520737 1.1956927349 16.06832048 -5.543797e+03 -5.523679e+03\n",
       "2      0.1972392 0.0006506298  0.01056270  1.780939e-01  1.895429e-01\n",
       "3      3.6329327 0.0134496092  0.27568563  3.097374e+00  3.445525e+00\n",
       "4      4.3375261 0.0148969168  0.31698955  3.720797e+00  4.117323e+00\n",
       "5      3.3370878 0.0127093304  0.28440287  2.791659e+00  3.141564e+00\n",
       "6      3.4715000 0.0103898173  0.31538750  2.843631e+00  3.245802e+00\n",
       "7      1.4982265 0.0069840063  0.22234685  1.061910e+00  1.343338e+00\n",
       "8      0.5832399 0.0092835255  0.30322833  2.510396e-02  3.715368e-01\n",
       "9      0.1147143 0.0017639371  0.05902539  5.266292e-03  7.296193e-02\n",
       "10    -0.1129056 0.0156587304  0.52932891 -1.186984e+00 -4.662099e-01\n",
       "   X50.          X75.          X97.5.        n_eff     Rhat     \n",
       "1  -5513.1013050 -5501.2417105 -5480.7377332  180.5934 0.9995295\n",
       "2      0.1964747     0.2043881     0.2188030  263.5613 0.9991405\n",
       "3      3.6250536     3.8110687     4.1945714  420.1544 0.9991785\n",
       "4      4.3296303     4.5447819     4.9611346  452.7903 0.9990645\n",
       "5      3.3299810     3.5263381     3.9184802  500.7519 0.9997764\n",
       "6      3.4727668     3.6934118     4.0503065  921.4529 0.9993288\n",
       "7      1.5059335     1.6490110     1.9177824 1013.5676 0.9995534\n",
       "8      0.5748025     0.7738567     1.2013517 1066.8754 0.9990317\n",
       "9      0.1127369     0.1549204     0.2334397 1119.7256 0.9990989\n",
       "10    -0.0950578     0.2401523     0.9438383 1142.7156 0.9990009\n",
       "   PARAM                \n",
       "1  lp__                 \n",
       "2  sigma_beta_impute_x  \n",
       "3  beta_impute_raw[7,16]\n",
       "4  beta_impute_raw[7,25]\n",
       "5  beta_impute_raw[8,17]\n",
       "6  beta_impute_raw[5,27]\n",
       "7  beta_impute_raw[4,4] \n",
       "8  beta_impute_raw[6,4] \n",
       "9  beta_impute[6,4]     \n",
       "10 beta_impute_raw[4,14]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A data.frame: 10 × 11</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>mean</th><th scope=col>se_mean</th><th scope=col>sd</th><th scope=col>X2.5.</th><th scope=col>X25.</th><th scope=col>X50.</th><th scope=col>X75.</th><th scope=col>X97.5.</th><th scope=col>n_eff</th><th scope=col>Rhat</th><th scope=col>PARAM</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td> 0.51640867</td><td>0.011842587</td><td>0.41118668</td><td>-0.30030119</td><td> 0.25400458</td><td> 0.48908695</td><td>0.787742967</td><td>1.36391972</td><td>1205.549</td><td>1.003561</td><td>beta_impute_raw[3,21]</td></tr>\n",
       "\t<tr><th scope=row>2</th><td> 0.23161804</td><td>0.001574323</td><td>0.07256845</td><td> 0.08728896</td><td> 0.18406437</td><td> 0.23234613</td><td>0.278254824</td><td>0.37151915</td><td>2124.750</td><td>1.003547</td><td>beta_impute[1,9]     </td></tr>\n",
       "\t<tr><th scope=row>3</th><td> 0.10170174</td><td>0.002306241</td><td>0.08079381</td><td>-0.05972333</td><td> 0.04961109</td><td> 0.09612933</td><td>0.154734287</td><td>0.26551895</td><td>1227.289</td><td>1.003540</td><td>beta_impute[3,21]    </td></tr>\n",
       "\t<tr><th scope=row>4</th><td>-0.22552211</td><td>0.009534655</td><td>0.38590639</td><td>-0.98936137</td><td>-0.48054038</td><td>-0.23625986</td><td>0.036739931</td><td>0.49465571</td><td>1638.151</td><td>1.003409</td><td>beta_impute_raw[6,21]</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>-0.04452559</td><td>0.001859412</td><td>0.07585322</td><td>-0.19545827</td><td>-0.09451529</td><td>-0.04647340</td><td>0.007485014</td><td>0.09729545</td><td>1664.167</td><td>1.003375</td><td>beta_impute[6,21]    </td></tr>\n",
       "\t<tr><th scope=row>6</th><td> 1.17621741</td><td>0.008417771</td><td>0.36959853</td><td> 0.44055025</td><td> 0.92927941</td><td> 1.17041269</td><td>1.418843823</td><td>1.93140420</td><td>1927.819</td><td>1.002851</td><td>beta_impute_raw[1,9] </td></tr>\n",
       "\t<tr><th scope=row>7</th><td>-0.11382482</td><td>0.006487158</td><td>0.28030502</td><td>-0.68483057</td><td>-0.29978539</td><td>-0.10539689</td><td>0.056003849</td><td>0.42525222</td><td>1867.037</td><td>1.002350</td><td>beta_impute_raw[4,16]</td></tr>\n",
       "\t<tr><th scope=row>8</th><td>-0.02235305</td><td>0.001294869</td><td>0.05498725</td><td>-0.13486865</td><td>-0.05828562</td><td>-0.02075392</td><td>0.011042828</td><td>0.08294994</td><td>1803.319</td><td>1.002322</td><td>beta_impute[4,16]    </td></tr>\n",
       "\t<tr><th scope=row>9</th><td> 0.79403343</td><td>0.008869983</td><td>0.38462335</td><td> 0.06309948</td><td> 0.53065739</td><td> 0.77645881</td><td>1.070965202</td><td>1.53488170</td><td>1880.294</td><td>1.002314</td><td>beta_impute_raw[5,24]</td></tr>\n",
       "\t<tr><th scope=row>10</th><td> 0.15631027</td><td>0.001733084</td><td>0.07548701</td><td> 0.01226579</td><td> 0.10401610</td><td> 0.15343741</td><td>0.209077144</td><td>0.30224898</td><td>1897.165</td><td>1.002114</td><td>beta_impute[5,24]    </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 10 × 11\n",
       "\\begin{tabular}{r|lllllllllll}\n",
       "  & mean & se\\_mean & sd & X2.5. & X25. & X50. & X75. & X97.5. & n\\_eff & Rhat & PARAM\\\\\n",
       "  & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <chr>\\\\\n",
       "\\hline\n",
       "\t1 &  0.51640867 & 0.011842587 & 0.41118668 & -0.30030119 &  0.25400458 &  0.48908695 & 0.787742967 & 1.36391972 & 1205.549 & 1.003561 & beta\\_impute\\_raw{[}3,21{]}\\\\\n",
       "\t2 &  0.23161804 & 0.001574323 & 0.07256845 &  0.08728896 &  0.18406437 &  0.23234613 & 0.278254824 & 0.37151915 & 2124.750 & 1.003547 & beta\\_impute{[}1,9{]}     \\\\\n",
       "\t3 &  0.10170174 & 0.002306241 & 0.08079381 & -0.05972333 &  0.04961109 &  0.09612933 & 0.154734287 & 0.26551895 & 1227.289 & 1.003540 & beta\\_impute{[}3,21{]}    \\\\\n",
       "\t4 & -0.22552211 & 0.009534655 & 0.38590639 & -0.98936137 & -0.48054038 & -0.23625986 & 0.036739931 & 0.49465571 & 1638.151 & 1.003409 & beta\\_impute\\_raw{[}6,21{]}\\\\\n",
       "\t5 & -0.04452559 & 0.001859412 & 0.07585322 & -0.19545827 & -0.09451529 & -0.04647340 & 0.007485014 & 0.09729545 & 1664.167 & 1.003375 & beta\\_impute{[}6,21{]}    \\\\\n",
       "\t6 &  1.17621741 & 0.008417771 & 0.36959853 &  0.44055025 &  0.92927941 &  1.17041269 & 1.418843823 & 1.93140420 & 1927.819 & 1.002851 & beta\\_impute\\_raw{[}1,9{]} \\\\\n",
       "\t7 & -0.11382482 & 0.006487158 & 0.28030502 & -0.68483057 & -0.29978539 & -0.10539689 & 0.056003849 & 0.42525222 & 1867.037 & 1.002350 & beta\\_impute\\_raw{[}4,16{]}\\\\\n",
       "\t8 & -0.02235305 & 0.001294869 & 0.05498725 & -0.13486865 & -0.05828562 & -0.02075392 & 0.011042828 & 0.08294994 & 1803.319 & 1.002322 & beta\\_impute{[}4,16{]}    \\\\\n",
       "\t9 &  0.79403343 & 0.008869983 & 0.38462335 &  0.06309948 &  0.53065739 &  0.77645881 & 1.070965202 & 1.53488170 & 1880.294 & 1.002314 & beta\\_impute\\_raw{[}5,24{]}\\\\\n",
       "\t10 &  0.15631027 & 0.001733084 & 0.07548701 &  0.01226579 &  0.10401610 &  0.15343741 & 0.209077144 & 0.30224898 & 1897.165 & 1.002114 & beta\\_impute{[}5,24{]}    \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 10 × 11\n",
       "\n",
       "| <!--/--> | mean &lt;dbl&gt; | se_mean &lt;dbl&gt; | sd &lt;dbl&gt; | X2.5. &lt;dbl&gt; | X25. &lt;dbl&gt; | X50. &lt;dbl&gt; | X75. &lt;dbl&gt; | X97.5. &lt;dbl&gt; | n_eff &lt;dbl&gt; | Rhat &lt;dbl&gt; | PARAM &lt;chr&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 1 |  0.51640867 | 0.011842587 | 0.41118668 | -0.30030119 |  0.25400458 |  0.48908695 | 0.787742967 | 1.36391972 | 1205.549 | 1.003561 | beta_impute_raw[3,21] |\n",
       "| 2 |  0.23161804 | 0.001574323 | 0.07256845 |  0.08728896 |  0.18406437 |  0.23234613 | 0.278254824 | 0.37151915 | 2124.750 | 1.003547 | beta_impute[1,9]      |\n",
       "| 3 |  0.10170174 | 0.002306241 | 0.08079381 | -0.05972333 |  0.04961109 |  0.09612933 | 0.154734287 | 0.26551895 | 1227.289 | 1.003540 | beta_impute[3,21]     |\n",
       "| 4 | -0.22552211 | 0.009534655 | 0.38590639 | -0.98936137 | -0.48054038 | -0.23625986 | 0.036739931 | 0.49465571 | 1638.151 | 1.003409 | beta_impute_raw[6,21] |\n",
       "| 5 | -0.04452559 | 0.001859412 | 0.07585322 | -0.19545827 | -0.09451529 | -0.04647340 | 0.007485014 | 0.09729545 | 1664.167 | 1.003375 | beta_impute[6,21]     |\n",
       "| 6 |  1.17621741 | 0.008417771 | 0.36959853 |  0.44055025 |  0.92927941 |  1.17041269 | 1.418843823 | 1.93140420 | 1927.819 | 1.002851 | beta_impute_raw[1,9]  |\n",
       "| 7 | -0.11382482 | 0.006487158 | 0.28030502 | -0.68483057 | -0.29978539 | -0.10539689 | 0.056003849 | 0.42525222 | 1867.037 | 1.002350 | beta_impute_raw[4,16] |\n",
       "| 8 | -0.02235305 | 0.001294869 | 0.05498725 | -0.13486865 | -0.05828562 | -0.02075392 | 0.011042828 | 0.08294994 | 1803.319 | 1.002322 | beta_impute[4,16]     |\n",
       "| 9 |  0.79403343 | 0.008869983 | 0.38462335 |  0.06309948 |  0.53065739 |  0.77645881 | 1.070965202 | 1.53488170 | 1880.294 | 1.002314 | beta_impute_raw[5,24] |\n",
       "| 10 |  0.15631027 | 0.001733084 | 0.07548701 |  0.01226579 |  0.10401610 |  0.15343741 | 0.209077144 | 0.30224898 | 1897.165 | 1.002114 | beta_impute[5,24]     |\n",
       "\n"
      ],
      "text/plain": [
       "   mean        se_mean     sd         X2.5.       X25.        X50.       \n",
       "1   0.51640867 0.011842587 0.41118668 -0.30030119  0.25400458  0.48908695\n",
       "2   0.23161804 0.001574323 0.07256845  0.08728896  0.18406437  0.23234613\n",
       "3   0.10170174 0.002306241 0.08079381 -0.05972333  0.04961109  0.09612933\n",
       "4  -0.22552211 0.009534655 0.38590639 -0.98936137 -0.48054038 -0.23625986\n",
       "5  -0.04452559 0.001859412 0.07585322 -0.19545827 -0.09451529 -0.04647340\n",
       "6   1.17621741 0.008417771 0.36959853  0.44055025  0.92927941  1.17041269\n",
       "7  -0.11382482 0.006487158 0.28030502 -0.68483057 -0.29978539 -0.10539689\n",
       "8  -0.02235305 0.001294869 0.05498725 -0.13486865 -0.05828562 -0.02075392\n",
       "9   0.79403343 0.008869983 0.38462335  0.06309948  0.53065739  0.77645881\n",
       "10  0.15631027 0.001733084 0.07548701  0.01226579  0.10401610  0.15343741\n",
       "   X75.        X97.5.     n_eff    Rhat     PARAM                \n",
       "1  0.787742967 1.36391972 1205.549 1.003561 beta_impute_raw[3,21]\n",
       "2  0.278254824 0.37151915 2124.750 1.003547 beta_impute[1,9]     \n",
       "3  0.154734287 0.26551895 1227.289 1.003540 beta_impute[3,21]    \n",
       "4  0.036739931 0.49465571 1638.151 1.003409 beta_impute_raw[6,21]\n",
       "5  0.007485014 0.09729545 1664.167 1.003375 beta_impute[6,21]    \n",
       "6  1.418843823 1.93140420 1927.819 1.002851 beta_impute_raw[1,9] \n",
       "7  0.056003849 0.42525222 1867.037 1.002350 beta_impute_raw[4,16]\n",
       "8  0.011042828 0.08294994 1803.319 1.002322 beta_impute[4,16]    \n",
       "9  1.070965202 1.53488170 1880.294 1.002314 beta_impute_raw[5,24]\n",
       "10 0.209077144 0.30224898 1897.165 1.002114 beta_impute[5,24]    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_sum = data.frame(summary(stage_1_fit)$summary) \n",
    "df_sum$PARAM = rownames(summary(stage_1_fit)$summary)\n",
    "df_sum %>% arrange(n_eff) %>% head(10)\n",
    "df_sum %>% arrange(-abs(Rhat)) %>% head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 2 regression code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage_2_regress = \"\n",
    "data {\n",
    "    int<lower=0> N;\n",
    "    int<lower=0> N_var;\n",
    "    int<lower=0> N_miss;\n",
    "\n",
    "    matrix[ N, N_var ] x_raw;\n",
    "\n",
    "    int<lower=0,upper=1> y[N];\n",
    "\n",
    "    //Threshold for imputation\n",
    "    //Separate threshold per metabolite\n",
    "    vector[N_var] threshold;\n",
    "    \n",
    "    // This vector contains the missing row index, column index\n",
    "    int x_missing[ N_miss, 2 ];\n",
    "    real x_missing_mean[ N_miss ];\n",
    "    real x_missing_sd[ N_miss ];\n",
    "    real<lower=0> sigma_beta_x_lower_bound;\n",
    "}\n",
    "parameters {\n",
    "    // Needed for imputation\n",
    "    vector<upper=0>[ N_miss ] x_impute_raw;\n",
    "    \n",
    "    //regression on y per metabolite in x_raw columns\n",
    "    vector[N_var] beta_x;\n",
    "    vector[N_var] alpha_x;\n",
    "\n",
    "    real<lower=sigma_beta_x_lower_bound> sigma_beta_x;\n",
    "    real<lower=1> nu_x;\n",
    "\n",
    "}\n",
    "transformed parameters {\n",
    "    // https://mc-stan.org/docs/2_18/stan-users-guide/vectors-with-varying-bounds.html\n",
    "    vector<upper=0>[ N_miss ] x_impute;\n",
    "    x_impute = x_impute_raw;\n",
    "    for(i in 1:N_miss) {\n",
    "        int metab_row = x_missing[i,1];\n",
    "        int metab_col = x_missing[i,2];\n",
    "        x_impute[i] = x_impute[i] + threshold[metab_col];\n",
    "    }\n",
    "\n",
    "}\n",
    "model {\n",
    "    matrix[N, N_var] x_merge;\n",
    "    //copy matrix\n",
    "    x_merge = x_raw;\n",
    "    \n",
    "    //fill in the values we are going to impute\n",
    "    for(i in 1:N_miss) {\n",
    "        int metab_row = x_missing[i,1];\n",
    "        int metab_col = x_missing[i,2];\n",
    "        x_merge[metab_row,metab_col] = x_impute[ i ];\n",
    "    }\n",
    "    \n",
    "    x_impute ~ normal(x_missing_mean, x_missing_sd);\n",
    "    \n",
    "    sigma_beta_x ~ cauchy(0,1);\n",
    "    nu_x ~ gamma(2,0.1);\n",
    "    beta_x ~  student_t(nu_x,0,sigma_beta_x);\n",
    "    alpha_x ~ normal(0,5);\n",
    "    \n",
    "    for(j in 1:N_var) {\n",
    "        vector[N] x_col = x_merge[ , j];\n",
    "        real beta = beta_x[j];\n",
    "        real alpha = alpha_x[j];\n",
    "        y ~ bernoulli_logit(alpha + beta * x_col);\n",
    "    }\n",
    "}\n",
    "\n",
    "\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DIAGNOSTIC(S) FROM PARSER:\n",
      "Info:\n",
      "Left-hand side of sampling statement (~) may contain a non-linear transform of a parameter or local variable.\n",
      "If it does, you need to include a target += statement with the log absolute determinant of the Jacobian of the transform.\n",
      "Left-hand-side of sampling statement:\n",
      "    x_impute ~ normal(...)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stage_2_regress_code_file = 'stage_2_regress.stan'\n",
    "write_lines(x = stage_2_regress, path = stage_2_regress_code_file)\n",
    "stage_2_regress_model = stan_model(file = stage_2_regress_code_file, verbose = FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# This function formats the data for\n",
    "###\n",
    "\n",
    "default_impute = function(x_censored, x_missing) {\n",
    "    N_miss = dim(x_missing)[1]\n",
    "    #print(N_miss)\n",
    "    x_missing_mean = rep(0,N_miss)\n",
    "    x_missing_sd = rep(1,N_miss)\n",
    "    \n",
    "    list(\n",
    "         x_missing_mean=x_missing_mean,\n",
    "         x_missing_sd=x_missing_sd\n",
    "        )\n",
    "}\n",
    "\n",
    "stage_2_regress_make_data = function(x_censored, y, IMPUTE_FUNC=default_impute, threshold=NULL, sigma_beta_x_lower_bound=0.1, ...) {\n",
    "    \n",
    "    if(is.null(threshold)) {\n",
    "        threshold = apply(x_censored,MARGIN=2,FUN=function(x) { min(x,na.rm = T)})\n",
    "    }\n",
    "    \n",
    "    naive_impute_val = log( exp(threshold) / 2)\n",
    "    \n",
    "    n = dim(x_censored)[1]\n",
    "    N_var = dim(x_censored)[2]\n",
    "    N_miss = sum(is.na(x_censored))\n",
    "    \n",
    "    x_naive_impute = x_censored %>% select_all()\n",
    "                 \n",
    "    for(j in 1:N_var) {\n",
    "        x_naive_impute[is.na(x_naive_impute[,j]),j] = naive_impute_val[j]\n",
    "    }            \n",
    "\n",
    "\n",
    "    x_censored[is.na(x_censored)] = missing_val\n",
    "\n",
    "    x_censored = as.matrix(x_censored)\n",
    "    x_missing = matrix(nrow = N_miss, ncol = 2)\n",
    "    x_missing_init = rep(0,N_miss)\n",
    "    x_missing_init_raw = rep(0,N_miss)\n",
    "    x_missing_mean = rep(0,N_miss)\n",
    "    x_missing_sd = rep(1,N_miss)\n",
    "    \n",
    "    # make a table were the first column is the row number in x_censored\n",
    "    # second column contains the metabolite column number in x_censored\n",
    "    col1 = c()\n",
    "    col2 = c()\n",
    "    for(j in 1:dim(x_censored)[2]) {\n",
    "        missing_in_col = which(x_censored[,j] == missing_val)\n",
    "        col1 = c(col1, missing_in_col)\n",
    "        col2 = c(col2, rep(j,length(missing_in_col)))\n",
    "    }\n",
    "    x_missing[,1] = col1\n",
    "    x_missing[,2] = col2\n",
    "    \n",
    "    # make a vector with naive imputation values\n",
    "    if( N_miss > 0 ) {\n",
    "        for(i in 1:dim(x_missing)[1]) {\n",
    "            row = x_missing[i,1]\n",
    "            col = x_missing[i,2]\n",
    "            x_missing_init[i] = x_naive_impute[row,col]\n",
    "            x_missing_init_raw[i] = x_missing_init[i] - threshold[col]\n",
    "        }\n",
    "    \n",
    "        mean_sds = IMPUTE_FUNC(x_censored,x_missing,...)\n",
    "        x_missing_mean = mean_sds$x_missing_mean\n",
    "        x_missing_sd = mean_sds$x_missing_sd\n",
    "    }\n",
    "    \n",
    "    data = list(\n",
    "            N = n,\n",
    "            N_miss = N_miss,\n",
    "            N_var = N_var,\n",
    "            x_raw = x_censored,\n",
    "            x_naive_impute = as.matrix(x_naive_impute),\n",
    "            x_missing = x_missing,\n",
    "            x_missing_init = x_missing_init,\n",
    "            x_missing_init_raw = x_missing_init_raw,\n",
    "            x_missing_mean=x_missing_mean,\n",
    "            x_missing_sd=x_missing_sd,\n",
    "            threshold = threshold,\n",
    "            y=y,\n",
    "            sigma_beta_x_lower_bound=sigma_beta_x_lower_bound\n",
    "        )\n",
    "\n",
    "    #str(data)\n",
    "    #mean(x_censored == missing_val)\n",
    "    #data$N_miss / (data$N * data$N_var)\n",
    "\n",
    "    data   \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage_1_impute = function(x_censored, x_missing, stage_1_post=NULL) {\n",
    "    N_miss = dim(x_missing)[1]\n",
    "    print(N_miss)\n",
    "    x_missing_mean = apply( stage_1_post$x_impute_mean, FUN=mean, MARGIN=2 )\n",
    "    x_missing_sd = apply( stage_1_post$x_impute, FUN=sd, MARGIN=2 )\n",
    "            \n",
    "    list(\n",
    "         x_missing_mean=x_missing_mean,\n",
    "         x_missing_sd=x_missing_sd\n",
    "        )\n",
    "}\n",
    "\n",
    "fancy_impute = function(x_censored, x_missing) {\n",
    "    N_miss = dim(x_missing)[1]\n",
    "    #print(N_miss)\n",
    "    x_missing_mean = rep(0,N_miss)\n",
    "    x_missing_sd = rep(1,N_miss)\n",
    "    \n",
    "    \n",
    "    x_obs = out$df_sample[,metabolites]\n",
    "    for(i in 1:N_miss) {\n",
    "        row = x_missing[i,1]\n",
    "        col = x_missing[i,2]\n",
    "        x_missing_mean[i] = x_obs[row,col]\n",
    "        x_missing_sd[i] = 0.001\n",
    "    }\n",
    "            \n",
    "    list(\n",
    "         x_missing_mean=x_missing_mean,\n",
    "         x_missing_sd=x_missing_sd\n",
    "        )\n",
    "}\n",
    "\n",
    "stage_1_post = extract(stage_1_fit)\n",
    "stage_2_data = stage_2_regress_make_data(x_censored, y, IMPUTE_FUNC = stage_1_impute, stage_1_post=stage_1_post)\n",
    "#stage_2_init = list(\n",
    "#    x_impute_raw = stage_2_data$x_missing_init_raw\n",
    "#)\n",
    "\n",
    "\n",
    "stage_2_init = replicate_init(\n",
    "    list(\n",
    "        x_impute_raw = stage_2_data$x_missing_init_raw\n",
    "    ), chains=4\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of 13\n",
      " $ N                       : int 200\n",
      " $ N_miss                  : int 0\n",
      " $ N_var                   : int 27\n",
      " $ x_raw                   : num [1:200, 1:27] -0.2539 0.1963 0.0995 1.0577 -0.5308 ...\n",
      "  ..- attr(*, \"dimnames\")=List of 2\n",
      "  .. ..$ : NULL\n",
      "  .. ..$ : chr [1:27] \"hydroxybutyrate\" \"oxoisocaproate\" \"X3.hydoxybutyrate\" \"alanine\" ...\n",
      " $ x_naive_impute          : num [1:200, 1:27] -0.2539 0.1963 0.0995 1.0577 -0.5308 ...\n",
      "  ..- attr(*, \"dimnames\")=List of 2\n",
      "  .. ..$ : NULL\n",
      "  .. ..$ : chr [1:27] \"hydroxybutyrate\" \"oxoisocaproate\" \"X3.hydoxybutyrate\" \"alanine\" ...\n",
      " $ x_missing               : int[0 , 1:2] \n",
      " $ x_missing_init          : num(0) \n",
      " $ x_missing_init_raw      : num(0) \n",
      " $ x_missing_mean          : num(0) \n",
      " $ x_missing_sd            : num(0) \n",
      " $ threshold               : Named num [1:27] -2.4 -2.11 -3.15 -2.4 -2.32 ...\n",
      "  ..- attr(*, \"names\")= chr [1:27] \"hydroxybutyrate\" \"oxoisocaproate\" \"X3.hydoxybutyrate\" \"alanine\" ...\n",
      " $ y                       : num [1:200] 0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ sigma_beta_x_lower_bound: num 0.1\n",
      "List of 4\n",
      " $ 1:List of 1\n",
      "  ..$ x_impute_raw: num(0) \n",
      " $ 2:List of 1\n",
      "  ..$ x_impute_raw: num(0) \n",
      " $ 3:List of 1\n",
      "  ..$ x_impute_raw: num(0) \n",
      " $ 4:List of 1\n",
      "  ..$ x_impute_raw: num(0) \n"
     ]
    }
   ],
   "source": [
    "str(stage_2_data)\n",
    "str(stage_2_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0"
      ],
      "text/latex": [
       "0"
      ],
      "text/markdown": [
       "0"
      ],
      "text/plain": [
       "[1] 0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/latex": [],
      "text/markdown": [],
      "text/plain": [
       "numeric(0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/latex": [],
      "text/markdown": [],
      "text/plain": [
       "numeric(0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>&lt;NA&gt;</li><li>&lt;NA&gt;</li><li>&lt;NA&gt;</li><li>&lt;NA&gt;</li><li>&lt;NA&gt;</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item <NA>\n",
       "\\item <NA>\n",
       "\\item <NA>\n",
       "\\item <NA>\n",
       "\\item <NA>\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. &lt;NA&gt;\n",
       "2. &lt;NA&gt;\n",
       "3. &lt;NA&gt;\n",
       "4. &lt;NA&gt;\n",
       "5. &lt;NA&gt;\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] NA NA NA NA NA"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#stage_2_data$threshold\n",
    "sum(apply(x_censored,FUN=function(x) { sum(is.na(x))},MARGIN=2))\n",
    "x_censored[ stage_2_data$x_missing %>% head ]\n",
    "out$df_sample[ stage_2_data$x_missing %>% head ]\n",
    "stage_2_data$x_missing_mean[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage_2_fit = sampling(stage_2_regress_model,  data = stage_2_data, init=stage_2_init, cores=4, chains=4, iter = 2000, control=list(adapt_delta=0.8))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A data.frame: 57 × 11</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>mean</th><th scope=col>se_mean</th><th scope=col>sd</th><th scope=col>X2.5.</th><th scope=col>X25.</th><th scope=col>X50.</th><th scope=col>X75.</th><th scope=col>X97.5.</th><th scope=col>n_eff</th><th scope=col>Rhat</th><th scope=col>PARAM</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>-3.694043e+03</td><td>0.139065514</td><td> 5.39343410</td><td>-3.705574e+03</td><td>-3.697444e+03</td><td>-3.693760e+03</td><td>-3.690293e+03</td><td>-3684.3347002</td><td>1504.152</td><td>1.0021703</td><td>lp__        </td></tr>\n",
       "\t<tr><td> 2.681259e-01</td><td>0.001483467</td><td> 0.05872571</td><td> 1.609705e-01</td><td> 2.293913e-01</td><td> 2.645376e-01</td><td> 3.036082e-01</td><td>    0.3939789</td><td>1567.115</td><td>1.0029695</td><td>sigma_beta_x</td></tr>\n",
       "\t<tr><td> 1.878750e+01</td><td>0.219294548</td><td>13.62029644</td><td> 2.406392e+00</td><td> 8.568944e+00</td><td> 1.574409e+01</td><td> 2.560232e+01</td><td>   52.7420476</td><td>3857.602</td><td>1.0004976</td><td>nu_x        </td></tr>\n",
       "\t<tr><td> 1.811881e-01</td><td>0.001816480</td><td> 0.12429340</td><td>-5.513418e-02</td><td> 9.596770e-02</td><td> 1.786721e-01</td><td> 2.645823e-01</td><td>    0.4317490</td><td>4682.038</td><td>0.9992651</td><td>beta_x[25]  </td></tr>\n",
       "\t<tr><td> 1.931798e-02</td><td>0.002043035</td><td> 0.14244069</td><td>-2.639041e-01</td><td>-7.673743e-02</td><td> 1.977823e-02</td><td> 1.131703e-01</td><td>    0.3018738</td><td>4860.899</td><td>0.9994084</td><td>alpha_x[25] </td></tr>\n",
       "\t<tr><td> 4.437609e-03</td><td>0.002009471</td><td> 0.14367672</td><td>-2.724323e-01</td><td>-9.384180e-02</td><td> 2.133610e-03</td><td> 1.019685e-01</td><td>    0.2853517</td><td>5112.219</td><td>0.9995786</td><td>alpha_x[17] </td></tr>\n",
       "\t<tr><td>-5.477411e-03</td><td>0.001772377</td><td> 0.12674483</td><td>-2.597522e-01</td><td>-9.005103e-02</td><td>-3.973641e-03</td><td> 7.892909e-02</td><td>    0.2380191</td><td>5113.853</td><td>0.9999204</td><td>beta_x[26]  </td></tr>\n",
       "\t<tr><td> 5.339711e-01</td><td>0.002126222</td><td> 0.15318093</td><td> 2.426675e-01</td><td> 4.318015e-01</td><td> 5.285661e-01</td><td> 6.336679e-01</td><td>    0.8526565</td><td>5190.296</td><td>0.9997843</td><td>beta_x[5]   </td></tr>\n",
       "\t<tr><td> 1.880705e-01</td><td>0.001803564</td><td> 0.13038177</td><td>-6.292559e-02</td><td> 9.761283e-02</td><td> 1.874869e-01</td><td> 2.740039e-01</td><td>    0.4439048</td><td>5226.013</td><td>0.9998307</td><td>beta_x[6]   </td></tr>\n",
       "\t<tr><td> 4.873805e-01</td><td>0.001993544</td><td> 0.14416563</td><td> 2.227174e-01</td><td> 3.903584e-01</td><td> 4.817169e-01</td><td> 5.787177e-01</td><td>    0.7833939</td><td>5229.638</td><td>0.9991161</td><td>beta_x[12]  </td></tr>\n",
       "\t<tr><td>-2.070250e-04</td><td>0.001990974</td><td> 0.14450157</td><td>-2.808962e-01</td><td>-9.899121e-02</td><td>-9.194523e-04</td><td> 9.623437e-02</td><td>    0.2853550</td><td>5267.614</td><td>0.9995539</td><td>alpha_x[27] </td></tr>\n",
       "\t<tr><td> 5.987635e-01</td><td>0.002168721</td><td> 0.15780673</td><td> 3.047517e-01</td><td> 4.921155e-01</td><td> 5.981408e-01</td><td> 7.000868e-01</td><td>    0.9223027</td><td>5294.726</td><td>0.9993473</td><td>beta_x[20]  </td></tr>\n",
       "\t<tr><td>-6.983727e-02</td><td>0.001644516</td><td> 0.12082988</td><td>-3.083429e-01</td><td>-1.493879e-01</td><td>-6.865519e-02</td><td> 1.269237e-02</td><td>    0.1553524</td><td>5398.495</td><td>1.0000847</td><td>beta_x[1]   </td></tr>\n",
       "\t<tr><td> 8.055559e-03</td><td>0.001930238</td><td> 0.14231742</td><td>-2.707388e-01</td><td>-8.652435e-02</td><td> 7.731701e-03</td><td> 1.040878e-01</td><td>    0.2889571</td><td>5436.185</td><td>0.9997446</td><td>alpha_x[6]  </td></tr>\n",
       "\t<tr><td>-1.921813e-04</td><td>0.001981764</td><td> 0.14718198</td><td>-2.877378e-01</td><td>-9.980865e-02</td><td> 1.159780e-03</td><td> 9.948430e-02</td><td>    0.2801377</td><td>5515.762</td><td>1.0003310</td><td>alpha_x[18] </td></tr>\n",
       "\t<tr><td> 5.515186e-01</td><td>0.002032523</td><td> 0.15354231</td><td> 2.620712e-01</td><td> 4.478194e-01</td><td> 5.483834e-01</td><td> 6.515272e-01</td><td>    0.8647490</td><td>5706.705</td><td>0.9999950</td><td>beta_x[24]  </td></tr>\n",
       "\t<tr><td> 8.004495e-02</td><td>0.001559144</td><td> 0.11784496</td><td>-1.445071e-01</td><td> 7.855911e-04</td><td> 7.934599e-02</td><td> 1.574930e-01</td><td>    0.3154096</td><td>5712.809</td><td>0.9994538</td><td>beta_x[8]   </td></tr>\n",
       "\t<tr><td> 1.580806e-01</td><td>0.001780630</td><td> 0.13512904</td><td>-9.744717e-02</td><td> 6.742447e-02</td><td> 1.550030e-01</td><td> 2.444554e-01</td><td>    0.4337151</td><td>5759.042</td><td>0.9993634</td><td>beta_x[27]  </td></tr>\n",
       "\t<tr><td> 3.788762e-01</td><td>0.001818174</td><td> 0.13877342</td><td> 1.160424e-01</td><td> 2.841536e-01</td><td> 3.778969e-01</td><td> 4.735805e-01</td><td>    0.6480720</td><td>5825.615</td><td>0.9997851</td><td>beta_x[4]   </td></tr>\n",
       "\t<tr><td> 4.475000e-01</td><td>0.001865530</td><td> 0.14268719</td><td> 1.752023e-01</td><td> 3.500616e-01</td><td> 4.489592e-01</td><td> 5.400916e-01</td><td>    0.7279739</td><td>5850.132</td><td>0.9996292</td><td>beta_x[23]  </td></tr>\n",
       "\t<tr><td>-1.893604e-04</td><td>0.001784458</td><td> 0.13651240</td><td>-2.596175e-01</td><td>-9.214229e-02</td><td>-1.978811e-03</td><td> 9.216000e-02</td><td>    0.2656803</td><td>5852.368</td><td>0.9992460</td><td>alpha_x[26] </td></tr>\n",
       "\t<tr><td> 7.100882e-02</td><td>0.001583049</td><td> 0.12157785</td><td>-1.637172e-01</td><td>-1.301007e-02</td><td> 6.934470e-02</td><td> 1.505074e-01</td><td>    0.3161093</td><td>5898.211</td><td>0.9996924</td><td>beta_x[10]  </td></tr>\n",
       "\t<tr><td> 3.415269e-02</td><td>0.001536114</td><td> 0.11850542</td><td>-1.989191e-01</td><td>-4.279894e-02</td><td> 3.521344e-02</td><td> 1.114238e-01</td><td>    0.2625607</td><td>5951.544</td><td>0.9994713</td><td>beta_x[13]  </td></tr>\n",
       "\t<tr><td> 3.675242e-02</td><td>0.001545242</td><td> 0.11921994</td><td>-1.998551e-01</td><td>-4.345446e-02</td><td> 3.554797e-02</td><td> 1.163678e-01</td><td>    0.2769094</td><td>5952.575</td><td>0.9994650</td><td>beta_x[11]  </td></tr>\n",
       "\t<tr><td>-8.967227e-02</td><td>0.001897032</td><td> 0.14640767</td><td>-3.767911e-01</td><td>-1.873004e-01</td><td>-8.893106e-02</td><td> 7.151570e-03</td><td>    0.1938974</td><td>5956.325</td><td>0.9997891</td><td>alpha_x[24] </td></tr>\n",
       "\t<tr><td>-5.552915e-03</td><td>0.001664325</td><td> 0.12913183</td><td>-2.527363e-01</td><td>-9.251236e-02</td><td>-5.316749e-03</td><td> 8.058979e-02</td><td>    0.2462845</td><td>6019.913</td><td>0.9992574</td><td>beta_x[18]  </td></tr>\n",
       "\t<tr><td>-1.133648e-02</td><td>0.001845666</td><td> 0.14358068</td><td>-2.962971e-01</td><td>-1.110652e-01</td><td>-1.054123e-02</td><td> 8.894128e-02</td><td>    0.2696808</td><td>6051.814</td><td>1.0003480</td><td>alpha_x[22] </td></tr>\n",
       "\t<tr><td> 8.615847e-03</td><td>0.001525538</td><td> 0.11875165</td><td>-2.263614e-01</td><td>-7.015550e-02</td><td> 9.341125e-03</td><td> 8.853026e-02</td><td>    0.2454911</td><td>6059.449</td><td>1.0000891</td><td>beta_x[21]  </td></tr>\n",
       "\t<tr><td> 2.487583e-02</td><td>0.001867354</td><td> 0.14571624</td><td>-2.633765e-01</td><td>-7.152704e-02</td><td> 2.695890e-02</td><td> 1.240579e-01</td><td>    0.3118293</td><td>6089.234</td><td>0.9995725</td><td>alpha_x[20] </td></tr>\n",
       "\t<tr><td> 1.923845e-02</td><td>0.001592230</td><td> 0.12447101</td><td>-2.280307e-01</td><td>-6.301956e-02</td><td> 1.824892e-02</td><td> 9.877477e-02</td><td>    0.2636860</td><td>6111.174</td><td>1.0008442</td><td>beta_x[19]  </td></tr>\n",
       "\t<tr><td> 5.047697e-04</td><td>0.001774834</td><td> 0.13920318</td><td>-2.664362e-01</td><td>-9.359658e-02</td><td>-8.334970e-04</td><td> 9.681978e-02</td><td>    0.2748681</td><td>6151.528</td><td>0.9993391</td><td>alpha_x[11] </td></tr>\n",
       "\t<tr><td> 2.393409e-01</td><td>0.001678456</td><td> 0.13274093</td><td>-1.179518e-02</td><td> 1.485488e-01</td><td> 2.368233e-01</td><td> 3.278915e-01</td><td>    0.5027814</td><td>6254.459</td><td>0.9997467</td><td>beta_x[7]   </td></tr>\n",
       "\t<tr><td>-4.966920e-03</td><td>0.001753106</td><td> 0.13937443</td><td>-2.762711e-01</td><td>-9.375960e-02</td><td>-7.227510e-03</td><td> 8.698692e-02</td><td>    0.2774669</td><td>6320.478</td><td>0.9996633</td><td>alpha_x[16] </td></tr>\n",
       "\t<tr><td>-2.027899e-03</td><td>0.001771000</td><td> 0.14080904</td><td>-2.782749e-01</td><td>-9.885931e-02</td><td>-3.695056e-03</td><td> 9.470729e-02</td><td>    0.2807672</td><td>6321.552</td><td>0.9998328</td><td>alpha_x[2]  </td></tr>\n",
       "\t<tr><td> 4.488737e-04</td><td>0.001819141</td><td> 0.14490523</td><td>-2.864172e-01</td><td>-9.480939e-02</td><td> 4.422779e-05</td><td> 9.620502e-02</td><td>    0.2891766</td><td>6345.053</td><td>0.9995207</td><td>alpha_x[21] </td></tr>\n",
       "\t<tr><td> 4.342524e-02</td><td>0.001560231</td><td> 0.12429871</td><td>-2.010399e-01</td><td>-4.108168e-02</td><td> 4.431161e-02</td><td> 1.261176e-01</td><td>    0.2844477</td><td>6346.810</td><td>0.9997678</td><td>beta_x[15]  </td></tr>\n",
       "\t<tr><td> 2.697834e-02</td><td>0.001765134</td><td> 0.14095871</td><td>-2.538554e-01</td><td>-6.878633e-02</td><td> 2.845588e-02</td><td> 1.225377e-01</td><td>    0.2965730</td><td>6377.177</td><td>0.9997299</td><td>alpha_x[4]  </td></tr>\n",
       "\t<tr><td>-4.089823e-03</td><td>0.001791085</td><td> 0.14312333</td><td>-2.769803e-01</td><td>-1.036339e-01</td><td>-7.339113e-03</td><td> 9.355727e-02</td><td>    0.2795035</td><td>6385.403</td><td>0.9999986</td><td>alpha_x[15] </td></tr>\n",
       "\t<tr><td> 2.312810e-01</td><td>0.001666275</td><td> 0.13377666</td><td>-1.980816e-02</td><td> 1.405008e-01</td><td> 2.293622e-01</td><td> 3.213096e-01</td><td>    0.5058789</td><td>6445.660</td><td>1.0003192</td><td>beta_x[22]  </td></tr>\n",
       "\t<tr><td>-2.443225e-03</td><td>0.001745535</td><td> 0.14046526</td><td>-2.773382e-01</td><td>-9.654538e-02</td><td>-1.443324e-03</td><td> 8.888806e-02</td><td>    0.2779728</td><td>6475.613</td><td>0.9994681</td><td>alpha_x[1]  </td></tr>\n",
       "\t<tr><td> 1.515319e-01</td><td>0.001650676</td><td> 0.13293022</td><td>-1.075566e-01</td><td> 6.064673e-02</td><td> 1.500917e-01</td><td> 2.385654e-01</td><td>    0.4196849</td><td>6485.203</td><td>0.9997378</td><td>beta_x[17]  </td></tr>\n",
       "\t<tr><td>-5.097384e-02</td><td>0.001509994</td><td> 0.12196100</td><td>-2.947551e-01</td><td>-1.340074e-01</td><td>-5.050020e-02</td><td> 3.341235e-02</td><td>    0.1819829</td><td>6523.666</td><td>1.0006353</td><td>beta_x[3]   </td></tr>\n",
       "\t<tr><td> 4.974161e-03</td><td>0.001728490</td><td> 0.14001928</td><td>-2.751225e-01</td><td>-8.849035e-02</td><td> 4.589035e-03</td><td> 9.709798e-02</td><td>    0.2784897</td><td>6562.084</td><td>1.0000728</td><td>alpha_x[10] </td></tr>\n",
       "\t<tr><td> 3.356031e-02</td><td>0.001541492</td><td> 0.12525838</td><td>-2.067778e-01</td><td>-5.179324e-02</td><td> 3.253743e-02</td><td> 1.157061e-01</td><td>    0.2820907</td><td>6602.848</td><td>0.9998646</td><td>beta_x[2]   </td></tr>\n",
       "\t<tr><td> 3.515204e-04</td><td>0.001721290</td><td> 0.14014626</td><td>-2.797585e-01</td><td>-9.203945e-02</td><td> 1.634337e-03</td><td> 9.428319e-02</td><td>    0.2658401</td><td>6629.108</td><td>0.9991067</td><td>alpha_x[9]  </td></tr>\n",
       "\t<tr><td> 4.332607e-03</td><td>0.001766777</td><td> 0.14408250</td><td>-2.840461e-01</td><td>-9.250645e-02</td><td> 6.421033e-03</td><td> 1.024955e-01</td><td>    0.2939405</td><td>6650.575</td><td>0.9997161</td><td>alpha_x[23] </td></tr>\n",
       "\t<tr><td> 1.333776e-02</td><td>0.001737981</td><td> 0.14205747</td><td>-2.654144e-01</td><td>-8.222197e-02</td><td> 1.526494e-02</td><td> 1.089499e-01</td><td>    0.2843003</td><td>6680.947</td><td>1.0002679</td><td>alpha_x[7]  </td></tr>\n",
       "\t<tr><td> 3.441801e-02</td><td>0.001550895</td><td> 0.12711050</td><td>-2.140593e-01</td><td>-5.450287e-02</td><td> 3.434621e-02</td><td> 1.218888e-01</td><td>    0.2841969</td><td>6717.347</td><td>0.9997828</td><td>beta_x[14]  </td></tr>\n",
       "\t<tr><td>-1.239817e-02</td><td>0.001385223</td><td> 0.11423317</td><td>-2.329569e-01</td><td>-9.004257e-02</td><td>-1.201095e-02</td><td> 6.317291e-02</td><td>    0.2151188</td><td>6800.570</td><td>0.9992704</td><td>beta_x[9]   </td></tr>\n",
       "\t<tr><td> 1.298107e-03</td><td>0.001727749</td><td> 0.14274610</td><td>-2.706598e-01</td><td>-9.689443e-02</td><td>-3.378894e-06</td><td> 9.784260e-02</td><td>    0.2841442</td><td>6826.016</td><td>0.9999437</td><td>alpha_x[19] </td></tr>\n",
       "\t<tr><td>-2.051336e-03</td><td>0.001699314</td><td> 0.14059100</td><td>-2.801947e-01</td><td>-9.708751e-02</td><td>-2.346416e-04</td><td> 9.178368e-02</td><td>    0.2776207</td><td>6844.910</td><td>0.9993639</td><td>alpha_x[14] </td></tr>\n",
       "\t<tr><td> 7.793788e-03</td><td>0.001765485</td><td> 0.14654324</td><td>-2.758648e-01</td><td>-9.202582e-02</td><td> 9.781096e-03</td><td> 1.094706e-01</td><td>    0.2895790</td><td>6889.748</td><td>0.9996283</td><td>alpha_x[5]  </td></tr>\n",
       "\t<tr><td> 5.466381e-03</td><td>0.001714228</td><td> 0.14336744</td><td>-2.742340e-01</td><td>-9.190501e-02</td><td> 7.102451e-03</td><td> 1.011554e-01</td><td>    0.2842708</td><td>6994.620</td><td>0.9999013</td><td>alpha_x[12] </td></tr>\n",
       "\t<tr><td> 2.424531e-03</td><td>0.001654452</td><td> 0.13944185</td><td>-2.679761e-01</td><td>-9.230852e-02</td><td> 3.487837e-03</td><td> 9.877493e-02</td><td>    0.2681630</td><td>7103.589</td><td>0.9994436</td><td>alpha_x[13] </td></tr>\n",
       "\t<tr><td>-3.694040e-02</td><td>0.001410554</td><td> 0.12076619</td><td>-2.822719e-01</td><td>-1.165492e-01</td><td>-3.619397e-02</td><td> 4.488197e-02</td><td>    0.1966121</td><td>7330.128</td><td>0.9999784</td><td>beta_x[16]  </td></tr>\n",
       "\t<tr><td> 5.309610e-03</td><td>0.001641204</td><td> 0.14345825</td><td>-2.770961e-01</td><td>-8.766737e-02</td><td> 6.776567e-03</td><td> 1.016101e-01</td><td>    0.2786737</td><td>7640.577</td><td>1.0001811</td><td>alpha_x[8]  </td></tr>\n",
       "\t<tr><td>-6.640138e-03</td><td>0.001573565</td><td> 0.14017603</td><td>-2.805967e-01</td><td>-1.014490e-01</td><td>-6.616993e-03</td><td> 8.962122e-02</td><td>    0.2623956</td><td>7935.566</td><td>0.9991331</td><td>alpha_x[3]  </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 57 × 11\n",
       "\\begin{tabular}{lllllllllll}\n",
       " mean & se\\_mean & sd & X2.5. & X25. & X50. & X75. & X97.5. & n\\_eff & Rhat & PARAM\\\\\n",
       " <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <chr>\\\\\n",
       "\\hline\n",
       "\t -3.694043e+03 & 0.139065514 &  5.39343410 & -3.705574e+03 & -3.697444e+03 & -3.693760e+03 & -3.690293e+03 & -3684.3347002 & 1504.152 & 1.0021703 & lp\\_\\_        \\\\\n",
       "\t  2.681259e-01 & 0.001483467 &  0.05872571 &  1.609705e-01 &  2.293913e-01 &  2.645376e-01 &  3.036082e-01 &     0.3939789 & 1567.115 & 1.0029695 & sigma\\_beta\\_x\\\\\n",
       "\t  1.878750e+01 & 0.219294548 & 13.62029644 &  2.406392e+00 &  8.568944e+00 &  1.574409e+01 &  2.560232e+01 &    52.7420476 & 3857.602 & 1.0004976 & nu\\_x        \\\\\n",
       "\t  1.811881e-01 & 0.001816480 &  0.12429340 & -5.513418e-02 &  9.596770e-02 &  1.786721e-01 &  2.645823e-01 &     0.4317490 & 4682.038 & 0.9992651 & beta\\_x{[}25{]}  \\\\\n",
       "\t  1.931798e-02 & 0.002043035 &  0.14244069 & -2.639041e-01 & -7.673743e-02 &  1.977823e-02 &  1.131703e-01 &     0.3018738 & 4860.899 & 0.9994084 & alpha\\_x{[}25{]} \\\\\n",
       "\t  4.437609e-03 & 0.002009471 &  0.14367672 & -2.724323e-01 & -9.384180e-02 &  2.133610e-03 &  1.019685e-01 &     0.2853517 & 5112.219 & 0.9995786 & alpha\\_x{[}17{]} \\\\\n",
       "\t -5.477411e-03 & 0.001772377 &  0.12674483 & -2.597522e-01 & -9.005103e-02 & -3.973641e-03 &  7.892909e-02 &     0.2380191 & 5113.853 & 0.9999204 & beta\\_x{[}26{]}  \\\\\n",
       "\t  5.339711e-01 & 0.002126222 &  0.15318093 &  2.426675e-01 &  4.318015e-01 &  5.285661e-01 &  6.336679e-01 &     0.8526565 & 5190.296 & 0.9997843 & beta\\_x{[}5{]}   \\\\\n",
       "\t  1.880705e-01 & 0.001803564 &  0.13038177 & -6.292559e-02 &  9.761283e-02 &  1.874869e-01 &  2.740039e-01 &     0.4439048 & 5226.013 & 0.9998307 & beta\\_x{[}6{]}   \\\\\n",
       "\t  4.873805e-01 & 0.001993544 &  0.14416563 &  2.227174e-01 &  3.903584e-01 &  4.817169e-01 &  5.787177e-01 &     0.7833939 & 5229.638 & 0.9991161 & beta\\_x{[}12{]}  \\\\\n",
       "\t -2.070250e-04 & 0.001990974 &  0.14450157 & -2.808962e-01 & -9.899121e-02 & -9.194523e-04 &  9.623437e-02 &     0.2853550 & 5267.614 & 0.9995539 & alpha\\_x{[}27{]} \\\\\n",
       "\t  5.987635e-01 & 0.002168721 &  0.15780673 &  3.047517e-01 &  4.921155e-01 &  5.981408e-01 &  7.000868e-01 &     0.9223027 & 5294.726 & 0.9993473 & beta\\_x{[}20{]}  \\\\\n",
       "\t -6.983727e-02 & 0.001644516 &  0.12082988 & -3.083429e-01 & -1.493879e-01 & -6.865519e-02 &  1.269237e-02 &     0.1553524 & 5398.495 & 1.0000847 & beta\\_x{[}1{]}   \\\\\n",
       "\t  8.055559e-03 & 0.001930238 &  0.14231742 & -2.707388e-01 & -8.652435e-02 &  7.731701e-03 &  1.040878e-01 &     0.2889571 & 5436.185 & 0.9997446 & alpha\\_x{[}6{]}  \\\\\n",
       "\t -1.921813e-04 & 0.001981764 &  0.14718198 & -2.877378e-01 & -9.980865e-02 &  1.159780e-03 &  9.948430e-02 &     0.2801377 & 5515.762 & 1.0003310 & alpha\\_x{[}18{]} \\\\\n",
       "\t  5.515186e-01 & 0.002032523 &  0.15354231 &  2.620712e-01 &  4.478194e-01 &  5.483834e-01 &  6.515272e-01 &     0.8647490 & 5706.705 & 0.9999950 & beta\\_x{[}24{]}  \\\\\n",
       "\t  8.004495e-02 & 0.001559144 &  0.11784496 & -1.445071e-01 &  7.855911e-04 &  7.934599e-02 &  1.574930e-01 &     0.3154096 & 5712.809 & 0.9994538 & beta\\_x{[}8{]}   \\\\\n",
       "\t  1.580806e-01 & 0.001780630 &  0.13512904 & -9.744717e-02 &  6.742447e-02 &  1.550030e-01 &  2.444554e-01 &     0.4337151 & 5759.042 & 0.9993634 & beta\\_x{[}27{]}  \\\\\n",
       "\t  3.788762e-01 & 0.001818174 &  0.13877342 &  1.160424e-01 &  2.841536e-01 &  3.778969e-01 &  4.735805e-01 &     0.6480720 & 5825.615 & 0.9997851 & beta\\_x{[}4{]}   \\\\\n",
       "\t  4.475000e-01 & 0.001865530 &  0.14268719 &  1.752023e-01 &  3.500616e-01 &  4.489592e-01 &  5.400916e-01 &     0.7279739 & 5850.132 & 0.9996292 & beta\\_x{[}23{]}  \\\\\n",
       "\t -1.893604e-04 & 0.001784458 &  0.13651240 & -2.596175e-01 & -9.214229e-02 & -1.978811e-03 &  9.216000e-02 &     0.2656803 & 5852.368 & 0.9992460 & alpha\\_x{[}26{]} \\\\\n",
       "\t  7.100882e-02 & 0.001583049 &  0.12157785 & -1.637172e-01 & -1.301007e-02 &  6.934470e-02 &  1.505074e-01 &     0.3161093 & 5898.211 & 0.9996924 & beta\\_x{[}10{]}  \\\\\n",
       "\t  3.415269e-02 & 0.001536114 &  0.11850542 & -1.989191e-01 & -4.279894e-02 &  3.521344e-02 &  1.114238e-01 &     0.2625607 & 5951.544 & 0.9994713 & beta\\_x{[}13{]}  \\\\\n",
       "\t  3.675242e-02 & 0.001545242 &  0.11921994 & -1.998551e-01 & -4.345446e-02 &  3.554797e-02 &  1.163678e-01 &     0.2769094 & 5952.575 & 0.9994650 & beta\\_x{[}11{]}  \\\\\n",
       "\t -8.967227e-02 & 0.001897032 &  0.14640767 & -3.767911e-01 & -1.873004e-01 & -8.893106e-02 &  7.151570e-03 &     0.1938974 & 5956.325 & 0.9997891 & alpha\\_x{[}24{]} \\\\\n",
       "\t -5.552915e-03 & 0.001664325 &  0.12913183 & -2.527363e-01 & -9.251236e-02 & -5.316749e-03 &  8.058979e-02 &     0.2462845 & 6019.913 & 0.9992574 & beta\\_x{[}18{]}  \\\\\n",
       "\t -1.133648e-02 & 0.001845666 &  0.14358068 & -2.962971e-01 & -1.110652e-01 & -1.054123e-02 &  8.894128e-02 &     0.2696808 & 6051.814 & 1.0003480 & alpha\\_x{[}22{]} \\\\\n",
       "\t  8.615847e-03 & 0.001525538 &  0.11875165 & -2.263614e-01 & -7.015550e-02 &  9.341125e-03 &  8.853026e-02 &     0.2454911 & 6059.449 & 1.0000891 & beta\\_x{[}21{]}  \\\\\n",
       "\t  2.487583e-02 & 0.001867354 &  0.14571624 & -2.633765e-01 & -7.152704e-02 &  2.695890e-02 &  1.240579e-01 &     0.3118293 & 6089.234 & 0.9995725 & alpha\\_x{[}20{]} \\\\\n",
       "\t  1.923845e-02 & 0.001592230 &  0.12447101 & -2.280307e-01 & -6.301956e-02 &  1.824892e-02 &  9.877477e-02 &     0.2636860 & 6111.174 & 1.0008442 & beta\\_x{[}19{]}  \\\\\n",
       "\t  5.047697e-04 & 0.001774834 &  0.13920318 & -2.664362e-01 & -9.359658e-02 & -8.334970e-04 &  9.681978e-02 &     0.2748681 & 6151.528 & 0.9993391 & alpha\\_x{[}11{]} \\\\\n",
       "\t  2.393409e-01 & 0.001678456 &  0.13274093 & -1.179518e-02 &  1.485488e-01 &  2.368233e-01 &  3.278915e-01 &     0.5027814 & 6254.459 & 0.9997467 & beta\\_x{[}7{]}   \\\\\n",
       "\t -4.966920e-03 & 0.001753106 &  0.13937443 & -2.762711e-01 & -9.375960e-02 & -7.227510e-03 &  8.698692e-02 &     0.2774669 & 6320.478 & 0.9996633 & alpha\\_x{[}16{]} \\\\\n",
       "\t -2.027899e-03 & 0.001771000 &  0.14080904 & -2.782749e-01 & -9.885931e-02 & -3.695056e-03 &  9.470729e-02 &     0.2807672 & 6321.552 & 0.9998328 & alpha\\_x{[}2{]}  \\\\\n",
       "\t  4.488737e-04 & 0.001819141 &  0.14490523 & -2.864172e-01 & -9.480939e-02 &  4.422779e-05 &  9.620502e-02 &     0.2891766 & 6345.053 & 0.9995207 & alpha\\_x{[}21{]} \\\\\n",
       "\t  4.342524e-02 & 0.001560231 &  0.12429871 & -2.010399e-01 & -4.108168e-02 &  4.431161e-02 &  1.261176e-01 &     0.2844477 & 6346.810 & 0.9997678 & beta\\_x{[}15{]}  \\\\\n",
       "\t  2.697834e-02 & 0.001765134 &  0.14095871 & -2.538554e-01 & -6.878633e-02 &  2.845588e-02 &  1.225377e-01 &     0.2965730 & 6377.177 & 0.9997299 & alpha\\_x{[}4{]}  \\\\\n",
       "\t -4.089823e-03 & 0.001791085 &  0.14312333 & -2.769803e-01 & -1.036339e-01 & -7.339113e-03 &  9.355727e-02 &     0.2795035 & 6385.403 & 0.9999986 & alpha\\_x{[}15{]} \\\\\n",
       "\t  2.312810e-01 & 0.001666275 &  0.13377666 & -1.980816e-02 &  1.405008e-01 &  2.293622e-01 &  3.213096e-01 &     0.5058789 & 6445.660 & 1.0003192 & beta\\_x{[}22{]}  \\\\\n",
       "\t -2.443225e-03 & 0.001745535 &  0.14046526 & -2.773382e-01 & -9.654538e-02 & -1.443324e-03 &  8.888806e-02 &     0.2779728 & 6475.613 & 0.9994681 & alpha\\_x{[}1{]}  \\\\\n",
       "\t  1.515319e-01 & 0.001650676 &  0.13293022 & -1.075566e-01 &  6.064673e-02 &  1.500917e-01 &  2.385654e-01 &     0.4196849 & 6485.203 & 0.9997378 & beta\\_x{[}17{]}  \\\\\n",
       "\t -5.097384e-02 & 0.001509994 &  0.12196100 & -2.947551e-01 & -1.340074e-01 & -5.050020e-02 &  3.341235e-02 &     0.1819829 & 6523.666 & 1.0006353 & beta\\_x{[}3{]}   \\\\\n",
       "\t  4.974161e-03 & 0.001728490 &  0.14001928 & -2.751225e-01 & -8.849035e-02 &  4.589035e-03 &  9.709798e-02 &     0.2784897 & 6562.084 & 1.0000728 & alpha\\_x{[}10{]} \\\\\n",
       "\t  3.356031e-02 & 0.001541492 &  0.12525838 & -2.067778e-01 & -5.179324e-02 &  3.253743e-02 &  1.157061e-01 &     0.2820907 & 6602.848 & 0.9998646 & beta\\_x{[}2{]}   \\\\\n",
       "\t  3.515204e-04 & 0.001721290 &  0.14014626 & -2.797585e-01 & -9.203945e-02 &  1.634337e-03 &  9.428319e-02 &     0.2658401 & 6629.108 & 0.9991067 & alpha\\_x{[}9{]}  \\\\\n",
       "\t  4.332607e-03 & 0.001766777 &  0.14408250 & -2.840461e-01 & -9.250645e-02 &  6.421033e-03 &  1.024955e-01 &     0.2939405 & 6650.575 & 0.9997161 & alpha\\_x{[}23{]} \\\\\n",
       "\t  1.333776e-02 & 0.001737981 &  0.14205747 & -2.654144e-01 & -8.222197e-02 &  1.526494e-02 &  1.089499e-01 &     0.2843003 & 6680.947 & 1.0002679 & alpha\\_x{[}7{]}  \\\\\n",
       "\t  3.441801e-02 & 0.001550895 &  0.12711050 & -2.140593e-01 & -5.450287e-02 &  3.434621e-02 &  1.218888e-01 &     0.2841969 & 6717.347 & 0.9997828 & beta\\_x{[}14{]}  \\\\\n",
       "\t -1.239817e-02 & 0.001385223 &  0.11423317 & -2.329569e-01 & -9.004257e-02 & -1.201095e-02 &  6.317291e-02 &     0.2151188 & 6800.570 & 0.9992704 & beta\\_x{[}9{]}   \\\\\n",
       "\t  1.298107e-03 & 0.001727749 &  0.14274610 & -2.706598e-01 & -9.689443e-02 & -3.378894e-06 &  9.784260e-02 &     0.2841442 & 6826.016 & 0.9999437 & alpha\\_x{[}19{]} \\\\\n",
       "\t -2.051336e-03 & 0.001699314 &  0.14059100 & -2.801947e-01 & -9.708751e-02 & -2.346416e-04 &  9.178368e-02 &     0.2776207 & 6844.910 & 0.9993639 & alpha\\_x{[}14{]} \\\\\n",
       "\t  7.793788e-03 & 0.001765485 &  0.14654324 & -2.758648e-01 & -9.202582e-02 &  9.781096e-03 &  1.094706e-01 &     0.2895790 & 6889.748 & 0.9996283 & alpha\\_x{[}5{]}  \\\\\n",
       "\t  5.466381e-03 & 0.001714228 &  0.14336744 & -2.742340e-01 & -9.190501e-02 &  7.102451e-03 &  1.011554e-01 &     0.2842708 & 6994.620 & 0.9999013 & alpha\\_x{[}12{]} \\\\\n",
       "\t  2.424531e-03 & 0.001654452 &  0.13944185 & -2.679761e-01 & -9.230852e-02 &  3.487837e-03 &  9.877493e-02 &     0.2681630 & 7103.589 & 0.9994436 & alpha\\_x{[}13{]} \\\\\n",
       "\t -3.694040e-02 & 0.001410554 &  0.12076619 & -2.822719e-01 & -1.165492e-01 & -3.619397e-02 &  4.488197e-02 &     0.1966121 & 7330.128 & 0.9999784 & beta\\_x{[}16{]}  \\\\\n",
       "\t  5.309610e-03 & 0.001641204 &  0.14345825 & -2.770961e-01 & -8.766737e-02 &  6.776567e-03 &  1.016101e-01 &     0.2786737 & 7640.577 & 1.0001811 & alpha\\_x{[}8{]}  \\\\\n",
       "\t -6.640138e-03 & 0.001573565 &  0.14017603 & -2.805967e-01 & -1.014490e-01 & -6.616993e-03 &  8.962122e-02 &     0.2623956 & 7935.566 & 0.9991331 & alpha\\_x{[}3{]}  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 57 × 11\n",
       "\n",
       "| mean &lt;dbl&gt; | se_mean &lt;dbl&gt; | sd &lt;dbl&gt; | X2.5. &lt;dbl&gt; | X25. &lt;dbl&gt; | X50. &lt;dbl&gt; | X75. &lt;dbl&gt; | X97.5. &lt;dbl&gt; | n_eff &lt;dbl&gt; | Rhat &lt;dbl&gt; | PARAM &lt;chr&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| -3.694043e+03 | 0.139065514 |  5.39343410 | -3.705574e+03 | -3.697444e+03 | -3.693760e+03 | -3.690293e+03 | -3684.3347002 | 1504.152 | 1.0021703 | lp__         |\n",
       "|  2.681259e-01 | 0.001483467 |  0.05872571 |  1.609705e-01 |  2.293913e-01 |  2.645376e-01 |  3.036082e-01 |     0.3939789 | 1567.115 | 1.0029695 | sigma_beta_x |\n",
       "|  1.878750e+01 | 0.219294548 | 13.62029644 |  2.406392e+00 |  8.568944e+00 |  1.574409e+01 |  2.560232e+01 |    52.7420476 | 3857.602 | 1.0004976 | nu_x         |\n",
       "|  1.811881e-01 | 0.001816480 |  0.12429340 | -5.513418e-02 |  9.596770e-02 |  1.786721e-01 |  2.645823e-01 |     0.4317490 | 4682.038 | 0.9992651 | beta_x[25]   |\n",
       "|  1.931798e-02 | 0.002043035 |  0.14244069 | -2.639041e-01 | -7.673743e-02 |  1.977823e-02 |  1.131703e-01 |     0.3018738 | 4860.899 | 0.9994084 | alpha_x[25]  |\n",
       "|  4.437609e-03 | 0.002009471 |  0.14367672 | -2.724323e-01 | -9.384180e-02 |  2.133610e-03 |  1.019685e-01 |     0.2853517 | 5112.219 | 0.9995786 | alpha_x[17]  |\n",
       "| -5.477411e-03 | 0.001772377 |  0.12674483 | -2.597522e-01 | -9.005103e-02 | -3.973641e-03 |  7.892909e-02 |     0.2380191 | 5113.853 | 0.9999204 | beta_x[26]   |\n",
       "|  5.339711e-01 | 0.002126222 |  0.15318093 |  2.426675e-01 |  4.318015e-01 |  5.285661e-01 |  6.336679e-01 |     0.8526565 | 5190.296 | 0.9997843 | beta_x[5]    |\n",
       "|  1.880705e-01 | 0.001803564 |  0.13038177 | -6.292559e-02 |  9.761283e-02 |  1.874869e-01 |  2.740039e-01 |     0.4439048 | 5226.013 | 0.9998307 | beta_x[6]    |\n",
       "|  4.873805e-01 | 0.001993544 |  0.14416563 |  2.227174e-01 |  3.903584e-01 |  4.817169e-01 |  5.787177e-01 |     0.7833939 | 5229.638 | 0.9991161 | beta_x[12]   |\n",
       "| -2.070250e-04 | 0.001990974 |  0.14450157 | -2.808962e-01 | -9.899121e-02 | -9.194523e-04 |  9.623437e-02 |     0.2853550 | 5267.614 | 0.9995539 | alpha_x[27]  |\n",
       "|  5.987635e-01 | 0.002168721 |  0.15780673 |  3.047517e-01 |  4.921155e-01 |  5.981408e-01 |  7.000868e-01 |     0.9223027 | 5294.726 | 0.9993473 | beta_x[20]   |\n",
       "| -6.983727e-02 | 0.001644516 |  0.12082988 | -3.083429e-01 | -1.493879e-01 | -6.865519e-02 |  1.269237e-02 |     0.1553524 | 5398.495 | 1.0000847 | beta_x[1]    |\n",
       "|  8.055559e-03 | 0.001930238 |  0.14231742 | -2.707388e-01 | -8.652435e-02 |  7.731701e-03 |  1.040878e-01 |     0.2889571 | 5436.185 | 0.9997446 | alpha_x[6]   |\n",
       "| -1.921813e-04 | 0.001981764 |  0.14718198 | -2.877378e-01 | -9.980865e-02 |  1.159780e-03 |  9.948430e-02 |     0.2801377 | 5515.762 | 1.0003310 | alpha_x[18]  |\n",
       "|  5.515186e-01 | 0.002032523 |  0.15354231 |  2.620712e-01 |  4.478194e-01 |  5.483834e-01 |  6.515272e-01 |     0.8647490 | 5706.705 | 0.9999950 | beta_x[24]   |\n",
       "|  8.004495e-02 | 0.001559144 |  0.11784496 | -1.445071e-01 |  7.855911e-04 |  7.934599e-02 |  1.574930e-01 |     0.3154096 | 5712.809 | 0.9994538 | beta_x[8]    |\n",
       "|  1.580806e-01 | 0.001780630 |  0.13512904 | -9.744717e-02 |  6.742447e-02 |  1.550030e-01 |  2.444554e-01 |     0.4337151 | 5759.042 | 0.9993634 | beta_x[27]   |\n",
       "|  3.788762e-01 | 0.001818174 |  0.13877342 |  1.160424e-01 |  2.841536e-01 |  3.778969e-01 |  4.735805e-01 |     0.6480720 | 5825.615 | 0.9997851 | beta_x[4]    |\n",
       "|  4.475000e-01 | 0.001865530 |  0.14268719 |  1.752023e-01 |  3.500616e-01 |  4.489592e-01 |  5.400916e-01 |     0.7279739 | 5850.132 | 0.9996292 | beta_x[23]   |\n",
       "| -1.893604e-04 | 0.001784458 |  0.13651240 | -2.596175e-01 | -9.214229e-02 | -1.978811e-03 |  9.216000e-02 |     0.2656803 | 5852.368 | 0.9992460 | alpha_x[26]  |\n",
       "|  7.100882e-02 | 0.001583049 |  0.12157785 | -1.637172e-01 | -1.301007e-02 |  6.934470e-02 |  1.505074e-01 |     0.3161093 | 5898.211 | 0.9996924 | beta_x[10]   |\n",
       "|  3.415269e-02 | 0.001536114 |  0.11850542 | -1.989191e-01 | -4.279894e-02 |  3.521344e-02 |  1.114238e-01 |     0.2625607 | 5951.544 | 0.9994713 | beta_x[13]   |\n",
       "|  3.675242e-02 | 0.001545242 |  0.11921994 | -1.998551e-01 | -4.345446e-02 |  3.554797e-02 |  1.163678e-01 |     0.2769094 | 5952.575 | 0.9994650 | beta_x[11]   |\n",
       "| -8.967227e-02 | 0.001897032 |  0.14640767 | -3.767911e-01 | -1.873004e-01 | -8.893106e-02 |  7.151570e-03 |     0.1938974 | 5956.325 | 0.9997891 | alpha_x[24]  |\n",
       "| -5.552915e-03 | 0.001664325 |  0.12913183 | -2.527363e-01 | -9.251236e-02 | -5.316749e-03 |  8.058979e-02 |     0.2462845 | 6019.913 | 0.9992574 | beta_x[18]   |\n",
       "| -1.133648e-02 | 0.001845666 |  0.14358068 | -2.962971e-01 | -1.110652e-01 | -1.054123e-02 |  8.894128e-02 |     0.2696808 | 6051.814 | 1.0003480 | alpha_x[22]  |\n",
       "|  8.615847e-03 | 0.001525538 |  0.11875165 | -2.263614e-01 | -7.015550e-02 |  9.341125e-03 |  8.853026e-02 |     0.2454911 | 6059.449 | 1.0000891 | beta_x[21]   |\n",
       "|  2.487583e-02 | 0.001867354 |  0.14571624 | -2.633765e-01 | -7.152704e-02 |  2.695890e-02 |  1.240579e-01 |     0.3118293 | 6089.234 | 0.9995725 | alpha_x[20]  |\n",
       "|  1.923845e-02 | 0.001592230 |  0.12447101 | -2.280307e-01 | -6.301956e-02 |  1.824892e-02 |  9.877477e-02 |     0.2636860 | 6111.174 | 1.0008442 | beta_x[19]   |\n",
       "|  5.047697e-04 | 0.001774834 |  0.13920318 | -2.664362e-01 | -9.359658e-02 | -8.334970e-04 |  9.681978e-02 |     0.2748681 | 6151.528 | 0.9993391 | alpha_x[11]  |\n",
       "|  2.393409e-01 | 0.001678456 |  0.13274093 | -1.179518e-02 |  1.485488e-01 |  2.368233e-01 |  3.278915e-01 |     0.5027814 | 6254.459 | 0.9997467 | beta_x[7]    |\n",
       "| -4.966920e-03 | 0.001753106 |  0.13937443 | -2.762711e-01 | -9.375960e-02 | -7.227510e-03 |  8.698692e-02 |     0.2774669 | 6320.478 | 0.9996633 | alpha_x[16]  |\n",
       "| -2.027899e-03 | 0.001771000 |  0.14080904 | -2.782749e-01 | -9.885931e-02 | -3.695056e-03 |  9.470729e-02 |     0.2807672 | 6321.552 | 0.9998328 | alpha_x[2]   |\n",
       "|  4.488737e-04 | 0.001819141 |  0.14490523 | -2.864172e-01 | -9.480939e-02 |  4.422779e-05 |  9.620502e-02 |     0.2891766 | 6345.053 | 0.9995207 | alpha_x[21]  |\n",
       "|  4.342524e-02 | 0.001560231 |  0.12429871 | -2.010399e-01 | -4.108168e-02 |  4.431161e-02 |  1.261176e-01 |     0.2844477 | 6346.810 | 0.9997678 | beta_x[15]   |\n",
       "|  2.697834e-02 | 0.001765134 |  0.14095871 | -2.538554e-01 | -6.878633e-02 |  2.845588e-02 |  1.225377e-01 |     0.2965730 | 6377.177 | 0.9997299 | alpha_x[4]   |\n",
       "| -4.089823e-03 | 0.001791085 |  0.14312333 | -2.769803e-01 | -1.036339e-01 | -7.339113e-03 |  9.355727e-02 |     0.2795035 | 6385.403 | 0.9999986 | alpha_x[15]  |\n",
       "|  2.312810e-01 | 0.001666275 |  0.13377666 | -1.980816e-02 |  1.405008e-01 |  2.293622e-01 |  3.213096e-01 |     0.5058789 | 6445.660 | 1.0003192 | beta_x[22]   |\n",
       "| -2.443225e-03 | 0.001745535 |  0.14046526 | -2.773382e-01 | -9.654538e-02 | -1.443324e-03 |  8.888806e-02 |     0.2779728 | 6475.613 | 0.9994681 | alpha_x[1]   |\n",
       "|  1.515319e-01 | 0.001650676 |  0.13293022 | -1.075566e-01 |  6.064673e-02 |  1.500917e-01 |  2.385654e-01 |     0.4196849 | 6485.203 | 0.9997378 | beta_x[17]   |\n",
       "| -5.097384e-02 | 0.001509994 |  0.12196100 | -2.947551e-01 | -1.340074e-01 | -5.050020e-02 |  3.341235e-02 |     0.1819829 | 6523.666 | 1.0006353 | beta_x[3]    |\n",
       "|  4.974161e-03 | 0.001728490 |  0.14001928 | -2.751225e-01 | -8.849035e-02 |  4.589035e-03 |  9.709798e-02 |     0.2784897 | 6562.084 | 1.0000728 | alpha_x[10]  |\n",
       "|  3.356031e-02 | 0.001541492 |  0.12525838 | -2.067778e-01 | -5.179324e-02 |  3.253743e-02 |  1.157061e-01 |     0.2820907 | 6602.848 | 0.9998646 | beta_x[2]    |\n",
       "|  3.515204e-04 | 0.001721290 |  0.14014626 | -2.797585e-01 | -9.203945e-02 |  1.634337e-03 |  9.428319e-02 |     0.2658401 | 6629.108 | 0.9991067 | alpha_x[9]   |\n",
       "|  4.332607e-03 | 0.001766777 |  0.14408250 | -2.840461e-01 | -9.250645e-02 |  6.421033e-03 |  1.024955e-01 |     0.2939405 | 6650.575 | 0.9997161 | alpha_x[23]  |\n",
       "|  1.333776e-02 | 0.001737981 |  0.14205747 | -2.654144e-01 | -8.222197e-02 |  1.526494e-02 |  1.089499e-01 |     0.2843003 | 6680.947 | 1.0002679 | alpha_x[7]   |\n",
       "|  3.441801e-02 | 0.001550895 |  0.12711050 | -2.140593e-01 | -5.450287e-02 |  3.434621e-02 |  1.218888e-01 |     0.2841969 | 6717.347 | 0.9997828 | beta_x[14]   |\n",
       "| -1.239817e-02 | 0.001385223 |  0.11423317 | -2.329569e-01 | -9.004257e-02 | -1.201095e-02 |  6.317291e-02 |     0.2151188 | 6800.570 | 0.9992704 | beta_x[9]    |\n",
       "|  1.298107e-03 | 0.001727749 |  0.14274610 | -2.706598e-01 | -9.689443e-02 | -3.378894e-06 |  9.784260e-02 |     0.2841442 | 6826.016 | 0.9999437 | alpha_x[19]  |\n",
       "| -2.051336e-03 | 0.001699314 |  0.14059100 | -2.801947e-01 | -9.708751e-02 | -2.346416e-04 |  9.178368e-02 |     0.2776207 | 6844.910 | 0.9993639 | alpha_x[14]  |\n",
       "|  7.793788e-03 | 0.001765485 |  0.14654324 | -2.758648e-01 | -9.202582e-02 |  9.781096e-03 |  1.094706e-01 |     0.2895790 | 6889.748 | 0.9996283 | alpha_x[5]   |\n",
       "|  5.466381e-03 | 0.001714228 |  0.14336744 | -2.742340e-01 | -9.190501e-02 |  7.102451e-03 |  1.011554e-01 |     0.2842708 | 6994.620 | 0.9999013 | alpha_x[12]  |\n",
       "|  2.424531e-03 | 0.001654452 |  0.13944185 | -2.679761e-01 | -9.230852e-02 |  3.487837e-03 |  9.877493e-02 |     0.2681630 | 7103.589 | 0.9994436 | alpha_x[13]  |\n",
       "| -3.694040e-02 | 0.001410554 |  0.12076619 | -2.822719e-01 | -1.165492e-01 | -3.619397e-02 |  4.488197e-02 |     0.1966121 | 7330.128 | 0.9999784 | beta_x[16]   |\n",
       "|  5.309610e-03 | 0.001641204 |  0.14345825 | -2.770961e-01 | -8.766737e-02 |  6.776567e-03 |  1.016101e-01 |     0.2786737 | 7640.577 | 1.0001811 | alpha_x[8]   |\n",
       "| -6.640138e-03 | 0.001573565 |  0.14017603 | -2.805967e-01 | -1.014490e-01 | -6.616993e-03 |  8.962122e-02 |     0.2623956 | 7935.566 | 0.9991331 | alpha_x[3]   |\n",
       "\n"
      ],
      "text/plain": [
       "   mean          se_mean     sd          X2.5.         X25.         \n",
       "1  -3.694043e+03 0.139065514  5.39343410 -3.705574e+03 -3.697444e+03\n",
       "2   2.681259e-01 0.001483467  0.05872571  1.609705e-01  2.293913e-01\n",
       "3   1.878750e+01 0.219294548 13.62029644  2.406392e+00  8.568944e+00\n",
       "4   1.811881e-01 0.001816480  0.12429340 -5.513418e-02  9.596770e-02\n",
       "5   1.931798e-02 0.002043035  0.14244069 -2.639041e-01 -7.673743e-02\n",
       "6   4.437609e-03 0.002009471  0.14367672 -2.724323e-01 -9.384180e-02\n",
       "7  -5.477411e-03 0.001772377  0.12674483 -2.597522e-01 -9.005103e-02\n",
       "8   5.339711e-01 0.002126222  0.15318093  2.426675e-01  4.318015e-01\n",
       "9   1.880705e-01 0.001803564  0.13038177 -6.292559e-02  9.761283e-02\n",
       "10  4.873805e-01 0.001993544  0.14416563  2.227174e-01  3.903584e-01\n",
       "11 -2.070250e-04 0.001990974  0.14450157 -2.808962e-01 -9.899121e-02\n",
       "12  5.987635e-01 0.002168721  0.15780673  3.047517e-01  4.921155e-01\n",
       "13 -6.983727e-02 0.001644516  0.12082988 -3.083429e-01 -1.493879e-01\n",
       "14  8.055559e-03 0.001930238  0.14231742 -2.707388e-01 -8.652435e-02\n",
       "15 -1.921813e-04 0.001981764  0.14718198 -2.877378e-01 -9.980865e-02\n",
       "16  5.515186e-01 0.002032523  0.15354231  2.620712e-01  4.478194e-01\n",
       "17  8.004495e-02 0.001559144  0.11784496 -1.445071e-01  7.855911e-04\n",
       "18  1.580806e-01 0.001780630  0.13512904 -9.744717e-02  6.742447e-02\n",
       "19  3.788762e-01 0.001818174  0.13877342  1.160424e-01  2.841536e-01\n",
       "20  4.475000e-01 0.001865530  0.14268719  1.752023e-01  3.500616e-01\n",
       "21 -1.893604e-04 0.001784458  0.13651240 -2.596175e-01 -9.214229e-02\n",
       "22  7.100882e-02 0.001583049  0.12157785 -1.637172e-01 -1.301007e-02\n",
       "23  3.415269e-02 0.001536114  0.11850542 -1.989191e-01 -4.279894e-02\n",
       "24  3.675242e-02 0.001545242  0.11921994 -1.998551e-01 -4.345446e-02\n",
       "25 -8.967227e-02 0.001897032  0.14640767 -3.767911e-01 -1.873004e-01\n",
       "26 -5.552915e-03 0.001664325  0.12913183 -2.527363e-01 -9.251236e-02\n",
       "27 -1.133648e-02 0.001845666  0.14358068 -2.962971e-01 -1.110652e-01\n",
       "28  8.615847e-03 0.001525538  0.11875165 -2.263614e-01 -7.015550e-02\n",
       "29  2.487583e-02 0.001867354  0.14571624 -2.633765e-01 -7.152704e-02\n",
       "30  1.923845e-02 0.001592230  0.12447101 -2.280307e-01 -6.301956e-02\n",
       "31  5.047697e-04 0.001774834  0.13920318 -2.664362e-01 -9.359658e-02\n",
       "32  2.393409e-01 0.001678456  0.13274093 -1.179518e-02  1.485488e-01\n",
       "33 -4.966920e-03 0.001753106  0.13937443 -2.762711e-01 -9.375960e-02\n",
       "34 -2.027899e-03 0.001771000  0.14080904 -2.782749e-01 -9.885931e-02\n",
       "35  4.488737e-04 0.001819141  0.14490523 -2.864172e-01 -9.480939e-02\n",
       "36  4.342524e-02 0.001560231  0.12429871 -2.010399e-01 -4.108168e-02\n",
       "37  2.697834e-02 0.001765134  0.14095871 -2.538554e-01 -6.878633e-02\n",
       "38 -4.089823e-03 0.001791085  0.14312333 -2.769803e-01 -1.036339e-01\n",
       "39  2.312810e-01 0.001666275  0.13377666 -1.980816e-02  1.405008e-01\n",
       "40 -2.443225e-03 0.001745535  0.14046526 -2.773382e-01 -9.654538e-02\n",
       "41  1.515319e-01 0.001650676  0.13293022 -1.075566e-01  6.064673e-02\n",
       "42 -5.097384e-02 0.001509994  0.12196100 -2.947551e-01 -1.340074e-01\n",
       "43  4.974161e-03 0.001728490  0.14001928 -2.751225e-01 -8.849035e-02\n",
       "44  3.356031e-02 0.001541492  0.12525838 -2.067778e-01 -5.179324e-02\n",
       "45  3.515204e-04 0.001721290  0.14014626 -2.797585e-01 -9.203945e-02\n",
       "46  4.332607e-03 0.001766777  0.14408250 -2.840461e-01 -9.250645e-02\n",
       "47  1.333776e-02 0.001737981  0.14205747 -2.654144e-01 -8.222197e-02\n",
       "48  3.441801e-02 0.001550895  0.12711050 -2.140593e-01 -5.450287e-02\n",
       "49 -1.239817e-02 0.001385223  0.11423317 -2.329569e-01 -9.004257e-02\n",
       "50  1.298107e-03 0.001727749  0.14274610 -2.706598e-01 -9.689443e-02\n",
       "51 -2.051336e-03 0.001699314  0.14059100 -2.801947e-01 -9.708751e-02\n",
       "52  7.793788e-03 0.001765485  0.14654324 -2.758648e-01 -9.202582e-02\n",
       "53  5.466381e-03 0.001714228  0.14336744 -2.742340e-01 -9.190501e-02\n",
       "54  2.424531e-03 0.001654452  0.13944185 -2.679761e-01 -9.230852e-02\n",
       "55 -3.694040e-02 0.001410554  0.12076619 -2.822719e-01 -1.165492e-01\n",
       "56  5.309610e-03 0.001641204  0.14345825 -2.770961e-01 -8.766737e-02\n",
       "57 -6.640138e-03 0.001573565  0.14017603 -2.805967e-01 -1.014490e-01\n",
       "   X50.          X75.          X97.5.        n_eff    Rhat      PARAM       \n",
       "1  -3.693760e+03 -3.690293e+03 -3684.3347002 1504.152 1.0021703 lp__        \n",
       "2   2.645376e-01  3.036082e-01     0.3939789 1567.115 1.0029695 sigma_beta_x\n",
       "3   1.574409e+01  2.560232e+01    52.7420476 3857.602 1.0004976 nu_x        \n",
       "4   1.786721e-01  2.645823e-01     0.4317490 4682.038 0.9992651 beta_x[25]  \n",
       "5   1.977823e-02  1.131703e-01     0.3018738 4860.899 0.9994084 alpha_x[25] \n",
       "6   2.133610e-03  1.019685e-01     0.2853517 5112.219 0.9995786 alpha_x[17] \n",
       "7  -3.973641e-03  7.892909e-02     0.2380191 5113.853 0.9999204 beta_x[26]  \n",
       "8   5.285661e-01  6.336679e-01     0.8526565 5190.296 0.9997843 beta_x[5]   \n",
       "9   1.874869e-01  2.740039e-01     0.4439048 5226.013 0.9998307 beta_x[6]   \n",
       "10  4.817169e-01  5.787177e-01     0.7833939 5229.638 0.9991161 beta_x[12]  \n",
       "11 -9.194523e-04  9.623437e-02     0.2853550 5267.614 0.9995539 alpha_x[27] \n",
       "12  5.981408e-01  7.000868e-01     0.9223027 5294.726 0.9993473 beta_x[20]  \n",
       "13 -6.865519e-02  1.269237e-02     0.1553524 5398.495 1.0000847 beta_x[1]   \n",
       "14  7.731701e-03  1.040878e-01     0.2889571 5436.185 0.9997446 alpha_x[6]  \n",
       "15  1.159780e-03  9.948430e-02     0.2801377 5515.762 1.0003310 alpha_x[18] \n",
       "16  5.483834e-01  6.515272e-01     0.8647490 5706.705 0.9999950 beta_x[24]  \n",
       "17  7.934599e-02  1.574930e-01     0.3154096 5712.809 0.9994538 beta_x[8]   \n",
       "18  1.550030e-01  2.444554e-01     0.4337151 5759.042 0.9993634 beta_x[27]  \n",
       "19  3.778969e-01  4.735805e-01     0.6480720 5825.615 0.9997851 beta_x[4]   \n",
       "20  4.489592e-01  5.400916e-01     0.7279739 5850.132 0.9996292 beta_x[23]  \n",
       "21 -1.978811e-03  9.216000e-02     0.2656803 5852.368 0.9992460 alpha_x[26] \n",
       "22  6.934470e-02  1.505074e-01     0.3161093 5898.211 0.9996924 beta_x[10]  \n",
       "23  3.521344e-02  1.114238e-01     0.2625607 5951.544 0.9994713 beta_x[13]  \n",
       "24  3.554797e-02  1.163678e-01     0.2769094 5952.575 0.9994650 beta_x[11]  \n",
       "25 -8.893106e-02  7.151570e-03     0.1938974 5956.325 0.9997891 alpha_x[24] \n",
       "26 -5.316749e-03  8.058979e-02     0.2462845 6019.913 0.9992574 beta_x[18]  \n",
       "27 -1.054123e-02  8.894128e-02     0.2696808 6051.814 1.0003480 alpha_x[22] \n",
       "28  9.341125e-03  8.853026e-02     0.2454911 6059.449 1.0000891 beta_x[21]  \n",
       "29  2.695890e-02  1.240579e-01     0.3118293 6089.234 0.9995725 alpha_x[20] \n",
       "30  1.824892e-02  9.877477e-02     0.2636860 6111.174 1.0008442 beta_x[19]  \n",
       "31 -8.334970e-04  9.681978e-02     0.2748681 6151.528 0.9993391 alpha_x[11] \n",
       "32  2.368233e-01  3.278915e-01     0.5027814 6254.459 0.9997467 beta_x[7]   \n",
       "33 -7.227510e-03  8.698692e-02     0.2774669 6320.478 0.9996633 alpha_x[16] \n",
       "34 -3.695056e-03  9.470729e-02     0.2807672 6321.552 0.9998328 alpha_x[2]  \n",
       "35  4.422779e-05  9.620502e-02     0.2891766 6345.053 0.9995207 alpha_x[21] \n",
       "36  4.431161e-02  1.261176e-01     0.2844477 6346.810 0.9997678 beta_x[15]  \n",
       "37  2.845588e-02  1.225377e-01     0.2965730 6377.177 0.9997299 alpha_x[4]  \n",
       "38 -7.339113e-03  9.355727e-02     0.2795035 6385.403 0.9999986 alpha_x[15] \n",
       "39  2.293622e-01  3.213096e-01     0.5058789 6445.660 1.0003192 beta_x[22]  \n",
       "40 -1.443324e-03  8.888806e-02     0.2779728 6475.613 0.9994681 alpha_x[1]  \n",
       "41  1.500917e-01  2.385654e-01     0.4196849 6485.203 0.9997378 beta_x[17]  \n",
       "42 -5.050020e-02  3.341235e-02     0.1819829 6523.666 1.0006353 beta_x[3]   \n",
       "43  4.589035e-03  9.709798e-02     0.2784897 6562.084 1.0000728 alpha_x[10] \n",
       "44  3.253743e-02  1.157061e-01     0.2820907 6602.848 0.9998646 beta_x[2]   \n",
       "45  1.634337e-03  9.428319e-02     0.2658401 6629.108 0.9991067 alpha_x[9]  \n",
       "46  6.421033e-03  1.024955e-01     0.2939405 6650.575 0.9997161 alpha_x[23] \n",
       "47  1.526494e-02  1.089499e-01     0.2843003 6680.947 1.0002679 alpha_x[7]  \n",
       "48  3.434621e-02  1.218888e-01     0.2841969 6717.347 0.9997828 beta_x[14]  \n",
       "49 -1.201095e-02  6.317291e-02     0.2151188 6800.570 0.9992704 beta_x[9]   \n",
       "50 -3.378894e-06  9.784260e-02     0.2841442 6826.016 0.9999437 alpha_x[19] \n",
       "51 -2.346416e-04  9.178368e-02     0.2776207 6844.910 0.9993639 alpha_x[14] \n",
       "52  9.781096e-03  1.094706e-01     0.2895790 6889.748 0.9996283 alpha_x[5]  \n",
       "53  7.102451e-03  1.011554e-01     0.2842708 6994.620 0.9999013 alpha_x[12] \n",
       "54  3.487837e-03  9.877493e-02     0.2681630 7103.589 0.9994436 alpha_x[13] \n",
       "55 -3.619397e-02  4.488197e-02     0.1966121 7330.128 0.9999784 beta_x[16]  \n",
       "56  6.776567e-03  1.016101e-01     0.2786737 7640.577 1.0001811 alpha_x[8]  \n",
       "57 -6.616993e-03  8.962122e-02     0.2623956 7935.566 0.9991331 alpha_x[3]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_sum = data.frame(summary(stage_2_fit)$summary) \n",
    "df_sum$PARAM = rownames(summary(stage_2_fit)$summary)\n",
    "df_sum %>% arrange(n_eff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run both models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_summary_table_beta = function(fit,metabolites) {\n",
    "    df_summary = data.frame(summary(fit)$summary)\n",
    "    post = rstan::extract(fit)\n",
    "    #compute prob > 0 or prob < 0\n",
    "    n_sample = dim(post$beta_x)[1]\n",
    "    g0 = colSums( (post$beta_x > 0) ) / n_sample \n",
    "    l0 = colSums( (post$beta_x < 0) ) / n_sample\n",
    "    df_prob = data.frame(G0=g0,L0=l0) %>% rowwise() %>% mutate(Max=max(G0,L0))\n",
    "    beta_names = c()\n",
    "    for(i in seq(0,dim(post$beta_x)[2])) {\n",
    "        beta_names=c(beta_names,paste0('beta_x[',i,']'))\n",
    "    }\n",
    "    df_summary_beta = df_summary %>% mutate(Param = rownames(.)) %>% \n",
    "    filter(Param %in% beta_names) %>% cbind(Metabolite = metabolites, P_GT_LT_0=df_prob$Max) %>%\n",
    "    mutate(Z=mean/sd) %>% arrange(-P_GT_LT_0, -abs(Z)) %>% select(Metabolite,Param,mean,sd,X2.5.,X50.,X97.5.,Rhat,Z,P_GT_LT_0)\n",
    "    return(df_summary_beta)   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_bayes_model = function(df_censored,metabolites,cores=4,chains=4,iter=2000, \n",
    "                           adapt_delta=0.8,\n",
    "                           max_treedepth=10) {\n",
    "    x_censored = df_censored[, metabolites]\n",
    "    y = df_censored$died_90_day\n",
    "    \n",
    "    stage_1_data = stage_1_impute_make_data(x_censored, y, N_use_impute=8)\n",
    "    stage_1_init_data = replicate_init(\n",
    "        stage_1_impute_get_init_vals(stage_1_data), chains=4\n",
    "    )\n",
    "    \n",
    "    control = list(adapt_delta=adapt_delta,max_treedepth=max_treedepth)\n",
    "    print(\"CONTROL\")\n",
    "    print(control)\n",
    "    \n",
    "    N_miss = stage_1_data$N_miss\n",
    "    stage_1_fit = NULL\n",
    "    stage_1_post = NULL\n",
    "    if(N_miss > 0) {\n",
    "        print(\"IMPUTING\")\n",
    "        stage_1_fit = sampling(stage_1_impute_model,  data = stage_1_data, init=stage_1_init_data, cores=cores, chains=chains, iter = iter,\n",
    "                             control = control )\n",
    "\n",
    "        stage_1_post = extract(stage_1_fit)\n",
    "    } else {\n",
    "        print(\"NO MISING DATA SKIPPING IMPUTATION\")\n",
    "    }\n",
    "    \n",
    "    stage_2_data = stage_2_regress_make_data(x_censored, y, IMPUTE_FUNC = stage_1_impute, stage_1_post=stage_1_post)\n",
    "    stage_2_init = list(\n",
    "        x_impute_raw = stage_2_data$x_missing_init_raw\n",
    "    )\n",
    "    \n",
    "    stage_2_init = replicate_init(\n",
    "        list(\n",
    "            x_impute_raw = stage_2_data$x_missing_init_raw\n",
    "        ), chains=4\n",
    "    )\n",
    "    \n",
    "    \n",
    "    stage_2_fit = sampling(stage_2_regress_model,  data = stage_2_data, init=stage_2_init, cores=cores, chains=chains, iter = iter, control = control )\n",
    "\n",
    "    \n",
    "    sum_table = make_summary_table_beta(stage_2_fit,metabolites)\n",
    "    rownames(sum_table) = sum_table$Metabolite\n",
    "    list( sum_table=sum_table, stage_1_fit=stage_1_fit, stage_2_fit=stage_2_fit)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAADAFBMVEUAAAABAQECAgIDAwME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\nJMACQgIsICTAAkICLCAkwAJCAiz4/+peNvJx4GlyAAAAAElFTkSuQmCC",
      "text/plain": [
       "Plot with title “Histogram of rstan::extract(stage_2_fit)$sigma_beta_x”"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 420,
       "width": 420
      },
      "text/plain": {
       "height": 420,
       "width": 420
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hist(rstan::extract(stage_2_fit)$sigma_beta_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A data.frame: 27 × 10</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>Metabolite</th><th scope=col>Param</th><th scope=col>mean</th><th scope=col>sd</th><th scope=col>X2.5.</th><th scope=col>X50.</th><th scope=col>X97.5.</th><th scope=col>Rhat</th><th scope=col>Z</th><th scope=col>P_GT_LT_0</th></tr>\n",
       "\t<tr><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>oacetylcarnitine </td><td>beta_x[20]</td><td> 0.598763494</td><td>0.1578067</td><td> 0.30475169</td><td> 0.598140772</td><td>0.9223027</td><td>0.9993473</td><td> 3.79428367</td><td>1.00000</td></tr>\n",
       "\t<tr><td>propyleneglycol  </td><td>beta_x[24]</td><td> 0.551518558</td><td>0.1535423</td><td> 0.26207118</td><td> 0.548383392</td><td>0.8647490</td><td>0.9999950</td><td> 3.59196464</td><td>1.00000</td></tr>\n",
       "\t<tr><td>glutamine        </td><td>beta_x[12]</td><td> 0.487380522</td><td>0.1441656</td><td> 0.22271744</td><td> 0.481716928</td><td>0.7833939</td><td>0.9991161</td><td> 3.38069848</td><td>1.00000</td></tr>\n",
       "\t<tr><td>betaine          </td><td>beta_x[5] </td><td> 0.533971086</td><td>0.1531809</td><td> 0.24266747</td><td> 0.528566102</td><td>0.8526565</td><td>0.9997843</td><td> 3.48588486</td><td>0.99975</td></tr>\n",
       "\t<tr><td>proline          </td><td>beta_x[23]</td><td> 0.447500043</td><td>0.1426872</td><td> 0.17520225</td><td> 0.448959221</td><td>0.7279739</td><td>0.9996292</td><td> 3.13623142</td><td>0.99975</td></tr>\n",
       "\t<tr><td>alanine          </td><td>beta_x[4] </td><td> 0.378876157</td><td>0.1387734</td><td> 0.11604238</td><td> 0.377896924</td><td>0.6480720</td><td>0.9997851</td><td> 2.73017810</td><td>0.99800</td></tr>\n",
       "\t<tr><td>choline          </td><td>beta_x[7] </td><td> 0.239340931</td><td>0.1327409</td><td>-0.01179518</td><td> 0.236823280</td><td>0.5027814</td><td>0.9997467</td><td> 1.80306800</td><td>0.96950</td></tr>\n",
       "\t<tr><td>phenylalanine    </td><td>beta_x[22]</td><td> 0.231281050</td><td>0.1337767</td><td>-0.01980816</td><td> 0.229362220</td><td>0.5058789</td><td>1.0003192</td><td> 1.72885950</td><td>0.96325</td></tr>\n",
       "\t<tr><td>pyruvate         </td><td>beta_x[25]</td><td> 0.181188076</td><td>0.1242934</td><td>-0.05513418</td><td> 0.178672112</td><td>0.4317490</td><td>0.9992651</td><td> 1.45774497</td><td>0.92575</td></tr>\n",
       "\t<tr><td>carnitine        </td><td>beta_x[6] </td><td> 0.188070455</td><td>0.1303818</td><td>-0.06292559</td><td> 0.187486855</td><td>0.4439048</td><td>0.9998307</td><td> 1.44245979</td><td>0.92475</td></tr>\n",
       "\t<tr><td>valine           </td><td>beta_x[27]</td><td> 0.158080609</td><td>0.1351290</td><td>-0.09744717</td><td> 0.155002995</td><td>0.4337151</td><td>0.9993634</td><td> 1.16984925</td><td>0.88650</td></tr>\n",
       "\t<tr><td>leucine          </td><td>beta_x[17]</td><td> 0.151531909</td><td>0.1329302</td><td>-0.10755660</td><td> 0.150091671</td><td>0.4196849</td><td>0.9997378</td><td> 1.13993572</td><td>0.87700</td></tr>\n",
       "\t<tr><td>citrate          </td><td>beta_x[8] </td><td> 0.080044953</td><td>0.1178450</td><td>-0.14450714</td><td> 0.079345993</td><td>0.3154096</td><td>0.9994538</td><td> 0.67923953</td><td>0.75150</td></tr>\n",
       "\t<tr><td>hydroxybutyrate  </td><td>beta_x[1] </td><td>-0.069837272</td><td>0.1208299</td><td>-0.30834294</td><td>-0.068655189</td><td>0.1553524</td><td>1.0000847</td><td>-0.57798016</td><td>0.72050</td></tr>\n",
       "\t<tr><td>creatinine       </td><td>beta_x[10]</td><td> 0.071008820</td><td>0.1215778</td><td>-0.16371717</td><td> 0.069344698</td><td>0.3161093</td><td>0.9996924</td><td> 0.58406052</td><td>0.71400</td></tr>\n",
       "\t<tr><td>X3.hydoxybutyrate</td><td>beta_x[3] </td><td>-0.050973838</td><td>0.1219610</td><td>-0.29475512</td><td>-0.050500196</td><td>0.1819829</td><td>1.0006353</td><td>-0.41795196</td><td>0.66175</td></tr>\n",
       "\t<tr><td>isoleucine       </td><td>beta_x[15]</td><td> 0.043425243</td><td>0.1242987</td><td>-0.20103988</td><td> 0.044311607</td><td>0.2844477</td><td>0.9997678</td><td> 0.34936197</td><td>0.64275</td></tr>\n",
       "\t<tr><td>glycine          </td><td>beta_x[13]</td><td> 0.034152689</td><td>0.1185054</td><td>-0.19891905</td><td> 0.035213439</td><td>0.2625607</td><td>0.9994713</td><td> 0.28819517</td><td>0.62525</td></tr>\n",
       "\t<tr><td>glucose          </td><td>beta_x[11]</td><td> 0.036752423</td><td>0.1192199</td><td>-0.19985507</td><td> 0.035547966</td><td>0.2769094</td><td>0.9994650</td><td> 0.30827412</td><td>0.62200</td></tr>\n",
       "\t<tr><td>lactate          </td><td>beta_x[16]</td><td>-0.036940402</td><td>0.1207662</td><td>-0.28227191</td><td>-0.036193966</td><td>0.1966121</td><td>0.9999784</td><td>-0.30588364</td><td>0.61625</td></tr>\n",
       "\t<tr><td>oxoisocaproate   </td><td>beta_x[2] </td><td> 0.033560308</td><td>0.1252584</td><td>-0.20677780</td><td> 0.032537432</td><td>0.2820907</td><td>0.9998646</td><td> 0.26792865</td><td>0.60575</td></tr>\n",
       "\t<tr><td>histidine        </td><td>beta_x[14]</td><td> 0.034418007</td><td>0.1271105</td><td>-0.21405935</td><td> 0.034346207</td><td>0.2841969</td><td>0.9997828</td><td> 0.27077233</td><td>0.60300</td></tr>\n",
       "\t<tr><td>methionine       </td><td>beta_x[19]</td><td> 0.019238451</td><td>0.1244710</td><td>-0.22803066</td><td> 0.018248916</td><td>0.2636860</td><td>1.0008442</td><td> 0.15456170</td><td>0.56625</td></tr>\n",
       "\t<tr><td>creatine         </td><td>beta_x[9] </td><td>-0.012398169</td><td>0.1142332</td><td>-0.23295689</td><td>-0.012010948</td><td>0.2151188</td><td>0.9992704</td><td>-0.10853388</td><td>0.53875</td></tr>\n",
       "\t<tr><td>ornithine        </td><td>beta_x[21]</td><td> 0.008615847</td><td>0.1187516</td><td>-0.22636143</td><td> 0.009341125</td><td>0.2454911</td><td>1.0000891</td><td> 0.07255349</td><td>0.53825</td></tr>\n",
       "\t<tr><td>lysine           </td><td>beta_x[18]</td><td>-0.005552915</td><td>0.1291318</td><td>-0.25273627</td><td>-0.005316749</td><td>0.2462845</td><td>0.9992574</td><td>-0.04300191</td><td>0.51375</td></tr>\n",
       "\t<tr><td>tyrosine         </td><td>beta_x[26]</td><td>-0.005477411</td><td>0.1267448</td><td>-0.25975215</td><td>-0.003973641</td><td>0.2380191</td><td>0.9999204</td><td>-0.04321605</td><td>0.51100</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 27 × 10\n",
       "\\begin{tabular}{llllllllll}\n",
       " Metabolite & Param & mean & sd & X2.5. & X50. & X97.5. & Rhat & Z & P\\_GT\\_LT\\_0\\\\\n",
       " <fct> & <chr> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t oacetylcarnitine  & beta\\_x{[}20{]} &  0.598763494 & 0.1578067 &  0.30475169 &  0.598140772 & 0.9223027 & 0.9993473 &  3.79428367 & 1.00000\\\\\n",
       "\t propyleneglycol   & beta\\_x{[}24{]} &  0.551518558 & 0.1535423 &  0.26207118 &  0.548383392 & 0.8647490 & 0.9999950 &  3.59196464 & 1.00000\\\\\n",
       "\t glutamine         & beta\\_x{[}12{]} &  0.487380522 & 0.1441656 &  0.22271744 &  0.481716928 & 0.7833939 & 0.9991161 &  3.38069848 & 1.00000\\\\\n",
       "\t betaine           & beta\\_x{[}5{]}  &  0.533971086 & 0.1531809 &  0.24266747 &  0.528566102 & 0.8526565 & 0.9997843 &  3.48588486 & 0.99975\\\\\n",
       "\t proline           & beta\\_x{[}23{]} &  0.447500043 & 0.1426872 &  0.17520225 &  0.448959221 & 0.7279739 & 0.9996292 &  3.13623142 & 0.99975\\\\\n",
       "\t alanine           & beta\\_x{[}4{]}  &  0.378876157 & 0.1387734 &  0.11604238 &  0.377896924 & 0.6480720 & 0.9997851 &  2.73017810 & 0.99800\\\\\n",
       "\t choline           & beta\\_x{[}7{]}  &  0.239340931 & 0.1327409 & -0.01179518 &  0.236823280 & 0.5027814 & 0.9997467 &  1.80306800 & 0.96950\\\\\n",
       "\t phenylalanine     & beta\\_x{[}22{]} &  0.231281050 & 0.1337767 & -0.01980816 &  0.229362220 & 0.5058789 & 1.0003192 &  1.72885950 & 0.96325\\\\\n",
       "\t pyruvate          & beta\\_x{[}25{]} &  0.181188076 & 0.1242934 & -0.05513418 &  0.178672112 & 0.4317490 & 0.9992651 &  1.45774497 & 0.92575\\\\\n",
       "\t carnitine         & beta\\_x{[}6{]}  &  0.188070455 & 0.1303818 & -0.06292559 &  0.187486855 & 0.4439048 & 0.9998307 &  1.44245979 & 0.92475\\\\\n",
       "\t valine            & beta\\_x{[}27{]} &  0.158080609 & 0.1351290 & -0.09744717 &  0.155002995 & 0.4337151 & 0.9993634 &  1.16984925 & 0.88650\\\\\n",
       "\t leucine           & beta\\_x{[}17{]} &  0.151531909 & 0.1329302 & -0.10755660 &  0.150091671 & 0.4196849 & 0.9997378 &  1.13993572 & 0.87700\\\\\n",
       "\t citrate           & beta\\_x{[}8{]}  &  0.080044953 & 0.1178450 & -0.14450714 &  0.079345993 & 0.3154096 & 0.9994538 &  0.67923953 & 0.75150\\\\\n",
       "\t hydroxybutyrate   & beta\\_x{[}1{]}  & -0.069837272 & 0.1208299 & -0.30834294 & -0.068655189 & 0.1553524 & 1.0000847 & -0.57798016 & 0.72050\\\\\n",
       "\t creatinine        & beta\\_x{[}10{]} &  0.071008820 & 0.1215778 & -0.16371717 &  0.069344698 & 0.3161093 & 0.9996924 &  0.58406052 & 0.71400\\\\\n",
       "\t X3.hydoxybutyrate & beta\\_x{[}3{]}  & -0.050973838 & 0.1219610 & -0.29475512 & -0.050500196 & 0.1819829 & 1.0006353 & -0.41795196 & 0.66175\\\\\n",
       "\t isoleucine        & beta\\_x{[}15{]} &  0.043425243 & 0.1242987 & -0.20103988 &  0.044311607 & 0.2844477 & 0.9997678 &  0.34936197 & 0.64275\\\\\n",
       "\t glycine           & beta\\_x{[}13{]} &  0.034152689 & 0.1185054 & -0.19891905 &  0.035213439 & 0.2625607 & 0.9994713 &  0.28819517 & 0.62525\\\\\n",
       "\t glucose           & beta\\_x{[}11{]} &  0.036752423 & 0.1192199 & -0.19985507 &  0.035547966 & 0.2769094 & 0.9994650 &  0.30827412 & 0.62200\\\\\n",
       "\t lactate           & beta\\_x{[}16{]} & -0.036940402 & 0.1207662 & -0.28227191 & -0.036193966 & 0.1966121 & 0.9999784 & -0.30588364 & 0.61625\\\\\n",
       "\t oxoisocaproate    & beta\\_x{[}2{]}  &  0.033560308 & 0.1252584 & -0.20677780 &  0.032537432 & 0.2820907 & 0.9998646 &  0.26792865 & 0.60575\\\\\n",
       "\t histidine         & beta\\_x{[}14{]} &  0.034418007 & 0.1271105 & -0.21405935 &  0.034346207 & 0.2841969 & 0.9997828 &  0.27077233 & 0.60300\\\\\n",
       "\t methionine        & beta\\_x{[}19{]} &  0.019238451 & 0.1244710 & -0.22803066 &  0.018248916 & 0.2636860 & 1.0008442 &  0.15456170 & 0.56625\\\\\n",
       "\t creatine          & beta\\_x{[}9{]}  & -0.012398169 & 0.1142332 & -0.23295689 & -0.012010948 & 0.2151188 & 0.9992704 & -0.10853388 & 0.53875\\\\\n",
       "\t ornithine         & beta\\_x{[}21{]} &  0.008615847 & 0.1187516 & -0.22636143 &  0.009341125 & 0.2454911 & 1.0000891 &  0.07255349 & 0.53825\\\\\n",
       "\t lysine            & beta\\_x{[}18{]} & -0.005552915 & 0.1291318 & -0.25273627 & -0.005316749 & 0.2462845 & 0.9992574 & -0.04300191 & 0.51375\\\\\n",
       "\t tyrosine          & beta\\_x{[}26{]} & -0.005477411 & 0.1267448 & -0.25975215 & -0.003973641 & 0.2380191 & 0.9999204 & -0.04321605 & 0.51100\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 27 × 10\n",
       "\n",
       "| Metabolite &lt;fct&gt; | Param &lt;chr&gt; | mean &lt;dbl&gt; | sd &lt;dbl&gt; | X2.5. &lt;dbl&gt; | X50. &lt;dbl&gt; | X97.5. &lt;dbl&gt; | Rhat &lt;dbl&gt; | Z &lt;dbl&gt; | P_GT_LT_0 &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|\n",
       "| oacetylcarnitine  | beta_x[20] |  0.598763494 | 0.1578067 |  0.30475169 |  0.598140772 | 0.9223027 | 0.9993473 |  3.79428367 | 1.00000 |\n",
       "| propyleneglycol   | beta_x[24] |  0.551518558 | 0.1535423 |  0.26207118 |  0.548383392 | 0.8647490 | 0.9999950 |  3.59196464 | 1.00000 |\n",
       "| glutamine         | beta_x[12] |  0.487380522 | 0.1441656 |  0.22271744 |  0.481716928 | 0.7833939 | 0.9991161 |  3.38069848 | 1.00000 |\n",
       "| betaine           | beta_x[5]  |  0.533971086 | 0.1531809 |  0.24266747 |  0.528566102 | 0.8526565 | 0.9997843 |  3.48588486 | 0.99975 |\n",
       "| proline           | beta_x[23] |  0.447500043 | 0.1426872 |  0.17520225 |  0.448959221 | 0.7279739 | 0.9996292 |  3.13623142 | 0.99975 |\n",
       "| alanine           | beta_x[4]  |  0.378876157 | 0.1387734 |  0.11604238 |  0.377896924 | 0.6480720 | 0.9997851 |  2.73017810 | 0.99800 |\n",
       "| choline           | beta_x[7]  |  0.239340931 | 0.1327409 | -0.01179518 |  0.236823280 | 0.5027814 | 0.9997467 |  1.80306800 | 0.96950 |\n",
       "| phenylalanine     | beta_x[22] |  0.231281050 | 0.1337767 | -0.01980816 |  0.229362220 | 0.5058789 | 1.0003192 |  1.72885950 | 0.96325 |\n",
       "| pyruvate          | beta_x[25] |  0.181188076 | 0.1242934 | -0.05513418 |  0.178672112 | 0.4317490 | 0.9992651 |  1.45774497 | 0.92575 |\n",
       "| carnitine         | beta_x[6]  |  0.188070455 | 0.1303818 | -0.06292559 |  0.187486855 | 0.4439048 | 0.9998307 |  1.44245979 | 0.92475 |\n",
       "| valine            | beta_x[27] |  0.158080609 | 0.1351290 | -0.09744717 |  0.155002995 | 0.4337151 | 0.9993634 |  1.16984925 | 0.88650 |\n",
       "| leucine           | beta_x[17] |  0.151531909 | 0.1329302 | -0.10755660 |  0.150091671 | 0.4196849 | 0.9997378 |  1.13993572 | 0.87700 |\n",
       "| citrate           | beta_x[8]  |  0.080044953 | 0.1178450 | -0.14450714 |  0.079345993 | 0.3154096 | 0.9994538 |  0.67923953 | 0.75150 |\n",
       "| hydroxybutyrate   | beta_x[1]  | -0.069837272 | 0.1208299 | -0.30834294 | -0.068655189 | 0.1553524 | 1.0000847 | -0.57798016 | 0.72050 |\n",
       "| creatinine        | beta_x[10] |  0.071008820 | 0.1215778 | -0.16371717 |  0.069344698 | 0.3161093 | 0.9996924 |  0.58406052 | 0.71400 |\n",
       "| X3.hydoxybutyrate | beta_x[3]  | -0.050973838 | 0.1219610 | -0.29475512 | -0.050500196 | 0.1819829 | 1.0006353 | -0.41795196 | 0.66175 |\n",
       "| isoleucine        | beta_x[15] |  0.043425243 | 0.1242987 | -0.20103988 |  0.044311607 | 0.2844477 | 0.9997678 |  0.34936197 | 0.64275 |\n",
       "| glycine           | beta_x[13] |  0.034152689 | 0.1185054 | -0.19891905 |  0.035213439 | 0.2625607 | 0.9994713 |  0.28819517 | 0.62525 |\n",
       "| glucose           | beta_x[11] |  0.036752423 | 0.1192199 | -0.19985507 |  0.035547966 | 0.2769094 | 0.9994650 |  0.30827412 | 0.62200 |\n",
       "| lactate           | beta_x[16] | -0.036940402 | 0.1207662 | -0.28227191 | -0.036193966 | 0.1966121 | 0.9999784 | -0.30588364 | 0.61625 |\n",
       "| oxoisocaproate    | beta_x[2]  |  0.033560308 | 0.1252584 | -0.20677780 |  0.032537432 | 0.2820907 | 0.9998646 |  0.26792865 | 0.60575 |\n",
       "| histidine         | beta_x[14] |  0.034418007 | 0.1271105 | -0.21405935 |  0.034346207 | 0.2841969 | 0.9997828 |  0.27077233 | 0.60300 |\n",
       "| methionine        | beta_x[19] |  0.019238451 | 0.1244710 | -0.22803066 |  0.018248916 | 0.2636860 | 1.0008442 |  0.15456170 | 0.56625 |\n",
       "| creatine          | beta_x[9]  | -0.012398169 | 0.1142332 | -0.23295689 | -0.012010948 | 0.2151188 | 0.9992704 | -0.10853388 | 0.53875 |\n",
       "| ornithine         | beta_x[21] |  0.008615847 | 0.1187516 | -0.22636143 |  0.009341125 | 0.2454911 | 1.0000891 |  0.07255349 | 0.53825 |\n",
       "| lysine            | beta_x[18] | -0.005552915 | 0.1291318 | -0.25273627 | -0.005316749 | 0.2462845 | 0.9992574 | -0.04300191 | 0.51375 |\n",
       "| tyrosine          | beta_x[26] | -0.005477411 | 0.1267448 | -0.25975215 | -0.003973641 | 0.2380191 | 0.9999204 | -0.04321605 | 0.51100 |\n",
       "\n"
      ],
      "text/plain": [
       "   Metabolite        Param      mean         sd        X2.5.       X50.        \n",
       "1  oacetylcarnitine  beta_x[20]  0.598763494 0.1578067  0.30475169  0.598140772\n",
       "2  propyleneglycol   beta_x[24]  0.551518558 0.1535423  0.26207118  0.548383392\n",
       "3  glutamine         beta_x[12]  0.487380522 0.1441656  0.22271744  0.481716928\n",
       "4  betaine           beta_x[5]   0.533971086 0.1531809  0.24266747  0.528566102\n",
       "5  proline           beta_x[23]  0.447500043 0.1426872  0.17520225  0.448959221\n",
       "6  alanine           beta_x[4]   0.378876157 0.1387734  0.11604238  0.377896924\n",
       "7  choline           beta_x[7]   0.239340931 0.1327409 -0.01179518  0.236823280\n",
       "8  phenylalanine     beta_x[22]  0.231281050 0.1337767 -0.01980816  0.229362220\n",
       "9  pyruvate          beta_x[25]  0.181188076 0.1242934 -0.05513418  0.178672112\n",
       "10 carnitine         beta_x[6]   0.188070455 0.1303818 -0.06292559  0.187486855\n",
       "11 valine            beta_x[27]  0.158080609 0.1351290 -0.09744717  0.155002995\n",
       "12 leucine           beta_x[17]  0.151531909 0.1329302 -0.10755660  0.150091671\n",
       "13 citrate           beta_x[8]   0.080044953 0.1178450 -0.14450714  0.079345993\n",
       "14 hydroxybutyrate   beta_x[1]  -0.069837272 0.1208299 -0.30834294 -0.068655189\n",
       "15 creatinine        beta_x[10]  0.071008820 0.1215778 -0.16371717  0.069344698\n",
       "16 X3.hydoxybutyrate beta_x[3]  -0.050973838 0.1219610 -0.29475512 -0.050500196\n",
       "17 isoleucine        beta_x[15]  0.043425243 0.1242987 -0.20103988  0.044311607\n",
       "18 glycine           beta_x[13]  0.034152689 0.1185054 -0.19891905  0.035213439\n",
       "19 glucose           beta_x[11]  0.036752423 0.1192199 -0.19985507  0.035547966\n",
       "20 lactate           beta_x[16] -0.036940402 0.1207662 -0.28227191 -0.036193966\n",
       "21 oxoisocaproate    beta_x[2]   0.033560308 0.1252584 -0.20677780  0.032537432\n",
       "22 histidine         beta_x[14]  0.034418007 0.1271105 -0.21405935  0.034346207\n",
       "23 methionine        beta_x[19]  0.019238451 0.1244710 -0.22803066  0.018248916\n",
       "24 creatine          beta_x[9]  -0.012398169 0.1142332 -0.23295689 -0.012010948\n",
       "25 ornithine         beta_x[21]  0.008615847 0.1187516 -0.22636143  0.009341125\n",
       "26 lysine            beta_x[18] -0.005552915 0.1291318 -0.25273627 -0.005316749\n",
       "27 tyrosine          beta_x[26] -0.005477411 0.1267448 -0.25975215 -0.003973641\n",
       "   X97.5.    Rhat      Z           P_GT_LT_0\n",
       "1  0.9223027 0.9993473  3.79428367 1.00000  \n",
       "2  0.8647490 0.9999950  3.59196464 1.00000  \n",
       "3  0.7833939 0.9991161  3.38069848 1.00000  \n",
       "4  0.8526565 0.9997843  3.48588486 0.99975  \n",
       "5  0.7279739 0.9996292  3.13623142 0.99975  \n",
       "6  0.6480720 0.9997851  2.73017810 0.99800  \n",
       "7  0.5027814 0.9997467  1.80306800 0.96950  \n",
       "8  0.5058789 1.0003192  1.72885950 0.96325  \n",
       "9  0.4317490 0.9992651  1.45774497 0.92575  \n",
       "10 0.4439048 0.9998307  1.44245979 0.92475  \n",
       "11 0.4337151 0.9993634  1.16984925 0.88650  \n",
       "12 0.4196849 0.9997378  1.13993572 0.87700  \n",
       "13 0.3154096 0.9994538  0.67923953 0.75150  \n",
       "14 0.1553524 1.0000847 -0.57798016 0.72050  \n",
       "15 0.3161093 0.9996924  0.58406052 0.71400  \n",
       "16 0.1819829 1.0006353 -0.41795196 0.66175  \n",
       "17 0.2844477 0.9997678  0.34936197 0.64275  \n",
       "18 0.2625607 0.9994713  0.28819517 0.62525  \n",
       "19 0.2769094 0.9994650  0.30827412 0.62200  \n",
       "20 0.1966121 0.9999784 -0.30588364 0.61625  \n",
       "21 0.2820907 0.9998646  0.26792865 0.60575  \n",
       "22 0.2841969 0.9997828  0.27077233 0.60300  \n",
       "23 0.2636860 1.0008442  0.15456170 0.56625  \n",
       "24 0.2151188 0.9992704 -0.10853388 0.53875  \n",
       "25 0.2454911 1.0000891  0.07255349 0.53825  \n",
       "26 0.2462845 0.9992574 -0.04300191 0.51375  \n",
       "27 0.2380191 0.9999204 -0.04321605 0.51100  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "make_summary_table_beta(stage_2_fit,metabolites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"CONTROL\"\n",
      "$adapt_delta\n",
      "[1] 0.8\n",
      "\n",
      "$max_treedepth\n",
      "[1] 10\n",
      "\n",
      "[1] \"NO MISING DATA SKIPPING IMPUTATION\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "“Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable.\n",
      "Running the chains for more iterations may help. See\n",
      "http://mc-stan.org/misc/warnings.html#tail-ess”\n"
     ]
    }
   ],
   "source": [
    "bayes_model_res = run_bayes_model(out$df_censored,metabolites,cores=4,chains=4,iter=2000, \n",
    "                           adapt_delta=0.8,\n",
    "                           max_treedepth=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 0\n",
       "2. 0\n",
       "3. 0\n",
       "4. 0\n",
       "5. 0\n",
       "6. 0\n",
       "7. 0\n",
       "8. 0\n",
       "9. 0\n",
       "10. 0\n",
       "11. 0\n",
       "12. 0\n",
       "13. 0\n",
       "14. 0\n",
       "15. 0\n",
       "16. 0\n",
       "17. 0\n",
       "18. 0\n",
       "19. 0\n",
       "20. 0\n",
       "21. 0\n",
       "22. 0\n",
       "23. 0\n",
       "24. 0\n",
       "25. 0\n",
       "26. 0\n",
       "27. 0\n",
       "28. 0\n",
       "29. 0\n",
       "30. 0\n",
       "31. 0\n",
       "32. 0\n",
       "33. 0\n",
       "34. 0\n",
       "35. 0\n",
       "36. 0\n",
       "37. 0\n",
       "38. 0\n",
       "39. 0\n",
       "40. 0\n",
       "41. 0\n",
       "42. 0\n",
       "43. 0\n",
       "44. 0\n",
       "45. 0\n",
       "46. 0\n",
       "47. 0\n",
       "48. 0\n",
       "49. 0\n",
       "50. 0\n",
       "51. 0\n",
       "52. 0\n",
       "53. 0\n",
       "54. 0\n",
       "55. 0\n",
       "56. 0\n",
       "57. 0\n",
       "58. 0\n",
       "59. 0\n",
       "60. 0\n",
       "61. 0\n",
       "62. 0\n",
       "63. 0\n",
       "64. 0\n",
       "65. 0\n",
       "66. 0\n",
       "67. 0\n",
       "68. 0\n",
       "69. 0\n",
       "70. 0\n",
       "71. 0\n",
       "72. 0\n",
       "73. 0\n",
       "74. 0\n",
       "75. 0\n",
       "76. 0\n",
       "77. 0\n",
       "78. 0\n",
       "79. 0\n",
       "80. 0\n",
       "81. 0\n",
       "82. 0\n",
       "83. 0\n",
       "84. 0\n",
       "85. 0\n",
       "86. 0\n",
       "87. 0\n",
       "88. 0\n",
       "89. 0\n",
       "90. 0\n",
       "91. 0\n",
       "92. 0\n",
       "93. 0\n",
       "94. 0\n",
       "95. 0\n",
       "96. 0\n",
       "97. 0\n",
       "98. 0\n",
       "99. 0\n",
       "100. 0\n",
       "101. 0\n",
       "102. 0\n",
       "103. 0\n",
       "104. 0\n",
       "105. 0\n",
       "106. 0\n",
       "107. 0\n",
       "108. 0\n",
       "109. 0\n",
       "110. 0\n",
       "111. 0\n",
       "112. 0\n",
       "113. 0\n",
       "114. 0\n",
       "115. 0\n",
       "116. 0\n",
       "117. 0\n",
       "118. 0\n",
       "119. 0\n",
       "120. 0\n",
       "121. 0\n",
       "122. 0\n",
       "123. 0\n",
       "124. 0\n",
       "125. 0\n",
       "126. 0\n",
       "127. 0\n",
       "128. 0\n",
       "129. 0\n",
       "130. 0\n",
       "131. 0\n",
       "132. 0\n",
       "133. 0\n",
       "134. 0\n",
       "135. 0\n",
       "136. 0\n",
       "137. 0\n",
       "138. 0\n",
       "139. 0\n",
       "140. 0\n",
       "141. 0\n",
       "142. 0\n",
       "143. 0\n",
       "144. 0\n",
       "145. 0\n",
       "146. 0\n",
       "147. 0\n",
       "148. 0\n",
       "149. 0\n",
       "150. 0\n",
       "151. 0\n",
       "152. 0\n",
       "153. 0\n",
       "154. 0\n",
       "155. 0\n",
       "156. 0\n",
       "157. 0\n",
       "158. 0\n",
       "159. 0\n",
       "160. 0\n",
       "161. 0\n",
       "162. 0\n",
       "163. 0\n",
       "164. 0\n",
       "165. 0\n",
       "166. 0\n",
       "167. 0\n",
       "168. 0\n",
       "169. 0\n",
       "170. 0\n",
       "171. 0\n",
       "172. 0\n",
       "173. 0\n",
       "174. 0\n",
       "175. 0\n",
       "176. 0\n",
       "177. 0\n",
       "178. 0\n",
       "179. 0\n",
       "180. 0\n",
       "181. 0\n",
       "182. 0\n",
       "183. 0\n",
       "184. 0\n",
       "185. 0\n",
       "186. 0\n",
       "187. 0\n",
       "188. 0\n",
       "189. 0\n",
       "190. 0\n",
       "191. 0\n",
       "192. 0\n",
       "193. 0\n",
       "194. 0\n",
       "195. 0\n",
       "196. 0\n",
       "197. 0\n",
       "198. 0\n",
       "199. 0\n",
       "200. 0\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  [1] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [38] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [75] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       "[112] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       "[149] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       "[186] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "apply( out$df_censored, FUN=function(x) { mean(is.na(x)) }, MARGIN=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>'sum_table'</li><li>'stage_1_fit'</li><li>'stage_2_fit'</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'sum\\_table'\n",
       "\\item 'stage\\_1\\_fit'\n",
       "\\item 'stage\\_2\\_fit'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'sum_table'\n",
       "2. 'stage_1_fit'\n",
       "3. 'stage_2_fit'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"sum_table\"   \"stage_1_fit\" \"stage_2_fit\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "names(bayes_model_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A data.frame: 20 × 11</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>mean</th><th scope=col>se_mean</th><th scope=col>sd</th><th scope=col>X2.5.</th><th scope=col>X25.</th><th scope=col>X50.</th><th scope=col>X75.</th><th scope=col>X97.5.</th><th scope=col>n_eff</th><th scope=col>Rhat</th><th scope=col>PARAM</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td> 2.666445e-01</td><td>0.002463678</td><td> 0.06206117</td><td> 1.328696e-01</td><td> 2.268586e-01</td><td> 2.656609e-01</td><td> 3.055718e-01</td><td>    0.3942095</td><td> 634.5591</td><td>1.0052367</td><td>sigma_beta_x</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>-3.694297e+03</td><td>0.133741148</td><td> 5.42053654</td><td>-3.705736e+03</td><td>-3.697910e+03</td><td>-3.693998e+03</td><td>-3.690474e+03</td><td>-3684.5282425</td><td>1642.6856</td><td>1.0014264</td><td>lp__        </td></tr>\n",
       "\t<tr><th scope=row>3</th><td> 1.821666e+01</td><td>0.276770117</td><td>13.23803835</td><td> 2.091644e+00</td><td> 8.416071e+00</td><td> 1.527438e+01</td><td> 2.495248e+01</td><td>   51.3873414</td><td>2287.7516</td><td>1.0010776</td><td>nu_x        </td></tr>\n",
       "\t<tr><th scope=row>4</th><td> 1.805063e-01</td><td>0.002154834</td><td> 0.12611408</td><td>-6.288948e-02</td><td> 9.641845e-02</td><td> 1.776910e-01</td><td> 2.641735e-01</td><td>    0.4324445</td><td>3425.3061</td><td>1.0010220</td><td>beta_x[25]  </td></tr>\n",
       "\t<tr><th scope=row>5</th><td> 6.077589e-01</td><td>0.002651654</td><td> 0.15864941</td><td> 3.163286e-01</td><td> 4.977810e-01</td><td> 6.070426e-01</td><td> 7.091381e-01</td><td>    0.9318559</td><td>3579.6709</td><td>0.9992719</td><td>beta_x[20]  </td></tr>\n",
       "\t<tr><th scope=row>6</th><td> 2.273991e-01</td><td>0.002183854</td><td> 0.13486477</td><td>-2.411362e-02</td><td> 1.357382e-01</td><td> 2.234030e-01</td><td> 3.197703e-01</td><td>    0.4952082</td><td>3813.7281</td><td>1.0003619</td><td>beta_x[22]  </td></tr>\n",
       "\t<tr><th scope=row>7</th><td>-1.948684e-03</td><td>0.002295566</td><td> 0.14390505</td><td>-2.837969e-01</td><td>-9.752990e-02</td><td>-2.470209e-03</td><td> 9.858648e-02</td><td>    0.2756219</td><td>3929.8193</td><td>0.9993425</td><td>alpha_x[23] </td></tr>\n",
       "\t<tr><th scope=row>8</th><td> 1.859764e-01</td><td>0.002077971</td><td> 0.13061477</td><td>-6.615270e-02</td><td> 9.688145e-02</td><td> 1.851186e-01</td><td> 2.720629e-01</td><td>    0.4462349</td><td>3950.9885</td><td>1.0026073</td><td>beta_x[6]   </td></tr>\n",
       "\t<tr><th scope=row>9</th><td> 8.355839e-03</td><td>0.002296283</td><td> 0.14537967</td><td>-2.689688e-01</td><td>-8.993625e-02</td><td> 4.675868e-03</td><td> 1.046595e-01</td><td>    0.3031569</td><td>4008.2647</td><td>1.0001969</td><td>alpha_x[5]  </td></tr>\n",
       "\t<tr><th scope=row>10</th><td> 4.836811e-01</td><td>0.002245501</td><td> 0.14306462</td><td> 2.124613e-01</td><td> 3.890061e-01</td><td> 4.779772e-01</td><td> 5.748605e-01</td><td>    0.7783925</td><td>4059.1778</td><td>0.9999291</td><td>beta_x[12]  </td></tr>\n",
       "\t<tr><th scope=row>11</th><td> 4.459455e-01</td><td>0.002146246</td><td> 0.13817152</td><td> 1.850931e-01</td><td> 3.517764e-01</td><td> 4.412668e-01</td><td> 5.389415e-01</td><td>    0.7259333</td><td>4144.5570</td><td>1.0005264</td><td>beta_x[23]  </td></tr>\n",
       "\t<tr><th scope=row>12</th><td> 3.747840e-01</td><td>0.002178580</td><td> 0.14301610</td><td> 1.083559e-01</td><td> 2.740038e-01</td><td> 3.707629e-01</td><td> 4.681028e-01</td><td>    0.6720630</td><td>4309.4593</td><td>1.0000537</td><td>beta_x[4]   </td></tr>\n",
       "\t<tr><th scope=row>13</th><td> 2.285250e-03</td><td>0.002110999</td><td> 0.13989517</td><td>-2.707905e-01</td><td>-9.120319e-02</td><td> 3.285005e-03</td><td> 9.741511e-02</td><td>    0.2799969</td><td>4391.6660</td><td>1.0000650</td><td>alpha_x[8]  </td></tr>\n",
       "\t<tr><th scope=row>14</th><td>-9.467682e-02</td><td>0.002250769</td><td> 0.14985753</td><td>-3.887576e-01</td><td>-1.935922e-01</td><td>-9.351785e-02</td><td> 4.255748e-03</td><td>    0.2018424</td><td>4432.9758</td><td>0.9999770</td><td>alpha_x[24] </td></tr>\n",
       "\t<tr><th scope=row>15</th><td>-1.061151e-03</td><td>0.002107106</td><td> 0.14034016</td><td>-2.773884e-01</td><td>-9.747946e-02</td><td>-5.457733e-04</td><td> 9.368277e-02</td><td>    0.2721876</td><td>4435.9980</td><td>0.9996895</td><td>alpha_x[11] </td></tr>\n",
       "\t<tr><th scope=row>16</th><td> 3.327988e-02</td><td>0.001911421</td><td> 0.12763469</td><td>-2.174885e-01</td><td>-5.176958e-02</td><td> 3.139633e-02</td><td> 1.167882e-01</td><td>    0.2894979</td><td>4458.8672</td><td>1.0001066</td><td>beta_x[2]   </td></tr>\n",
       "\t<tr><th scope=row>17</th><td> 1.724547e-02</td><td>0.002124920</td><td> 0.14300469</td><td>-2.629663e-01</td><td>-7.990490e-02</td><td> 1.768786e-02</td><td> 1.151801e-01</td><td>    0.2953089</td><td>4529.1385</td><td>0.9994576</td><td>alpha_x[25] </td></tr>\n",
       "\t<tr><th scope=row>18</th><td>-3.536305e-02</td><td>0.001858035</td><td> 0.12512593</td><td>-2.823228e-01</td><td>-1.194190e-01</td><td>-3.402049e-02</td><td> 4.843645e-02</td><td>    0.2071887</td><td>4535.0988</td><td>0.9994064</td><td>beta_x[16]  </td></tr>\n",
       "\t<tr><th scope=row>19</th><td> 6.252783e-03</td><td>0.002169057</td><td> 0.14638190</td><td>-2.810456e-01</td><td>-9.325424e-02</td><td> 3.764722e-03</td><td> 1.043737e-01</td><td>    0.2955102</td><td>4554.4169</td><td>0.9993877</td><td>alpha_x[10] </td></tr>\n",
       "\t<tr><th scope=row>20</th><td> 8.351808e-03</td><td>0.001761744</td><td> 0.11919547</td><td>-2.287759e-01</td><td>-6.980728e-02</td><td> 7.840889e-03</td><td> 8.719670e-02</td><td>    0.2448817</td><td>4577.5567</td><td>1.0001896</td><td>beta_x[21]  </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 20 × 11\n",
       "\\begin{tabular}{r|lllllllllll}\n",
       "  & mean & se\\_mean & sd & X2.5. & X25. & X50. & X75. & X97.5. & n\\_eff & Rhat & PARAM\\\\\n",
       "  & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <chr>\\\\\n",
       "\\hline\n",
       "\t1 &  2.666445e-01 & 0.002463678 &  0.06206117 &  1.328696e-01 &  2.268586e-01 &  2.656609e-01 &  3.055718e-01 &     0.3942095 &  634.5591 & 1.0052367 & sigma\\_beta\\_x\\\\\n",
       "\t2 & -3.694297e+03 & 0.133741148 &  5.42053654 & -3.705736e+03 & -3.697910e+03 & -3.693998e+03 & -3.690474e+03 & -3684.5282425 & 1642.6856 & 1.0014264 & lp\\_\\_        \\\\\n",
       "\t3 &  1.821666e+01 & 0.276770117 & 13.23803835 &  2.091644e+00 &  8.416071e+00 &  1.527438e+01 &  2.495248e+01 &    51.3873414 & 2287.7516 & 1.0010776 & nu\\_x        \\\\\n",
       "\t4 &  1.805063e-01 & 0.002154834 &  0.12611408 & -6.288948e-02 &  9.641845e-02 &  1.776910e-01 &  2.641735e-01 &     0.4324445 & 3425.3061 & 1.0010220 & beta\\_x{[}25{]}  \\\\\n",
       "\t5 &  6.077589e-01 & 0.002651654 &  0.15864941 &  3.163286e-01 &  4.977810e-01 &  6.070426e-01 &  7.091381e-01 &     0.9318559 & 3579.6709 & 0.9992719 & beta\\_x{[}20{]}  \\\\\n",
       "\t6 &  2.273991e-01 & 0.002183854 &  0.13486477 & -2.411362e-02 &  1.357382e-01 &  2.234030e-01 &  3.197703e-01 &     0.4952082 & 3813.7281 & 1.0003619 & beta\\_x{[}22{]}  \\\\\n",
       "\t7 & -1.948684e-03 & 0.002295566 &  0.14390505 & -2.837969e-01 & -9.752990e-02 & -2.470209e-03 &  9.858648e-02 &     0.2756219 & 3929.8193 & 0.9993425 & alpha\\_x{[}23{]} \\\\\n",
       "\t8 &  1.859764e-01 & 0.002077971 &  0.13061477 & -6.615270e-02 &  9.688145e-02 &  1.851186e-01 &  2.720629e-01 &     0.4462349 & 3950.9885 & 1.0026073 & beta\\_x{[}6{]}   \\\\\n",
       "\t9 &  8.355839e-03 & 0.002296283 &  0.14537967 & -2.689688e-01 & -8.993625e-02 &  4.675868e-03 &  1.046595e-01 &     0.3031569 & 4008.2647 & 1.0001969 & alpha\\_x{[}5{]}  \\\\\n",
       "\t10 &  4.836811e-01 & 0.002245501 &  0.14306462 &  2.124613e-01 &  3.890061e-01 &  4.779772e-01 &  5.748605e-01 &     0.7783925 & 4059.1778 & 0.9999291 & beta\\_x{[}12{]}  \\\\\n",
       "\t11 &  4.459455e-01 & 0.002146246 &  0.13817152 &  1.850931e-01 &  3.517764e-01 &  4.412668e-01 &  5.389415e-01 &     0.7259333 & 4144.5570 & 1.0005264 & beta\\_x{[}23{]}  \\\\\n",
       "\t12 &  3.747840e-01 & 0.002178580 &  0.14301610 &  1.083559e-01 &  2.740038e-01 &  3.707629e-01 &  4.681028e-01 &     0.6720630 & 4309.4593 & 1.0000537 & beta\\_x{[}4{]}   \\\\\n",
       "\t13 &  2.285250e-03 & 0.002110999 &  0.13989517 & -2.707905e-01 & -9.120319e-02 &  3.285005e-03 &  9.741511e-02 &     0.2799969 & 4391.6660 & 1.0000650 & alpha\\_x{[}8{]}  \\\\\n",
       "\t14 & -9.467682e-02 & 0.002250769 &  0.14985753 & -3.887576e-01 & -1.935922e-01 & -9.351785e-02 &  4.255748e-03 &     0.2018424 & 4432.9758 & 0.9999770 & alpha\\_x{[}24{]} \\\\\n",
       "\t15 & -1.061151e-03 & 0.002107106 &  0.14034016 & -2.773884e-01 & -9.747946e-02 & -5.457733e-04 &  9.368277e-02 &     0.2721876 & 4435.9980 & 0.9996895 & alpha\\_x{[}11{]} \\\\\n",
       "\t16 &  3.327988e-02 & 0.001911421 &  0.12763469 & -2.174885e-01 & -5.176958e-02 &  3.139633e-02 &  1.167882e-01 &     0.2894979 & 4458.8672 & 1.0001066 & beta\\_x{[}2{]}   \\\\\n",
       "\t17 &  1.724547e-02 & 0.002124920 &  0.14300469 & -2.629663e-01 & -7.990490e-02 &  1.768786e-02 &  1.151801e-01 &     0.2953089 & 4529.1385 & 0.9994576 & alpha\\_x{[}25{]} \\\\\n",
       "\t18 & -3.536305e-02 & 0.001858035 &  0.12512593 & -2.823228e-01 & -1.194190e-01 & -3.402049e-02 &  4.843645e-02 &     0.2071887 & 4535.0988 & 0.9994064 & beta\\_x{[}16{]}  \\\\\n",
       "\t19 &  6.252783e-03 & 0.002169057 &  0.14638190 & -2.810456e-01 & -9.325424e-02 &  3.764722e-03 &  1.043737e-01 &     0.2955102 & 4554.4169 & 0.9993877 & alpha\\_x{[}10{]} \\\\\n",
       "\t20 &  8.351808e-03 & 0.001761744 &  0.11919547 & -2.287759e-01 & -6.980728e-02 &  7.840889e-03 &  8.719670e-02 &     0.2448817 & 4577.5567 & 1.0001896 & beta\\_x{[}21{]}  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 20 × 11\n",
       "\n",
       "| <!--/--> | mean &lt;dbl&gt; | se_mean &lt;dbl&gt; | sd &lt;dbl&gt; | X2.5. &lt;dbl&gt; | X25. &lt;dbl&gt; | X50. &lt;dbl&gt; | X75. &lt;dbl&gt; | X97.5. &lt;dbl&gt; | n_eff &lt;dbl&gt; | Rhat &lt;dbl&gt; | PARAM &lt;chr&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 1 |  2.666445e-01 | 0.002463678 |  0.06206117 |  1.328696e-01 |  2.268586e-01 |  2.656609e-01 |  3.055718e-01 |     0.3942095 |  634.5591 | 1.0052367 | sigma_beta_x |\n",
       "| 2 | -3.694297e+03 | 0.133741148 |  5.42053654 | -3.705736e+03 | -3.697910e+03 | -3.693998e+03 | -3.690474e+03 | -3684.5282425 | 1642.6856 | 1.0014264 | lp__         |\n",
       "| 3 |  1.821666e+01 | 0.276770117 | 13.23803835 |  2.091644e+00 |  8.416071e+00 |  1.527438e+01 |  2.495248e+01 |    51.3873414 | 2287.7516 | 1.0010776 | nu_x         |\n",
       "| 4 |  1.805063e-01 | 0.002154834 |  0.12611408 | -6.288948e-02 |  9.641845e-02 |  1.776910e-01 |  2.641735e-01 |     0.4324445 | 3425.3061 | 1.0010220 | beta_x[25]   |\n",
       "| 5 |  6.077589e-01 | 0.002651654 |  0.15864941 |  3.163286e-01 |  4.977810e-01 |  6.070426e-01 |  7.091381e-01 |     0.9318559 | 3579.6709 | 0.9992719 | beta_x[20]   |\n",
       "| 6 |  2.273991e-01 | 0.002183854 |  0.13486477 | -2.411362e-02 |  1.357382e-01 |  2.234030e-01 |  3.197703e-01 |     0.4952082 | 3813.7281 | 1.0003619 | beta_x[22]   |\n",
       "| 7 | -1.948684e-03 | 0.002295566 |  0.14390505 | -2.837969e-01 | -9.752990e-02 | -2.470209e-03 |  9.858648e-02 |     0.2756219 | 3929.8193 | 0.9993425 | alpha_x[23]  |\n",
       "| 8 |  1.859764e-01 | 0.002077971 |  0.13061477 | -6.615270e-02 |  9.688145e-02 |  1.851186e-01 |  2.720629e-01 |     0.4462349 | 3950.9885 | 1.0026073 | beta_x[6]    |\n",
       "| 9 |  8.355839e-03 | 0.002296283 |  0.14537967 | -2.689688e-01 | -8.993625e-02 |  4.675868e-03 |  1.046595e-01 |     0.3031569 | 4008.2647 | 1.0001969 | alpha_x[5]   |\n",
       "| 10 |  4.836811e-01 | 0.002245501 |  0.14306462 |  2.124613e-01 |  3.890061e-01 |  4.779772e-01 |  5.748605e-01 |     0.7783925 | 4059.1778 | 0.9999291 | beta_x[12]   |\n",
       "| 11 |  4.459455e-01 | 0.002146246 |  0.13817152 |  1.850931e-01 |  3.517764e-01 |  4.412668e-01 |  5.389415e-01 |     0.7259333 | 4144.5570 | 1.0005264 | beta_x[23]   |\n",
       "| 12 |  3.747840e-01 | 0.002178580 |  0.14301610 |  1.083559e-01 |  2.740038e-01 |  3.707629e-01 |  4.681028e-01 |     0.6720630 | 4309.4593 | 1.0000537 | beta_x[4]    |\n",
       "| 13 |  2.285250e-03 | 0.002110999 |  0.13989517 | -2.707905e-01 | -9.120319e-02 |  3.285005e-03 |  9.741511e-02 |     0.2799969 | 4391.6660 | 1.0000650 | alpha_x[8]   |\n",
       "| 14 | -9.467682e-02 | 0.002250769 |  0.14985753 | -3.887576e-01 | -1.935922e-01 | -9.351785e-02 |  4.255748e-03 |     0.2018424 | 4432.9758 | 0.9999770 | alpha_x[24]  |\n",
       "| 15 | -1.061151e-03 | 0.002107106 |  0.14034016 | -2.773884e-01 | -9.747946e-02 | -5.457733e-04 |  9.368277e-02 |     0.2721876 | 4435.9980 | 0.9996895 | alpha_x[11]  |\n",
       "| 16 |  3.327988e-02 | 0.001911421 |  0.12763469 | -2.174885e-01 | -5.176958e-02 |  3.139633e-02 |  1.167882e-01 |     0.2894979 | 4458.8672 | 1.0001066 | beta_x[2]    |\n",
       "| 17 |  1.724547e-02 | 0.002124920 |  0.14300469 | -2.629663e-01 | -7.990490e-02 |  1.768786e-02 |  1.151801e-01 |     0.2953089 | 4529.1385 | 0.9994576 | alpha_x[25]  |\n",
       "| 18 | -3.536305e-02 | 0.001858035 |  0.12512593 | -2.823228e-01 | -1.194190e-01 | -3.402049e-02 |  4.843645e-02 |     0.2071887 | 4535.0988 | 0.9994064 | beta_x[16]   |\n",
       "| 19 |  6.252783e-03 | 0.002169057 |  0.14638190 | -2.810456e-01 | -9.325424e-02 |  3.764722e-03 |  1.043737e-01 |     0.2955102 | 4554.4169 | 0.9993877 | alpha_x[10]  |\n",
       "| 20 |  8.351808e-03 | 0.001761744 |  0.11919547 | -2.287759e-01 | -6.980728e-02 |  7.840889e-03 |  8.719670e-02 |     0.2448817 | 4577.5567 | 1.0001896 | beta_x[21]   |\n",
       "\n"
      ],
      "text/plain": [
       "   mean          se_mean     sd          X2.5.         X25.         \n",
       "1   2.666445e-01 0.002463678  0.06206117  1.328696e-01  2.268586e-01\n",
       "2  -3.694297e+03 0.133741148  5.42053654 -3.705736e+03 -3.697910e+03\n",
       "3   1.821666e+01 0.276770117 13.23803835  2.091644e+00  8.416071e+00\n",
       "4   1.805063e-01 0.002154834  0.12611408 -6.288948e-02  9.641845e-02\n",
       "5   6.077589e-01 0.002651654  0.15864941  3.163286e-01  4.977810e-01\n",
       "6   2.273991e-01 0.002183854  0.13486477 -2.411362e-02  1.357382e-01\n",
       "7  -1.948684e-03 0.002295566  0.14390505 -2.837969e-01 -9.752990e-02\n",
       "8   1.859764e-01 0.002077971  0.13061477 -6.615270e-02  9.688145e-02\n",
       "9   8.355839e-03 0.002296283  0.14537967 -2.689688e-01 -8.993625e-02\n",
       "10  4.836811e-01 0.002245501  0.14306462  2.124613e-01  3.890061e-01\n",
       "11  4.459455e-01 0.002146246  0.13817152  1.850931e-01  3.517764e-01\n",
       "12  3.747840e-01 0.002178580  0.14301610  1.083559e-01  2.740038e-01\n",
       "13  2.285250e-03 0.002110999  0.13989517 -2.707905e-01 -9.120319e-02\n",
       "14 -9.467682e-02 0.002250769  0.14985753 -3.887576e-01 -1.935922e-01\n",
       "15 -1.061151e-03 0.002107106  0.14034016 -2.773884e-01 -9.747946e-02\n",
       "16  3.327988e-02 0.001911421  0.12763469 -2.174885e-01 -5.176958e-02\n",
       "17  1.724547e-02 0.002124920  0.14300469 -2.629663e-01 -7.990490e-02\n",
       "18 -3.536305e-02 0.001858035  0.12512593 -2.823228e-01 -1.194190e-01\n",
       "19  6.252783e-03 0.002169057  0.14638190 -2.810456e-01 -9.325424e-02\n",
       "20  8.351808e-03 0.001761744  0.11919547 -2.287759e-01 -6.980728e-02\n",
       "   X50.          X75.          X97.5.        n_eff     Rhat      PARAM       \n",
       "1   2.656609e-01  3.055718e-01     0.3942095  634.5591 1.0052367 sigma_beta_x\n",
       "2  -3.693998e+03 -3.690474e+03 -3684.5282425 1642.6856 1.0014264 lp__        \n",
       "3   1.527438e+01  2.495248e+01    51.3873414 2287.7516 1.0010776 nu_x        \n",
       "4   1.776910e-01  2.641735e-01     0.4324445 3425.3061 1.0010220 beta_x[25]  \n",
       "5   6.070426e-01  7.091381e-01     0.9318559 3579.6709 0.9992719 beta_x[20]  \n",
       "6   2.234030e-01  3.197703e-01     0.4952082 3813.7281 1.0003619 beta_x[22]  \n",
       "7  -2.470209e-03  9.858648e-02     0.2756219 3929.8193 0.9993425 alpha_x[23] \n",
       "8   1.851186e-01  2.720629e-01     0.4462349 3950.9885 1.0026073 beta_x[6]   \n",
       "9   4.675868e-03  1.046595e-01     0.3031569 4008.2647 1.0001969 alpha_x[5]  \n",
       "10  4.779772e-01  5.748605e-01     0.7783925 4059.1778 0.9999291 beta_x[12]  \n",
       "11  4.412668e-01  5.389415e-01     0.7259333 4144.5570 1.0005264 beta_x[23]  \n",
       "12  3.707629e-01  4.681028e-01     0.6720630 4309.4593 1.0000537 beta_x[4]   \n",
       "13  3.285005e-03  9.741511e-02     0.2799969 4391.6660 1.0000650 alpha_x[8]  \n",
       "14 -9.351785e-02  4.255748e-03     0.2018424 4432.9758 0.9999770 alpha_x[24] \n",
       "15 -5.457733e-04  9.368277e-02     0.2721876 4435.9980 0.9996895 alpha_x[11] \n",
       "16  3.139633e-02  1.167882e-01     0.2894979 4458.8672 1.0001066 beta_x[2]   \n",
       "17  1.768786e-02  1.151801e-01     0.2953089 4529.1385 0.9994576 alpha_x[25] \n",
       "18 -3.402049e-02  4.843645e-02     0.2071887 4535.0988 0.9994064 beta_x[16]  \n",
       "19  3.764722e-03  1.043737e-01     0.2955102 4554.4169 0.9993877 alpha_x[10] \n",
       "20  7.840889e-03  8.719670e-02     0.2448817 4577.5567 1.0001896 beta_x[21]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_sum = data.frame(summary(bayes_model_res$stage_2_fit)$summary) \n",
    "df_sum$PARAM = rownames(summary(bayes_model_res$stage_2_fit)$summary)\n",
    "df_sum %>% arrange(n_eff) %>% head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A data.frame: 27 × 10</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>Metabolite</th><th scope=col>Param</th><th scope=col>mean</th><th scope=col>sd</th><th scope=col>X2.5.</th><th scope=col>X50.</th><th scope=col>X97.5.</th><th scope=col>Rhat</th><th scope=col>Z</th><th scope=col>P_GT_LT_0</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>oacetylcarnitine</th><td>oacetylcarnitine </td><td>beta_x[20]</td><td> 0.607758944</td><td>0.1586494</td><td> 0.3163286082</td><td> 0.607042607</td><td>0.9318559</td><td>0.9992719</td><td> 3.83083012</td><td>1.00000</td></tr>\n",
       "\t<tr><th scope=row>betaine</th><td>betaine          </td><td>beta_x[5] </td><td> 0.532592474</td><td>0.1543020</td><td> 0.2386197291</td><td> 0.528290541</td><td>0.8478007</td><td>0.9994034</td><td> 3.45162400</td><td>1.00000</td></tr>\n",
       "\t<tr><th scope=row>glutamine</th><td>glutamine        </td><td>beta_x[12]</td><td> 0.483681085</td><td>0.1430646</td><td> 0.2124613381</td><td> 0.477977232</td><td>0.7783925</td><td>0.9999291</td><td> 3.38085748</td><td>1.00000</td></tr>\n",
       "\t<tr><th scope=row>propyleneglycol</th><td>propyleneglycol  </td><td>beta_x[24]</td><td> 0.556407559</td><td>0.1604862</td><td> 0.2488525927</td><td> 0.552118424</td><td>0.8837982</td><td>1.0002966</td><td> 3.46701178</td><td>0.99925</td></tr>\n",
       "\t<tr><th scope=row>proline</th><td>proline          </td><td>beta_x[23]</td><td> 0.445945542</td><td>0.1381715</td><td> 0.1850931031</td><td> 0.441266804</td><td>0.7259333</td><td>1.0005264</td><td> 3.22747792</td><td>0.99900</td></tr>\n",
       "\t<tr><th scope=row>alanine</th><td>alanine          </td><td>beta_x[4] </td><td> 0.374784027</td><td>0.1430161</td><td> 0.1083558581</td><td> 0.370762881</td><td>0.6720630</td><td>1.0000537</td><td> 2.62057225</td><td>0.99725</td></tr>\n",
       "\t<tr><th scope=row>choline</th><td>choline          </td><td>beta_x[7] </td><td> 0.241344261</td><td>0.1302298</td><td> 0.0003743308</td><td> 0.234269981</td><td>0.5024538</td><td>0.9996741</td><td> 1.85321887</td><td>0.97500</td></tr>\n",
       "\t<tr><th scope=row>phenylalanine</th><td>phenylalanine    </td><td>beta_x[22]</td><td> 0.227399111</td><td>0.1348648</td><td>-0.0241136226</td><td> 0.223402998</td><td>0.4952082</td><td>1.0003619</td><td> 1.68612684</td><td>0.95875</td></tr>\n",
       "\t<tr><th scope=row>carnitine</th><td>carnitine        </td><td>beta_x[6] </td><td> 0.185976377</td><td>0.1306148</td><td>-0.0661526957</td><td> 0.185118578</td><td>0.4462349</td><td>1.0026073</td><td> 1.42385405</td><td>0.92600</td></tr>\n",
       "\t<tr><th scope=row>pyruvate</th><td>pyruvate         </td><td>beta_x[25]</td><td> 0.180506306</td><td>0.1261141</td><td>-0.0628894757</td><td> 0.177691034</td><td>0.4324445</td><td>1.0010220</td><td> 1.43129386</td><td>0.92575</td></tr>\n",
       "\t<tr><th scope=row>valine</th><td>valine           </td><td>beta_x[27]</td><td> 0.157394229</td><td>0.1322081</td><td>-0.0924711653</td><td> 0.151409597</td><td>0.4258299</td><td>0.9996358</td><td> 1.19050337</td><td>0.88750</td></tr>\n",
       "\t<tr><th scope=row>leucine</th><td>leucine          </td><td>beta_x[17]</td><td> 0.152270998</td><td>0.1346257</td><td>-0.1088550558</td><td> 0.150552378</td><td>0.4240136</td><td>0.9993213</td><td> 1.13106910</td><td>0.87675</td></tr>\n",
       "\t<tr><th scope=row>citrate</th><td>citrate          </td><td>beta_x[8] </td><td> 0.081272402</td><td>0.1188707</td><td>-0.1481489911</td><td> 0.078610501</td><td>0.3225321</td><td>0.9992403</td><td> 0.68370428</td><td>0.75250</td></tr>\n",
       "\t<tr><th scope=row>hydroxybutyrate</th><td>hydroxybutyrate  </td><td>beta_x[1] </td><td>-0.072215148</td><td>0.1180887</td><td>-0.3050103725</td><td>-0.071184628</td><td>0.1549530</td><td>0.9999072</td><td>-0.61153299</td><td>0.73325</td></tr>\n",
       "\t<tr><th scope=row>creatinine</th><td>creatinine       </td><td>beta_x[10]</td><td> 0.069026064</td><td>0.1251423</td><td>-0.1745556374</td><td> 0.068515773</td><td>0.3182585</td><td>1.0001239</td><td> 0.55158065</td><td>0.70150</td></tr>\n",
       "\t<tr><th scope=row>X3.hydoxybutyrate</th><td>X3.hydoxybutyrate</td><td>beta_x[3] </td><td>-0.051271768</td><td>0.1228525</td><td>-0.2911473558</td><td>-0.047838209</td><td>0.1861140</td><td>0.9994954</td><td>-0.41734403</td><td>0.65550</td></tr>\n",
       "\t<tr><th scope=row>isoleucine</th><td>isoleucine       </td><td>beta_x[15]</td><td> 0.046041340</td><td>0.1213888</td><td>-0.1876663488</td><td> 0.044092055</td><td>0.2872076</td><td>0.9992542</td><td> 0.37928834</td><td>0.64925</td></tr>\n",
       "\t<tr><th scope=row>glucose</th><td>glucose          </td><td>beta_x[11]</td><td> 0.035221355</td><td>0.1130394</td><td>-0.1826572965</td><td> 0.034511690</td><td>0.2653456</td><td>1.0002660</td><td> 0.31158469</td><td>0.61525</td></tr>\n",
       "\t<tr><th scope=row>glycine</th><td>glycine          </td><td>beta_x[13]</td><td> 0.036256780</td><td>0.1198157</td><td>-0.2026163810</td><td> 0.034836776</td><td>0.2685608</td><td>0.9996628</td><td> 0.30260464</td><td>0.61425</td></tr>\n",
       "\t<tr><th scope=row>histidine</th><td>histidine        </td><td>beta_x[14]</td><td> 0.033318357</td><td>0.1248855</td><td>-0.2104594416</td><td> 0.032862004</td><td>0.2784720</td><td>0.9992637</td><td> 0.26679128</td><td>0.60875</td></tr>\n",
       "\t<tr><th scope=row>lactate</th><td>lactate          </td><td>beta_x[16]</td><td>-0.035363052</td><td>0.1251259</td><td>-0.2823227974</td><td>-0.034020486</td><td>0.2071887</td><td>0.9994064</td><td>-0.28261970</td><td>0.60675</td></tr>\n",
       "\t<tr><th scope=row>oxoisocaproate</th><td>oxoisocaproate   </td><td>beta_x[2] </td><td> 0.033279884</td><td>0.1276347</td><td>-0.2174885233</td><td> 0.031396325</td><td>0.2894979</td><td>1.0001066</td><td> 0.26074326</td><td>0.59375</td></tr>\n",
       "\t<tr><th scope=row>methionine</th><td>methionine       </td><td>beta_x[19]</td><td> 0.019495013</td><td>0.1263657</td><td>-0.2279824807</td><td> 0.020889829</td><td>0.2690154</td><td>0.9991148</td><td> 0.15427462</td><td>0.56725</td></tr>\n",
       "\t<tr><th scope=row>creatine</th><td>creatine         </td><td>beta_x[9] </td><td>-0.011257544</td><td>0.1152621</td><td>-0.2413257644</td><td>-0.009819537</td><td>0.2140675</td><td>0.9995280</td><td>-0.09766906</td><td>0.53475</td></tr>\n",
       "\t<tr><th scope=row>ornithine</th><td>ornithine        </td><td>beta_x[21]</td><td> 0.008351808</td><td>0.1191955</td><td>-0.2287759064</td><td> 0.007840889</td><td>0.2448817</td><td>1.0001896</td><td> 0.07006816</td><td>0.52650</td></tr>\n",
       "\t<tr><th scope=row>lysine</th><td>lysine           </td><td>beta_x[18]</td><td>-0.008581664</td><td>0.1234035</td><td>-0.2564782846</td><td>-0.006708722</td><td>0.2369026</td><td>0.9999137</td><td>-0.06954150</td><td>0.52200</td></tr>\n",
       "\t<tr><th scope=row>tyrosine</th><td>tyrosine         </td><td>beta_x[26]</td><td>-0.006236188</td><td>0.1276988</td><td>-0.2563842340</td><td>-0.006296916</td><td>0.2424370</td><td>1.0001693</td><td>-0.04883515</td><td>0.52075</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 27 × 10\n",
       "\\begin{tabular}{r|llllllllll}\n",
       "  & Metabolite & Param & mean & sd & X2.5. & X50. & X97.5. & Rhat & Z & P\\_GT\\_LT\\_0\\\\\n",
       "  & <fct> & <chr> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\toacetylcarnitine & oacetylcarnitine  & beta\\_x{[}20{]} &  0.607758944 & 0.1586494 &  0.3163286082 &  0.607042607 & 0.9318559 & 0.9992719 &  3.83083012 & 1.00000\\\\\n",
       "\tbetaine & betaine           & beta\\_x{[}5{]}  &  0.532592474 & 0.1543020 &  0.2386197291 &  0.528290541 & 0.8478007 & 0.9994034 &  3.45162400 & 1.00000\\\\\n",
       "\tglutamine & glutamine         & beta\\_x{[}12{]} &  0.483681085 & 0.1430646 &  0.2124613381 &  0.477977232 & 0.7783925 & 0.9999291 &  3.38085748 & 1.00000\\\\\n",
       "\tpropyleneglycol & propyleneglycol   & beta\\_x{[}24{]} &  0.556407559 & 0.1604862 &  0.2488525927 &  0.552118424 & 0.8837982 & 1.0002966 &  3.46701178 & 0.99925\\\\\n",
       "\tproline & proline           & beta\\_x{[}23{]} &  0.445945542 & 0.1381715 &  0.1850931031 &  0.441266804 & 0.7259333 & 1.0005264 &  3.22747792 & 0.99900\\\\\n",
       "\talanine & alanine           & beta\\_x{[}4{]}  &  0.374784027 & 0.1430161 &  0.1083558581 &  0.370762881 & 0.6720630 & 1.0000537 &  2.62057225 & 0.99725\\\\\n",
       "\tcholine & choline           & beta\\_x{[}7{]}  &  0.241344261 & 0.1302298 &  0.0003743308 &  0.234269981 & 0.5024538 & 0.9996741 &  1.85321887 & 0.97500\\\\\n",
       "\tphenylalanine & phenylalanine     & beta\\_x{[}22{]} &  0.227399111 & 0.1348648 & -0.0241136226 &  0.223402998 & 0.4952082 & 1.0003619 &  1.68612684 & 0.95875\\\\\n",
       "\tcarnitine & carnitine         & beta\\_x{[}6{]}  &  0.185976377 & 0.1306148 & -0.0661526957 &  0.185118578 & 0.4462349 & 1.0026073 &  1.42385405 & 0.92600\\\\\n",
       "\tpyruvate & pyruvate          & beta\\_x{[}25{]} &  0.180506306 & 0.1261141 & -0.0628894757 &  0.177691034 & 0.4324445 & 1.0010220 &  1.43129386 & 0.92575\\\\\n",
       "\tvaline & valine            & beta\\_x{[}27{]} &  0.157394229 & 0.1322081 & -0.0924711653 &  0.151409597 & 0.4258299 & 0.9996358 &  1.19050337 & 0.88750\\\\\n",
       "\tleucine & leucine           & beta\\_x{[}17{]} &  0.152270998 & 0.1346257 & -0.1088550558 &  0.150552378 & 0.4240136 & 0.9993213 &  1.13106910 & 0.87675\\\\\n",
       "\tcitrate & citrate           & beta\\_x{[}8{]}  &  0.081272402 & 0.1188707 & -0.1481489911 &  0.078610501 & 0.3225321 & 0.9992403 &  0.68370428 & 0.75250\\\\\n",
       "\thydroxybutyrate & hydroxybutyrate   & beta\\_x{[}1{]}  & -0.072215148 & 0.1180887 & -0.3050103725 & -0.071184628 & 0.1549530 & 0.9999072 & -0.61153299 & 0.73325\\\\\n",
       "\tcreatinine & creatinine        & beta\\_x{[}10{]} &  0.069026064 & 0.1251423 & -0.1745556374 &  0.068515773 & 0.3182585 & 1.0001239 &  0.55158065 & 0.70150\\\\\n",
       "\tX3.hydoxybutyrate & X3.hydoxybutyrate & beta\\_x{[}3{]}  & -0.051271768 & 0.1228525 & -0.2911473558 & -0.047838209 & 0.1861140 & 0.9994954 & -0.41734403 & 0.65550\\\\\n",
       "\tisoleucine & isoleucine        & beta\\_x{[}15{]} &  0.046041340 & 0.1213888 & -0.1876663488 &  0.044092055 & 0.2872076 & 0.9992542 &  0.37928834 & 0.64925\\\\\n",
       "\tglucose & glucose           & beta\\_x{[}11{]} &  0.035221355 & 0.1130394 & -0.1826572965 &  0.034511690 & 0.2653456 & 1.0002660 &  0.31158469 & 0.61525\\\\\n",
       "\tglycine & glycine           & beta\\_x{[}13{]} &  0.036256780 & 0.1198157 & -0.2026163810 &  0.034836776 & 0.2685608 & 0.9996628 &  0.30260464 & 0.61425\\\\\n",
       "\thistidine & histidine         & beta\\_x{[}14{]} &  0.033318357 & 0.1248855 & -0.2104594416 &  0.032862004 & 0.2784720 & 0.9992637 &  0.26679128 & 0.60875\\\\\n",
       "\tlactate & lactate           & beta\\_x{[}16{]} & -0.035363052 & 0.1251259 & -0.2823227974 & -0.034020486 & 0.2071887 & 0.9994064 & -0.28261970 & 0.60675\\\\\n",
       "\toxoisocaproate & oxoisocaproate    & beta\\_x{[}2{]}  &  0.033279884 & 0.1276347 & -0.2174885233 &  0.031396325 & 0.2894979 & 1.0001066 &  0.26074326 & 0.59375\\\\\n",
       "\tmethionine & methionine        & beta\\_x{[}19{]} &  0.019495013 & 0.1263657 & -0.2279824807 &  0.020889829 & 0.2690154 & 0.9991148 &  0.15427462 & 0.56725\\\\\n",
       "\tcreatine & creatine          & beta\\_x{[}9{]}  & -0.011257544 & 0.1152621 & -0.2413257644 & -0.009819537 & 0.2140675 & 0.9995280 & -0.09766906 & 0.53475\\\\\n",
       "\tornithine & ornithine         & beta\\_x{[}21{]} &  0.008351808 & 0.1191955 & -0.2287759064 &  0.007840889 & 0.2448817 & 1.0001896 &  0.07006816 & 0.52650\\\\\n",
       "\tlysine & lysine            & beta\\_x{[}18{]} & -0.008581664 & 0.1234035 & -0.2564782846 & -0.006708722 & 0.2369026 & 0.9999137 & -0.06954150 & 0.52200\\\\\n",
       "\ttyrosine & tyrosine          & beta\\_x{[}26{]} & -0.006236188 & 0.1276988 & -0.2563842340 & -0.006296916 & 0.2424370 & 1.0001693 & -0.04883515 & 0.52075\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 27 × 10\n",
       "\n",
       "| <!--/--> | Metabolite &lt;fct&gt; | Param &lt;chr&gt; | mean &lt;dbl&gt; | sd &lt;dbl&gt; | X2.5. &lt;dbl&gt; | X50. &lt;dbl&gt; | X97.5. &lt;dbl&gt; | Rhat &lt;dbl&gt; | Z &lt;dbl&gt; | P_GT_LT_0 &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| oacetylcarnitine | oacetylcarnitine  | beta_x[20] |  0.607758944 | 0.1586494 |  0.3163286082 |  0.607042607 | 0.9318559 | 0.9992719 |  3.83083012 | 1.00000 |\n",
       "| betaine | betaine           | beta_x[5]  |  0.532592474 | 0.1543020 |  0.2386197291 |  0.528290541 | 0.8478007 | 0.9994034 |  3.45162400 | 1.00000 |\n",
       "| glutamine | glutamine         | beta_x[12] |  0.483681085 | 0.1430646 |  0.2124613381 |  0.477977232 | 0.7783925 | 0.9999291 |  3.38085748 | 1.00000 |\n",
       "| propyleneglycol | propyleneglycol   | beta_x[24] |  0.556407559 | 0.1604862 |  0.2488525927 |  0.552118424 | 0.8837982 | 1.0002966 |  3.46701178 | 0.99925 |\n",
       "| proline | proline           | beta_x[23] |  0.445945542 | 0.1381715 |  0.1850931031 |  0.441266804 | 0.7259333 | 1.0005264 |  3.22747792 | 0.99900 |\n",
       "| alanine | alanine           | beta_x[4]  |  0.374784027 | 0.1430161 |  0.1083558581 |  0.370762881 | 0.6720630 | 1.0000537 |  2.62057225 | 0.99725 |\n",
       "| choline | choline           | beta_x[7]  |  0.241344261 | 0.1302298 |  0.0003743308 |  0.234269981 | 0.5024538 | 0.9996741 |  1.85321887 | 0.97500 |\n",
       "| phenylalanine | phenylalanine     | beta_x[22] |  0.227399111 | 0.1348648 | -0.0241136226 |  0.223402998 | 0.4952082 | 1.0003619 |  1.68612684 | 0.95875 |\n",
       "| carnitine | carnitine         | beta_x[6]  |  0.185976377 | 0.1306148 | -0.0661526957 |  0.185118578 | 0.4462349 | 1.0026073 |  1.42385405 | 0.92600 |\n",
       "| pyruvate | pyruvate          | beta_x[25] |  0.180506306 | 0.1261141 | -0.0628894757 |  0.177691034 | 0.4324445 | 1.0010220 |  1.43129386 | 0.92575 |\n",
       "| valine | valine            | beta_x[27] |  0.157394229 | 0.1322081 | -0.0924711653 |  0.151409597 | 0.4258299 | 0.9996358 |  1.19050337 | 0.88750 |\n",
       "| leucine | leucine           | beta_x[17] |  0.152270998 | 0.1346257 | -0.1088550558 |  0.150552378 | 0.4240136 | 0.9993213 |  1.13106910 | 0.87675 |\n",
       "| citrate | citrate           | beta_x[8]  |  0.081272402 | 0.1188707 | -0.1481489911 |  0.078610501 | 0.3225321 | 0.9992403 |  0.68370428 | 0.75250 |\n",
       "| hydroxybutyrate | hydroxybutyrate   | beta_x[1]  | -0.072215148 | 0.1180887 | -0.3050103725 | -0.071184628 | 0.1549530 | 0.9999072 | -0.61153299 | 0.73325 |\n",
       "| creatinine | creatinine        | beta_x[10] |  0.069026064 | 0.1251423 | -0.1745556374 |  0.068515773 | 0.3182585 | 1.0001239 |  0.55158065 | 0.70150 |\n",
       "| X3.hydoxybutyrate | X3.hydoxybutyrate | beta_x[3]  | -0.051271768 | 0.1228525 | -0.2911473558 | -0.047838209 | 0.1861140 | 0.9994954 | -0.41734403 | 0.65550 |\n",
       "| isoleucine | isoleucine        | beta_x[15] |  0.046041340 | 0.1213888 | -0.1876663488 |  0.044092055 | 0.2872076 | 0.9992542 |  0.37928834 | 0.64925 |\n",
       "| glucose | glucose           | beta_x[11] |  0.035221355 | 0.1130394 | -0.1826572965 |  0.034511690 | 0.2653456 | 1.0002660 |  0.31158469 | 0.61525 |\n",
       "| glycine | glycine           | beta_x[13] |  0.036256780 | 0.1198157 | -0.2026163810 |  0.034836776 | 0.2685608 | 0.9996628 |  0.30260464 | 0.61425 |\n",
       "| histidine | histidine         | beta_x[14] |  0.033318357 | 0.1248855 | -0.2104594416 |  0.032862004 | 0.2784720 | 0.9992637 |  0.26679128 | 0.60875 |\n",
       "| lactate | lactate           | beta_x[16] | -0.035363052 | 0.1251259 | -0.2823227974 | -0.034020486 | 0.2071887 | 0.9994064 | -0.28261970 | 0.60675 |\n",
       "| oxoisocaproate | oxoisocaproate    | beta_x[2]  |  0.033279884 | 0.1276347 | -0.2174885233 |  0.031396325 | 0.2894979 | 1.0001066 |  0.26074326 | 0.59375 |\n",
       "| methionine | methionine        | beta_x[19] |  0.019495013 | 0.1263657 | -0.2279824807 |  0.020889829 | 0.2690154 | 0.9991148 |  0.15427462 | 0.56725 |\n",
       "| creatine | creatine          | beta_x[9]  | -0.011257544 | 0.1152621 | -0.2413257644 | -0.009819537 | 0.2140675 | 0.9995280 | -0.09766906 | 0.53475 |\n",
       "| ornithine | ornithine         | beta_x[21] |  0.008351808 | 0.1191955 | -0.2287759064 |  0.007840889 | 0.2448817 | 1.0001896 |  0.07006816 | 0.52650 |\n",
       "| lysine | lysine            | beta_x[18] | -0.008581664 | 0.1234035 | -0.2564782846 | -0.006708722 | 0.2369026 | 0.9999137 | -0.06954150 | 0.52200 |\n",
       "| tyrosine | tyrosine          | beta_x[26] | -0.006236188 | 0.1276988 | -0.2563842340 | -0.006296916 | 0.2424370 | 1.0001693 | -0.04883515 | 0.52075 |\n",
       "\n"
      ],
      "text/plain": [
       "                  Metabolite        Param      mean         sd       \n",
       "oacetylcarnitine  oacetylcarnitine  beta_x[20]  0.607758944 0.1586494\n",
       "betaine           betaine           beta_x[5]   0.532592474 0.1543020\n",
       "glutamine         glutamine         beta_x[12]  0.483681085 0.1430646\n",
       "propyleneglycol   propyleneglycol   beta_x[24]  0.556407559 0.1604862\n",
       "proline           proline           beta_x[23]  0.445945542 0.1381715\n",
       "alanine           alanine           beta_x[4]   0.374784027 0.1430161\n",
       "choline           choline           beta_x[7]   0.241344261 0.1302298\n",
       "phenylalanine     phenylalanine     beta_x[22]  0.227399111 0.1348648\n",
       "carnitine         carnitine         beta_x[6]   0.185976377 0.1306148\n",
       "pyruvate          pyruvate          beta_x[25]  0.180506306 0.1261141\n",
       "valine            valine            beta_x[27]  0.157394229 0.1322081\n",
       "leucine           leucine           beta_x[17]  0.152270998 0.1346257\n",
       "citrate           citrate           beta_x[8]   0.081272402 0.1188707\n",
       "hydroxybutyrate   hydroxybutyrate   beta_x[1]  -0.072215148 0.1180887\n",
       "creatinine        creatinine        beta_x[10]  0.069026064 0.1251423\n",
       "X3.hydoxybutyrate X3.hydoxybutyrate beta_x[3]  -0.051271768 0.1228525\n",
       "isoleucine        isoleucine        beta_x[15]  0.046041340 0.1213888\n",
       "glucose           glucose           beta_x[11]  0.035221355 0.1130394\n",
       "glycine           glycine           beta_x[13]  0.036256780 0.1198157\n",
       "histidine         histidine         beta_x[14]  0.033318357 0.1248855\n",
       "lactate           lactate           beta_x[16] -0.035363052 0.1251259\n",
       "oxoisocaproate    oxoisocaproate    beta_x[2]   0.033279884 0.1276347\n",
       "methionine        methionine        beta_x[19]  0.019495013 0.1263657\n",
       "creatine          creatine          beta_x[9]  -0.011257544 0.1152621\n",
       "ornithine         ornithine         beta_x[21]  0.008351808 0.1191955\n",
       "lysine            lysine            beta_x[18] -0.008581664 0.1234035\n",
       "tyrosine          tyrosine          beta_x[26] -0.006236188 0.1276988\n",
       "                  X2.5.         X50.         X97.5.    Rhat      Z          \n",
       "oacetylcarnitine   0.3163286082  0.607042607 0.9318559 0.9992719  3.83083012\n",
       "betaine            0.2386197291  0.528290541 0.8478007 0.9994034  3.45162400\n",
       "glutamine          0.2124613381  0.477977232 0.7783925 0.9999291  3.38085748\n",
       "propyleneglycol    0.2488525927  0.552118424 0.8837982 1.0002966  3.46701178\n",
       "proline            0.1850931031  0.441266804 0.7259333 1.0005264  3.22747792\n",
       "alanine            0.1083558581  0.370762881 0.6720630 1.0000537  2.62057225\n",
       "choline            0.0003743308  0.234269981 0.5024538 0.9996741  1.85321887\n",
       "phenylalanine     -0.0241136226  0.223402998 0.4952082 1.0003619  1.68612684\n",
       "carnitine         -0.0661526957  0.185118578 0.4462349 1.0026073  1.42385405\n",
       "pyruvate          -0.0628894757  0.177691034 0.4324445 1.0010220  1.43129386\n",
       "valine            -0.0924711653  0.151409597 0.4258299 0.9996358  1.19050337\n",
       "leucine           -0.1088550558  0.150552378 0.4240136 0.9993213  1.13106910\n",
       "citrate           -0.1481489911  0.078610501 0.3225321 0.9992403  0.68370428\n",
       "hydroxybutyrate   -0.3050103725 -0.071184628 0.1549530 0.9999072 -0.61153299\n",
       "creatinine        -0.1745556374  0.068515773 0.3182585 1.0001239  0.55158065\n",
       "X3.hydoxybutyrate -0.2911473558 -0.047838209 0.1861140 0.9994954 -0.41734403\n",
       "isoleucine        -0.1876663488  0.044092055 0.2872076 0.9992542  0.37928834\n",
       "glucose           -0.1826572965  0.034511690 0.2653456 1.0002660  0.31158469\n",
       "glycine           -0.2026163810  0.034836776 0.2685608 0.9996628  0.30260464\n",
       "histidine         -0.2104594416  0.032862004 0.2784720 0.9992637  0.26679128\n",
       "lactate           -0.2823227974 -0.034020486 0.2071887 0.9994064 -0.28261970\n",
       "oxoisocaproate    -0.2174885233  0.031396325 0.2894979 1.0001066  0.26074326\n",
       "methionine        -0.2279824807  0.020889829 0.2690154 0.9991148  0.15427462\n",
       "creatine          -0.2413257644 -0.009819537 0.2140675 0.9995280 -0.09766906\n",
       "ornithine         -0.2287759064  0.007840889 0.2448817 1.0001896  0.07006816\n",
       "lysine            -0.2564782846 -0.006708722 0.2369026 0.9999137 -0.06954150\n",
       "tyrosine          -0.2563842340 -0.006296916 0.2424370 1.0001693 -0.04883515\n",
       "                  P_GT_LT_0\n",
       "oacetylcarnitine  1.00000  \n",
       "betaine           1.00000  \n",
       "glutamine         1.00000  \n",
       "propyleneglycol   0.99925  \n",
       "proline           0.99900  \n",
       "alanine           0.99725  \n",
       "choline           0.97500  \n",
       "phenylalanine     0.95875  \n",
       "carnitine         0.92600  \n",
       "pyruvate          0.92575  \n",
       "valine            0.88750  \n",
       "leucine           0.87675  \n",
       "citrate           0.75250  \n",
       "hydroxybutyrate   0.73325  \n",
       "creatinine        0.70150  \n",
       "X3.hydoxybutyrate 0.65550  \n",
       "isoleucine        0.64925  \n",
       "glucose           0.61525  \n",
       "glycine           0.61425  \n",
       "histidine         0.60875  \n",
       "lactate           0.60675  \n",
       "oxoisocaproate    0.59375  \n",
       "methionine        0.56725  \n",
       "creatine          0.53475  \n",
       "ornithine         0.52650  \n",
       "lysine            0.52200  \n",
       "tyrosine          0.52075  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bayes_model_res$sum_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Full Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_sim = function(n_sim=100,n_0=100,n_1=100,frac_sig=0.4,\n",
    "                   metabolites=NULL,censor=TRUE,max_missing=0.4,iter=2000,sim_number=1,MISSING_RATE=NULL,alpha=NULL,beta=NULL) {\n",
    "    res = data.frame(stringsAsFactors = F)\n",
    "    for(i in 1:n_sim) {\n",
    "        sim_data = make_df(n_0,mu_0,sigma_0,n_1,mu_1,sigma_1,frac_sig=frac_sig,censor=censor,max_missing=max_missing,alpha = alpha, beta=beta)\n",
    "        df_censored = sim_data$df_censored\n",
    "        df_naive_impute = sim_data$df_naive_impute\n",
    "        truth = sim_data$truth\n",
    "        \n",
    "        out_sim = paste0(\"RAW_\", \"SIM_NUMBER_\",sim_number,\"_N_SAMPLE_\",n_sample,\"_FRAC_SIG_\",frac_sig,'_MISSING_RATE_',MISSING_RATE,'_SIM_DATA','.rds' )\n",
    "        print(\"WRITNG OUT...\")\n",
    "        print(out_sim)\n",
    "        write_rds(sim_data, out_sim, compress = 'gz')\n",
    "        \n",
    "        df_eff_sim = sapply(metabolites,FUN=function( x ) { apply_logistic_sim(x,df_naive_impute) } )\n",
    "        sig_raw = as.vector( df_eff_sim['Pr(>|z|)',] < 0.05)\n",
    "        eff_raw = as.vector( df_eff_sim['Estimate',])\n",
    "        \n",
    "        sig_bon = as.vector( p.adjust( df_eff_sim['Pr(>|z|)',],method='bonferroni') < 0.05)\n",
    "        eff_bon = as.vector( df_eff_sim['Estimate',])\n",
    "        \n",
    "        sig_bh = as.vector( p.adjust( df_eff_sim['Pr(>|z|)',],method='BH') < 0.05)\n",
    "        eff_bh = as.vector( df_eff_sim['Estimate',])\n",
    "        \n",
    "        bayes_model_res = run_bayes_model(df_censored,metabolites,cores=4,chains=4,iter=2000, \n",
    "                           adapt_delta=adapt_delta,\n",
    "                           max_treedepth=max_treedepth)\n",
    "        \n",
    "        \n",
    "        sum_table = bayes_model_res$sum_table\n",
    "        stage_1_fit = bayes_model_res$stage_1_fit\n",
    "        stage_2_fit = bayes_model_res$stage_2_fit\n",
    "        \n",
    "        out_fit = paste0(\"RAW_\", \"SIM_NUMBER_\",sim_number,\"_N_SAMPLE_\",n_sample,\"_FRAC_SIG_\",frac_sig,'_MISSING_RATE_',MISSING_RATE,'_FIT_DATA','.rds' )\n",
    "        print(\"WRITNG OUT...\")\n",
    "        print(out_fit)\n",
    "        write_rds(bayes_model_res, out_fit, compress = 'gz')\n",
    "\n",
    "        sig_bayes = as.vector( sum_table[metabolites,'P_GT_LT_0'] > 0.975  )\n",
    "        eff_bayes = as.vector( sum_table[metabolites,'mean'] )\n",
    "        \n",
    "        res_bayes = compute_stats(sig_bayes,truth,'bayes', eff_bayes, true_effs )\n",
    "        res = rbind(res,res_bayes,stringsAsFactors = F)\n",
    "        \n",
    "        res_raw = compute_stats(sig_raw,truth,'raw', eff_raw, true_effs )\n",
    "        res = rbind(res,res_raw,stringsAsFactors = F)\n",
    "        res_bon = compute_stats(sig_bon,truth,'bon', eff_bon, true_effs )\n",
    "        res = rbind(res,res_bon,stringsAsFactors = F)\n",
    "        res_bh = compute_stats(sig_bh,truth,'bh', eff_bh, true_effs )\n",
    "        res = rbind(res,res_bh,stringsAsFactors = F)\n",
    "        \n",
    "    }\n",
    "    res\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_logistic_sim = function(met,df) {\n",
    "    m = glm(died_90_day ~ I(df[,met]) ,data=df,family=\"binomial\")\n",
    "    summary(m)$coef[2,]\n",
    "}\n",
    "\n",
    "compute_stats = function(sig, truth, label, est_effs, true_effs ) {\n",
    "    tp = sum(   (sig == 1) & (truth == 1)  )\n",
    "    fn = sum(  (sig == 0) & (truth == 1) )\n",
    "    fp = sum(  (sig == 1) & (truth == 0)   )\n",
    "    tn =  sum(  (sig == 0) & (truth == 0)  )\n",
    "    avg_mag_error = mean( abs(est_effs[sig & truth]/true_effs[sig & truth]) )\n",
    "    num_sign_error = sum( (sign(est_effs) != sign(true_effs))[sig & truth] )\n",
    "    n_sig = sum(sig)\n",
    "    n_true = sum(truth)\n",
    "    \n",
    "    if(n_sig == 0) {\n",
    "        avg_mag_error = 0\n",
    "        num_sign_error = 0\n",
    "    }\n",
    "    return(list(label=label,tp=tp,fn=fn,fp=fp,tn=tn,avg_mag_error=avg_mag_error, num_sign_error=num_sign_error, n_sig=n_sig, n_true=n_true))\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>0.163364533408035</li><li>-0.0719094665568287</li><li>0.0624695472174143</li><li>0.497537667236366</li><li>0.65312578690536</li><li>0.375400571682463</li><li>0.228516667851782</li><li>0.296442697766152</li><li>0.248074240055132</li><li>0.397163650717822</li><li>0.00714500050815776</li><li>0.544193713839098</li><li>0.560530087468972</li><li>0.349306688307906</li><li>0.0557554962785265</li><li>0.528384922843494</li><li>0.19568022088194</li><li>0.539678609728228</li><li>0.491448915096003</li><li>0.742787623351699</li><li>0.260777675261804</li><li>0.352879482832724</li><li>0.484480117733923</li><li>0.613135152004664</li><li>0.257000716735528</li><li>0.656703857983067</li><li>0.170360191482621</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 0.163364533408035\n",
       "\\item -0.0719094665568287\n",
       "\\item 0.0624695472174143\n",
       "\\item 0.497537667236366\n",
       "\\item 0.65312578690536\n",
       "\\item 0.375400571682463\n",
       "\\item 0.228516667851782\n",
       "\\item 0.296442697766152\n",
       "\\item 0.248074240055132\n",
       "\\item 0.397163650717822\n",
       "\\item 0.00714500050815776\n",
       "\\item 0.544193713839098\n",
       "\\item 0.560530087468972\n",
       "\\item 0.349306688307906\n",
       "\\item 0.0557554962785265\n",
       "\\item 0.528384922843494\n",
       "\\item 0.19568022088194\n",
       "\\item 0.539678609728228\n",
       "\\item 0.491448915096003\n",
       "\\item 0.742787623351699\n",
       "\\item 0.260777675261804\n",
       "\\item 0.352879482832724\n",
       "\\item 0.484480117733923\n",
       "\\item 0.613135152004664\n",
       "\\item 0.257000716735528\n",
       "\\item 0.656703857983067\n",
       "\\item 0.170360191482621\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 0.163364533408035\n",
       "2. -0.0719094665568287\n",
       "3. 0.0624695472174143\n",
       "4. 0.497537667236366\n",
       "5. 0.65312578690536\n",
       "6. 0.375400571682463\n",
       "7. 0.228516667851782\n",
       "8. 0.296442697766152\n",
       "9. 0.248074240055132\n",
       "10. 0.397163650717822\n",
       "11. 0.00714500050815776\n",
       "12. 0.544193713839098\n",
       "13. 0.560530087468972\n",
       "14. 0.349306688307906\n",
       "15. 0.0557554962785265\n",
       "16. 0.528384922843494\n",
       "17. 0.19568022088194\n",
       "18. 0.539678609728228\n",
       "19. 0.491448915096003\n",
       "20. 0.742787623351699\n",
       "21. 0.260777675261804\n",
       "22. 0.352879482832724\n",
       "23. 0.484480117733923\n",
       "24. 0.613135152004664\n",
       "25. 0.257000716735528\n",
       "26. 0.656703857983067\n",
       "27. 0.170360191482621\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1]  0.163364533 -0.071909467  0.062469547  0.497537667  0.653125787\n",
       " [6]  0.375400572  0.228516668  0.296442698  0.248074240  0.397163651\n",
       "[11]  0.007145001  0.544193714  0.560530087  0.349306688  0.055755496\n",
       "[16]  0.528384923  0.195680221  0.539678610  0.491448915  0.742787623\n",
       "[21]  0.260777675  0.352879483  0.484480118  0.613135152  0.257000717\n",
       "[26]  0.656703858  0.170360191"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sim_data = make_df(10000,mu_0,sigma_0,10000,mu_1,sigma_1,frac_sig=1,censor=FALSE)\n",
    "df_sample = sim_data$df_sample\n",
    "truth = sim_data$truth\n",
    "df_eff_sim = sapply(colnames(df_sample)[1:27],FUN=function( x ) { apply_logistic_sim(x,df_sample) } )\n",
    "true_effs = as.numeric(df_eff_sim['Estimate',])\n",
    "true_effs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"WRITNG OUT...\"\n",
      "[1] \"RAW_SIM_NUMBER_1_N_SAMPLE_100_FRAC_SIG_0.4_MISSING_RATE_0.05_SIM_DATA.rds\"\n",
      "[1] \"CONTROL\"\n",
      "$adapt_delta\n",
      "[1] 0.8\n",
      "\n",
      "$max_treedepth\n",
      "[1] 10\n",
      "\n",
      "[1] \"NO MISING DATA SKIPPING IMPUTATION\"\n",
      "[1] \"WRITNG OUT...\"\n",
      "[1] \"RAW_SIM_NUMBER_1_N_SAMPLE_100_FRAC_SIG_0.4_MISSING_RATE_0.05_FIT_DATA.rds\"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n_sample = 100\n",
    "frac_sig=0.4\n",
    "max_missing=0.4\n",
    "n_iter=2000\n",
    "adapt_delta=0.8\n",
    "max_treedepth=10\n",
    "TARGET_MISSING_RATE = 0.05\n",
    "beta_params = get_alpha_beta_for_target_rate(df_nmr,metabolites,TARGET_MISSING_RATE = TARGET_MISSING_RATE)\n",
    "alpha = beta_params$alpha\n",
    "beta = beta_params$beta\n",
    "sim_number=1\n",
    "res = run_sim(n_sim=1,n_0=n_sample,\n",
    "              n_1=n_sample,frac_sig=frac_sig,metabolites=metabolites,\n",
    "              max_missing=max_missing,iter=n_iter,sim_number=1,MISSING_RATE=TARGET_MISSING_RATE,\n",
    "              alpha=alpha, beta=beta, censor=FALSE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
